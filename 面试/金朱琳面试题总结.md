* settings源码分析

  ```python
  Django配置文件有两个，一个是暴露给用户自定义配置的，另一个是默认的全局配置文件，即用户指定了就用用户的，用户没有指定就用默认的。
  全局配置文件入口：from django.conf import global_settings
  自定义配置文件入口：from django.conf import settings
  1）利用单例模式settings = LazySettings()
  2）查看LazySettings类
  class LazySettings(LazyObject):
      def _setup(self, name=None):
          # settings_module是从os.environ全局字典中获取ENVIRONMENT_VARIABLE环境变量，而ENVIRONMENT_VARIABLE = "DJANGO_SETTINGS_MODULE"，从manage.py中得出os.environ.setdefault("DJANGO_SETTINGS_MODULE", "test03.settings")即往os.environ大字典中添加键值对，故settings_module="test03.settings"
          settings_module = os.environ.get(ENVIRONMENT_VARIABLE)
          if not settings_module:
              desc = ("setting %s" % name) if name else "settings"
          self._wrapped = Settings(settings_module)
  3）查看Settings类
  class Settings(object):
      def __init__(self, settings_module):
          for setting in dir(global_settings):# 循环获取全局配置文件中的变量名
              if setting.isupper(): #判断是否是大写
                  # 利用反射获取变量名对应的值，并添加键值对
                  setattr(self, setting, getattr(global_settings, setting))
          self.SETTINGS_MODULE = settings_module
          # 获取配置文件模块名即settings
          mod = importlib.import_module(self.SETTINGS_MODULE)
          for setting in dir(mod):# 循环获取暴露给用户配置文件中所有的变量名
              if setting.isupper():
                  setting_value = getattr(mod, setting) # 获取大写变量名对应的值
                  setattr(self, setting, setting_value) # 给对象赋值
  应用：基于settings源码实现配置文件可插拔式设计？
  # about_settings/conf/settings.py
  NAME = "自定义配置"
  # about_settings/lib/conf/global_settings.py
  NAME = "系统默认全局配置"
  # about_settings/start.py
  import os, sys
  BASE_DIR = os.path.dirname(__file__) # 获取当前项目绝对路径
  sys.path.append(BASE_DIR) # 将路径添加到环境变量中
  os.environ.setdefault("SETTINGS_MODULES", "conf.settings") # 往系统信息中添加字符串所对应环境的映射对象
  from lib.conf import settings # 导包就是导__init__
  print(settings.NAME)
  # about_settings/lib/conf/__init__.py
  import os, importlib
  from lib.conf import global_settings
  class Settings:
      def __init__(self):
          for setting in dir(global_settings):
              if setting.upper():
                  k = setting
                  v = getattr(global_settings, setting)
                  setattr(self, k, v)
              # 从系统信息中获取暴露给用户的配置文件字符串路径
              mod = os.environ.get("SETTINGS_MODULES")
              # 获取用户配置文件模块名，即settings
              module = importlib.import_module(mod)
              for setting in dir(module):
                  if setting.upper():
                      k = setting
                      v = getattr(module, setting)
                      setattr(self, k, v)
  settings = Settings()
  1）循环获取默认的配置文件中所有的大写配置
  2）利用setattr给对象不停的设置键值对
  3）再循环获取暴露给用户自定义配置文件中所有的大写配置
  4）再利用setattr给对象不停的设置键值对
  ```

* 熟练使用Django框架中ORM、Forms、Auth、中间件等操作

  ```python
  Admin组件：对model中对应的数据表进行增删改查提供的组件
  model组件：负责操作数据库
  form组件：既可生成HTML代码，又可对数据有效性校验且校验信息返回并展示
  ModelForm组件：既用于数据库操作,也可用于用户请求的验证  
  # 必知必会十三条
  1）all方法：查询所有，返回queryset对象
  2）filter方法：过滤，返回queryset对象
  3）get方法：过滤，返回数据对象本身
  4）first方法：取第一个，返回数据对象本身
  5）last方法：取最后一个，返回数据对象本身
  6）exclude方法：除此之外，返回queryset对象
  7）values方法：获取字段对应的所有数据，返回queryset对象，列表套字典形式存在
  8）values_list方法：获取字段对应的所有数据，返回queryset对象，列表套元组形式存在
  9）count方法：统计数据的条数
  10）distinct方法：去重，记录必须完全相同才行
  11）order_by方法：排序，默认升序，字段前加负号降序，返回queryset对象
  12）reverse方法：倒序，前提是先经过排序才行，返回queryset对象
  13）exists方法：判断是否存在
  # 双下划线查询
  1）price__gt=50:大于50
  2）price__lt=50:小于50
  3）price__gte=50:大于等于50
  4）price__lte=50:小于等于50
  5）price__in=[50,60,70]:价格是其中一个取出
  6）price__range=(50,60):价格在某个范围，顾头不顾尾
  7）title__contains="p":区分大小写
  8）title__icontains="p"：忽略大小写
  9）title__startswith="p":以什么开头
  10）title__endswith="p":以什么结尾
  11）publish_date__year="2019":查询2019年出版
  # 基于对象的跨表查询（子查询）和基于双下划线的跨表查询（连表查询）
  1）外键字段在A表，由A查B表是正向查询，反之由B表查A是反向查询。
  2）正向查询按字段，反向查询按表名小写（多个结果用表名小写_set）
  # 聚合查询
  aggregate
  # 分组查询
  annotate
  # F与Q查询
  1）F查询用于比较条件（+-<>）
  2）Q查询用于逻辑条件（&|~）
  # 模型类关系
  1）一对多关系：ForeignKey---定义在多的一方
  2）多对多关系：ManyToMany---都可以
  3）一对一关系：OneToOne---都可以
  ORM：对象关系映射，通过models中的类来对应数据库中的一个表，一个对象对应一个数据行，一个属性对应数据库中的一个字段
  django中only与defer的区别？
  only('id','name'):取的对象，只有id和name
  注：only将括号内的字段对应值，直接封装到返回给你的对象中，点该字段不再走数据库，一旦点括号内其他字段，就会频繁走数据库查询
  defer('id','name'):取出对象，字段除了id和name都有
  注：defer将括号内的字段排除在外的对应值，直接封装到返回给你的对象中，点其他字段不再走数据库，一旦点括号内的字段，就会频繁走数据库查询
  django中select_related与prefetch_related的区别？
  前提：有外键存在时，可以很好的减少数据库请求的次数,提高性能
  select_related：通过多表join关联查询,一次性获得所有数据,只执行一次SQL查询
  prefetch_related：分别查询每个表,然后根据它们之间的关系进行处理,执行两次查询
  ```

* 理解OOP编程思想三大特性、反射、元类、魔法方法

  ```python
  封装:把一堆数据属性与方法数据放在一个容器中，这个容器就是对象。让对象可以通过 "." 来调用对象中的数据属性与方法属性。 
  继承:子类可以继承父类的数据属性与方法属性，并可以对其进行修改或使用。
  多态:让多种类若具备类似的数据属性与方法属性，都统一好命名规范，这样可以提高开发者的代码统一性，使得调用者更方便去理解。
  鸭子模型：在python中不会强制性要求所有人的代码都统一规范，不统一也不会报错，若使用抽象类就会使python代码强制统一规范，这样不符合python动态语言的特性。所以让大家都自觉统一好规范，若大家的对象方法都类似的话就一种规范，只要长得像鸭子，就称之为鸭子类型。
  super：可在子类中调用父类的方法或属性, 可能你会说, 子类本来就可以调用父类中所有非私有的属性或方法,而我现在说的是, 当子类中实现了某个方法, 父类中也有这个方法, 当你调用这个方法时, 既想执行子类的又想执行父类的, 在这种情况下就可以使用super()
  mro：全称Method Resolution Order，方法解析顺序。方法调用时就需要对当前类和基类进行搜索以确定方法所在的位置，而搜索的顺序就是所谓的「方法解析顺序」。
  反射：通过字符串来获取、设置、删除对象的属性或方法，其应用场景是框架
  元类：因一切皆对象，实例化类的类，由内置元类type实例化得到，内置函数exec将执行期间产生的名字存放在局部和全局名称空间中，利用class关键字底层原理type(class_name,class_bases,class_namespace)，从而通过元类控制类的产生，利用魔法方法__call__来控制类的产生过程（先调用__new__产生一个空对象，再调用__init__初始化空对象，最后返回初始化对象）
  单下划线:只有类对象和子类对象自己能访问到这些变量。
  双下划线:只有类对象自己能访问，连子类对象也不能访问到这个数据。
  __setattr__: 添加/修改属性会触发它的执行
  __delattr__: 删除属性的时候会触发
  __getattr__: 只有在使用点调用属性且属性不存在的时候才会触发
  __getattribute__: 不管是否存在,我都会执行
  类变量:所有对象共有，其中一个对象将它值改变，其他对象得到的就是改变后的结果
  实例变量:对象私有，某一个对象将其值改变，不影响其他对象
  非绑定方法或静态方法：定义在类内部的普通方法，谁都不绑定，对象或类都可调用，但是不会自动传值
  绑定方法：对象绑定方法和类的绑定方法，其特殊之处在于绑定给谁就是谁来调用，并且把自身传过来，用于不需要通过对象，只需要通过类来完成某事时，当然对象也可调用，一般不用。
  type：只接收一个参数，不但可以判断变量是否属于某个类型，而且可以得到参数变量未知的所属的类型
  isinstance：只能判断是否属于某个已知类型，不能直接得到变量未知的所属的类型
  单例模式：即单个实例是同一个类实例化多次的结果指向同一个对象，用于节省内存空间
  # 通过类的绑定方法实现单例模式
  import settings
  class Mysql:
      _instance = None
      def __init__(self, host, port):
          self.host = host
          self.port = port
      @classmethod
      def singleton(cls):
          if not cls._instance:
              cls._instance = Mysql(settings.HOST, settings.PORT)
          return cls._instance
  obj1 = Mysql('127.0.0.1', '3307')
  obj2 = Mysql('127.0.0.1', '3308')
  print(obj1 is obj2)  # False
  obj3 = Mysql.singleton()
  obj4 = Mysql.singleton()
  print(obj3 is obj4)  # True
  with语句：在嵌套的代码执行之后，自动关闭文件。
  with context_expression [as target(s)]:
      with-body
  context_expression：返回一个上下文管理器对象，自定义的上下文管理器要实现上下文管理协议所需要的 __enter__() 和 __exit__() 两个方法
  ```

* 熟练使用Python语言三大器、列表推导式、字典生成式、匿名函数

  ```python
  装饰器定义：本质上是一个函数，在满足不改变被装饰函数的调用方式和代码的前提下，被装饰的函数当作参数传到装饰器里，然后把值赋值给被装饰函数，其实调用的是装饰器的内层函数来执行。
  from functools import wraps
  def outter(func): # func是被装饰的函数
      @wraps(func)
      def inner(*args,**kwargs): # inner是未来要运行的函数
          # 此处加功能
          res = func(*args,**kwargs)
          return res
      return inner
  @outter
  def learn():
      pass
  print(learn)  # 若没加装饰器修复技术，打印login仍是inner函数内存地址，没达到已加乱真，反之则打印login函数的内存地址及所有相关信息
  生成器定义：函数内部有yield则就是生成器函数，调用函数则返回一个生成器，循环生成器时，则函数内部代码才会执行。本质上生成器是特殊的迭代器
  可迭代对象：具有__iter__()方法的对象，除了数字类型和函数之外都是可迭代对象，可迭代对象不一定是迭代器对象。
  迭代器对象：既具有__iter__方法，又具有__next__方法的对象，只有文件是迭代器对象，迭代器对象一定是可迭代对象。
  列表推导式：lt = [i**2 for i in range(10)]或lt = [(k,v) for (k,v) in dic.items()]
  字典生成式：dic_new = {k:v**2 for k,v in dic.items()}，一般与zip拉链函数配合使用dic = {k:v**2 for k,v in zip(['a','b','c'],[1,2,3])}
  匿名函数：没有绑定变量名，使用一次就被回收，加括号就可运行，通常与max()、sorted()、filter()方法联合使用
  max(salary_dict,key=lambda name:salary_dict[name])
  sorted(salary_dict,key=lambda name:salary_dict[name])
  ```

* 数据库怎么优化查询效率？

  ```python
  1）引擎选择：若数据表需事务处理，应考虑innodb，因完全符合ACID特性，不需要事务处理，默认存储引擎myisam
  2）分表分库，主从
  3）对查询进行优化，尽量避免全表扫描，先考虑where及order by涉及的列上建立索引
  4）对于多张大数据量的表JOIN，要先分页再JOIN，否则性能很差
  ```

* 数据库三大范式

  ```python
  范式：数据库设计对数据的存储性能还有对数据的操作都有关系，故需要一定的规范
  第一范式：要求数据库表的每一列都是不可分割的原子数据项。
  第二范式：在第一范式基础上，确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。
  第三范式：在第二范式基础上，确保数据表中的每一列数据都和主键直接相关，而不能间接相关。
  ```

* 数据库负载均衡

  ```python
  定义：由一组相互独立的计算机构成，通过网络进行连接，由路由器衔接在一起，各节点相互协作、共同负载、均衡压力，对客户端来说，整个集群可视为一台具有超高性能的独立服务器
  ```

* 优化数据库？

  ```python
  本质：数据库是文件，读写文件是IO操作，缓存是代码，运行代码是内存操作，即优化方案从如何降低IO，把内存IO移动到硬盘IO直接提高效率，降低IO次数，高级是算法优化。
  1）在程序中，保证实现功能基础上，尽量减少对数据库访问次数
  2）避免使用不兼容的数据类型，如float和int、char和varchar等
  3）存储引擎
  4）评论数、点赞数、点踩数虽可通过跨表查询得出，但查询数据库频率太高，将三者设计为普通字段
  5）使用缓存
  6）垂直分表：把一些不经常读的数据放在一张表中，节约磁盘IO
  7）设计表时严格按照设计范式设计
  ```

* 数据库引擎

  ```python
  # 存储引擎是针对表的，驱动数据的方式-数据库优化
  mysql>show engines;查看所有引擎
  1）innodb（默认）：支持事务、行级锁、外键，安全性能高但效率偏低
  2）myisam：查询效率优于innodb，当不需要支持事务、行级锁、外键，即不考虑安全性时可设置myisam来优化数据库
  3）blackhole：像黑洞一样的存储引擎，存什么就会没什么。
  4）memory：像内存一样的存储引擎，断电或退出即消失
  ```

* 1000w条数据，使用limit offset分页时，为什么越往后越慢，如何解决？

  ```python
  当一个数据库表过于庞大，LIMIT offset, length中的offset值过大，则SQL查询语句会非常缓慢，你需增加order by，并且order by字段需要建立索引。
  
  如果使用子查询去优化LIMIT的话，则子查询必须是连续的，某种意义来讲，子查询不应该有where条件，where会过滤数据，使数据失去连续性。
  
  如果你查询的记录比较大，并且数据传输量比较大，比如包含了text类型的field，则可以通过建立子查询。
  ```

* 简述触发器、函数、视图、存储过程？

  ```python
  触发器：触发器是一个特殊的存储过程，它是MySQL在insert、update、delete的时候自动执行的代码块。
  
  函数：MySQL中提供了许多内置函数，还可以自定义函数（实现程序员需要sql逻辑处理）
  　　 自定义函数创建语法：
  　　　　   创建：CREATE FUNCTION 函数名称(参数列表) 　
  　　　       RETURNS 返回值类型 　函数体
   　　修改： ALTER FUNCTION 函数名称 [characteristic ...]
  　　 删除：DROP FUNCTION [IF EXISTS] 函数名称
  　　 调用：SELECT 函数名称(参数列表)
    
  视图：视图是由查询结果形成的一张虚拟表，是表通过某种运算得到的一个投影
  　　 　　 create view view_name as select 语句
    
  存储过程：把一段代码封装起来，当要执行这一段代码的时候，可以通过调用该存储过程来实现（经过第一次编译后再次调用不需要再次编译，比一个个执行sql语句效率高）
  　　 create procedure 存储过程名(参数,参数,…)
  　　 begin
  　　 //代码
  　　 end
  ```

* 事务

  ```python
  事务：包含多条执行的sql语句，如转账--从一个用户将资金转出，再将资金转入到另一个用户
  start transaction; --开启事务,在这条语句之后的sql将处在同一事务,并不会立即修改数据库
  commit;--提交事务,让这个事务中的sql立即执行数据的操作,
  rollback;--回滚事务,取消这个事务,这个事务不会对数据库中的数据产生任何影响
  事务的四大特性（ACID）：
  1）原子性：事务是一组不可分割的单位，要么同时成功，要么同时失败
  2）一致性：事务前后的数据应该保持一致
  3）隔离性：多用户并发访问数据时，一个用户的事务不能被其它事务所干扰
  4）持久性：一个事务一旦被提交，对数据的改变是永久性的
  ```

* 数据库锁的作用？

  ```python
  根据不同的锁的作用域我们可以把数据库的锁分为三种，分别为：
    行锁：对表中的某一行进行加锁。
    页锁：对表中一组连续的行进行加锁。
    表锁：对整张表进行加锁
  不同的作用域对并发性能是有很大影响的，比如说如果数据库的插入都是使用表锁，那在大量用户对某张表进行插入读取操作的话，同时只能有一个用户可以访问该表，那并发量肯定就是惨不忍睹了。
  
  乐观锁
  在乐观锁中，我们有3种常用的做法来实现：
  
  第一种就是在数据取得的时候把整个数据都copy到应用中，在进行提交的时候比对当前数据库中的数据和开始的时候更新前取得的数据。当发现两个数据一模一样以后，就表示没有冲突可以提交，否则则是并发冲突，需要去用业务逻辑进行解决。
  
  第二种乐观锁的做法就是采用版本戳，这个在Hibernate中得到了使用。采用版本戳的话，首先需要在你有乐观锁的数据库table上建立一个新的column，比如为number型，当你数据每更新一次的时候，版本数就会往上增加1。比如同样有2个session同样对某条数据进行操作。两者都取到当前的数据的版本号为1，当第一个session进行数据更新后，在提交的时候查看到当前数据的版本还为1，和自己一开始取到的版本相同。就正式提交，然后把版本号增加1，这个时候当前数据的版本为2。当第二个session也更新了数据提交的时候，发现数据库中版本为2，和一开始这个session取到的版本号不一致，就知道别人更新过此条数据，这个时候再进行业务处理，比如整个Transaction都Rollback等等操作。在用版本戳的时候，可以在应用程序侧使用版本戳的验证，也可以在数据库侧采用Trigger(触发器)来进行验证。不过数据库的Trigger的性能开销还是比较的大，所以能在应用侧进行验证的话还是推荐不用Trigger。
  
  第三种做法和第二种做法有点类似，就是也新增一个Table的Column，不过这次这个column是采用timestamp型，存储数据最后更新的时间。在Oracle9i以后可以采用新的数据类型，也就是timestamp with time zone类型来做时间戳。这种Timestamp的数据精度在Oracle的时间类型中是最高的，精确到微秒(还没与到纳秒的级别)，一般来说，加上数据库处理时间和人的思考动作时间，微秒级别是非常非常够了，其实只要精确到毫秒甚至秒都应该没有什么问题。和刚才的版本戳类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。如果不想把代码写在程序中或者由于别的原因无法把代码写在现有的程序中，也可以把这个时间戳乐观锁逻辑写在Trigger或者存储过程中
  
  悲观锁（排他锁）
  悲观锁也称之为互斥锁，可以写为X锁，指的是同时只能有一个事务可以对某个资源进行访问操作。如果有两个事务同时要操作某张表，我们称之为事务A和事务B，如果事务A获得了这张表的表锁，那事务B只能等待事务A释放了这个锁之后才能对该表进行操作。
  
  数据库的insert，update操作默认是采用互斥锁进行加锁，读取select则不是，如果要对select操作使用互斥锁，可以这样写
  
  select * from table where id = 1 for update
  共享锁
  共享锁是一种乐观锁，可以写为S锁，在数据库中共享锁的作用主要是针对读取操作的。如果读取操作使用X锁的话，并发量会非常低，所以数据库提供了共享锁S锁，提高读取操作的并发性能，多个事务可以同时持有一个资源的S锁，不像X锁，同时只能有一个事务持有。
  
  举个例子：
  
  事务A和事务B对表TABLE进行访问，事务A想查看id = 1的行信息
  
  select * from TABLE where id = 1 lock in share mode
  如果当前id = 1的行对应的X锁没有被其他事务获取，那事务A就顺利的获得了该行的S锁。
  
  现在事务B也想查看id = 1 的行信息，会怎么样？
  
  select * from TABLE where id = 1 lock in share mode
  现在持有该行锁的只有事务A，持有的是S锁，所以事务B也可以获取该行的S锁，两个事务可以并发的读取id = 1的行。
  
  这个和之前所说的乐观锁实现是有区别的，最大的不同就是读取的时候共享锁是要真的去持有锁，但是乐观锁只是实现了一种CAS模式，但是并读取的时候没有真的持有锁。
  ```

* 简述数据库分库分表？

  ```python
  # 水平分库
  1、概念：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。
  2、结果：
    每个库的结构都一样；
    每个库的数据都不一样，没有交集；
    所有库的并集是全量数据；
  3、场景：系统绝对并发量上来了，分表难以根本上解决问题，并且还没有明显的业务归属来垂直分库。
  4、分析：库多了，io和cpu的压力自然可以成倍缓解。
  
  # 水平分表
  1、概念：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。
  2、结果：
    每个表的结构都一样；
    每个表的数据都不一样，没有交集；
    所有表的并集是全量数据；
  3、场景：系统绝对并发量并没有上来，只是单表的数据量太多，影响了SQL效率，加重了CPU负担，以至于成为瓶颈。
  4、分析：表的数据量少了，单次SQL执行效率高，自然减轻了CPU的负担。
  
  # 垂直分库
  1、概念：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。
  2、结果：
    每个库的结构都不一样；
    每个库的数据也不一样，没有交集；
    所有库的并集是全量数据；
  3、场景：系统绝对并发量上来了，并且可以抽象出单独的业务模块。
  4、分析：到这一步，基本上就可以服务化了。例如，随着业务的发展一些公用的配置表、字典表等越来越多，这时可以将这些表拆到单独的库中，甚至可以服务化。再有，随着业务的发展孵化出了一套业务模式，这时可以将相关的表拆到单独的库中，甚至可以服务化。
  
  # 垂直分表
  1、概念：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。
  2、结果：
    2.1、每个表的结构都不一样；
    2.2、每个表的数据也不一样，一般来说，每个表的字段至少有一列交集，一般是主键，用于关联数据；
    2.3、所有表的并集是全量数据；
  3、场景：系统绝对并发量并没有上来，表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，单行数据所需的存储空间较大。以至于数据库缓存的数据行减少，查询时会去读磁盘数据产生大量的随机读IO，产生IO瓶颈。
  4、分析：可以用列表页和详情页来帮助理解。垂直分表的拆分原则是将热点数据（可能会冗余经常一起查询的数据）放在一起作为主表，非热点数据放在一起作为扩展表。这样更多的热点数据就能被缓存下来，进而减少了随机读IO。拆了之后，要想获得全部数据就需要关联两个表来取数据。
  但记住，千万别用join，因为join不仅会增加CPU负担并且会讲两个表耦合在一起（必须在一个数据库实例上）。关联数据，应该在业务Service层做文章，分别获取主表和扩展表数据然后用关联字段关联得到全部数据。
  ```

* 简述数据库读写分离？

  ```python
  MySQL Proxy最强大的一项功能是实现“读写分离(Read/Write Splitting)”。基本的原理是让主数据库处理事务性查询，而从数据库处理SELECT查询。数据库复制被用来把事务性查询导致的变更同步到集群中的从数据库。 当然，主服务器也可以提供查询服务。使用读写分离最大的作用无非是环境服务器压力。
  读写分离的好处:
  1、增加冗余
  2、增加了机器的处理能力
  3、对于读操作为主的应用，使用读写分离是最好的场景，因为可以确保写的服务器压力更小，而读又可以接受点时间上的延迟。
  读写分离提高性能之原因:
  1、物理服务器增加，负荷增加
  2、主从只负责各自的写和读，极大程度的缓解X锁和S锁争用
  3、从库可配置myisam引擎，提升查询性能以及节约系统开销
  4、从库同步主库的数据和主库直接写还是有区别的，通过主库发送来的binlog恢复
  ```

* 简述char与varchar的区别？

  ```python
  1）char：定长，按规定宽度存放数据并以规定宽度读取数据，通常更占空间，存取更高效
  2）varchar：不定长，根据数据长度计算所需宽度，并在数据开始以数据头方式将宽度信息保存起来，计算耗时，通常节省空间
  总结：数据长度相近的数据提倡用char来存放数据，数据需高效存取，以空间换时间，采用char。
  ```

* 简述leftjoin和rightjoin的区别？

  ```python
  left join:外链接之左连接：优先显示左表全部记录,以左表为准，即找出所有员工信息，当然包括没有部门的员工，本质就是：在内连接的基础上增加左边有右边没有的结果
  right join:外链接之右连接：优先显示右表全部记录，以右表为准，即找出所有部门信息，包括没有员工的部门，本质就是：在内连接的基础上增加右边有左边没有的结果
  ```

* 索引有什么作用，有什么分类，优劣点？

  ```python
  1）索引就是键（key）且是添加给数据库表字段的
  2）给表创建键后，该表不仅会形成表结构、表数据，还有键的B+结构图
  3）键的结构图是需要维护的，在数据完成增删改操作时，只有影响到有键的字段，结构图都要维护一侧，故创建键后一定会降低增删改的效率
  4）键极大的加快查询速度（开发需求中，几乎业务和查有关系）--主从复制（读写分离）、一主两从
  5）建立键的方式：主键、外键、唯一键、index
  ```

* MySQL慢日志

  ```python
  慢日志查询：记录sql语句中超过设定的时间阈值的查询语句。例如，一条查询sql语句，我们设置的阈值为1s，当这条查询语句的执行时间超过了1s，则将被写入到慢查询配置的日志中.慢查询主要是为了我们做sql语句的优化功能.
  ```

* 如何利用Redis做缓存？

  ```python
  # 设置django缓存存放位置为redis数据库,并设置一个默认(default)选项,在redis中(配置文件/etc/redis/redis.conf)开启了RDB持久化储存
  # pip install django-redis, 然后在视图中可以通过 from django_redis import get_redis_connection 这个方法和redis数据库进行连接
  CACHES = {
      "default": {
          "BACKEND": "django_redis.cache.RedisCache",
          # redis服务器的ip地址及端口号,及数据库序号,redis一共有15个数据库 0~15
          "LOCATION": "redis://127.0.0.1:6379/6",
  　　　　　# "LOCATION": "redis://:passwordpassword@47.193.146.xxx:6379/0", # 如果redis设置密码的话，需要以这种格式进行设置,host前面是密码
          "OPTIONS": {
              "CLIENT_CLASS": "django_redis.client.DefaultClient",
          }
      }
  }
  ```

* 基于django使用ajax发送post请求时，有那种方式携带csrftoken？

  ```python
  1）后端将csrftoken传到前端，发送post请求时携带发送
  data: {
          csrfmiddlewaretoken: '{{ csrf_token }}'
    },
  2）获取form中隐藏标签的csrftoken值，加入到请求数据中到后端
  data: {
            csrfmiddlewaretoken:$('[name="csrfmiddlewaretoken"]').val()
       },
  3）cookie中存在csrftoken，将值放到请求头中
  headers:{ "X-CSRFtoken":$.cookie("csrftoken")} 
  ```

* django中Model中ForeignKey字段中的on_delete参数有什么作用？

  ```python
  删除关联表中的数据时,当前表与其关联的field的操作
  django2.0之后，表与表之间关联的时候,必须要写on_delete参数,否则会报异常
  ```

* django中如何执行原生SQL？

  ```python
  1）使用execute执行自定义的SQL（类似于pymysql的用法）
  from django.db import connection
  cursor = connection.cursor()
  cursor.execute("SELECT DATE_FORMAT(create_time, '%Y-%m') FROM blog_article;")
  ret = cursor.fetchall()
  print(ret)
  2）使用extra方法 ：queryset.extra(select={"key": "原生的SQL语句"})
  3）使用raw方法
  ```

* django如何连接多个数据库并实现读写分离？

  ```python
  # 在配置文件中
  DATABASES = {
      'default': {
          'ENGINE': 'django.db.backends.mysql',
          'HOST': '127.0.0.1',  # 主服务器的运行ip
          'PORT': 3306,   # 主服务器的运行port
          'USER': 'django',  # 主服务器的用户名
          'PASSWORD': 'django',  # 主服务器的密码
          'NAME': 'djangobase'   #  数据表名
      },
      'slave': {
          'ENGINE': 'django.db.backends.mysql', 
          'HOST': '127.0.0.1',
          'PORT': 8306,
          'USER': 'django_slave',
          'PASSWORD': 'django_slave',
          'NAME': 'djangobase_slave'
      }
  }　　
  # 在utils中创建db_router.py文件，并定义一个db类来进行读写分离
  class MasterSlaveDBRouter(object):
      """数据库主从读写分离路由"""
   
      def db_for_read(self, model, **hints):
          """读数据库"""
          return "slave"
   
      def db_for_write(self, model, **hints):
          """写数据库"""
          return "default"
   
      def allow_relation(self, obj1, obj2, **hints):
          """是否运行关联操作"""
          return True　
  # 在配置文件中配置读写分离
  DATABASE_ROUTERS = ['项目名.utils.db_router."自定义的类名称"']
  ```

* 如何给CBV函数设置装饰器

  ```python
  from django.utils.decorators import method_decorator
          # 给方法加：
              @method_decorator(check_login)
              def post(self, request):
                  ...
          # 给dispatch加：
              @method_decorator(check_login)
              def dispatch(self, request, *args, **kwargs):
                  ...
          # 给类加：
              @method_decorator(check_login, name="get")
              @method_decorator(check_login, name="post")
              class HomeView(View):
                  ... 
  ```

* Django中如何在model保存前做一定的固定操作，如写一句日志

  ```python
  利用Django的Model的Signal Dispatcher，通过django.db.models.signals.pre_save()方法，在事件发生前发射触发信号，这一切都被调度中的receiver方法深藏。信号处理一般写在Model中
  import logging
  from django.db import models
  from django.db.models.signals import pre_save
  from django.dispatch import receiver
  class Order(models.Model):
  logger = logging.getLogger(__name__)
  @receiver(pre_save, sender=Order)
  def pre_save_handler(sender, **kwargs):
   logger.debug("{},{}".format(sender, **kwargs))
  ```

* websocket协议及原理

  ```python
  websocket是一种在单个TCP连接上进行全双工通讯的协议，双工（duplex）是指两台通讯设备之间，允许有双向的资料传输。全双工的是指，允许两台设备间同时进行双向资料传输。这是相对于半双工来说的，半双工不能同时进行双向传输，这期间的区别相当于手机和对讲机的区别，手机在讲话的同时也能听到对方说话，对讲机只能一个说完另一个才能说。
  django中实现websocket大致有两种方式：一种是channels，依赖于Redis等，一种是dwebsocket
  ```

* 反向解析

  ```python
  场景：模板中的超链接，视图中的重定向
  使用：在定义路由url时为include定义namespace属性，为url定义name属性，在模板中使用url标签{% url 'namespace_value:name_value'%}，在视图中使用reverse函数：redirect(reverse('namespace_value:name_value'))
  ```

* HttpRequest和HttpResponse？

  ```python
  HttpRequest:django接收用户发送的请求报文后，将报文封装到HttpRequest对象中去
  HttpResponse：返回一个数据报文，render内部已经封装好了HttpResponse类
  请求对象：视图第一个参数必须是HttpRequest对象，因处理web请求必须是请求对象，从根本上说是基于web框架，故view处理的一个request对象，请求的所有属性可根据根式：request.属性
  1）request.path:请求页面路径，不包含域名
  2）request.get_full_path:获取带参数的路径
  3）request.method:获取页面请求方式
  4）request.GET:获取get请求方式的数据
  5）request.POST:获取post请求方式的数据
  6）request.COOKIES:获取cookie
  7）request.session:获取session
  8）request.FILES:上传图片
  ```

* git常用命令

  ```python
  1）git clone:克隆指定仓库
  2）git status：查看当前仓库状态
  3）git diff：比较版本的区别
  4）git log：查看日志
  5）git reset：回溯历史版本
  6）git add：将文件添加到暂存区
  7）git commit：将文件提交到服务器
  8）git checkout：切换到指定分支
  9）git rm：删除指定文件
  .gitignore文件的作用：
  # 此为注释 – 将被 Git 忽略
  *.a       # 忽略所有 .a 结尾的文件
  !lib.a    # 但 lib.a 除外
  /TODO     # 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO
  build/    # 忽略 build/ 目录下的所有文件
  doc/*.txt # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt
  ```

* apache和nginx的区别

  ```python
  nginx:更轻量级、扛并发、异步非阻塞
  apche：阻塞型、模块超多
  ```

* Django中对数据查询结果排序怎么做，降序怎么做，查询大于某个字段怎么做？

  ```python
  1）排序使用order_by()
  2）降序需在排序字段名加-
  3）查询字段大于某值使用filter(字段名_gt=值)
  ```

* 跨域问题（CORS）

  ```python
  源：若两个页面的协议、端口、域名都相同，则两个页面具有相同的源
  同源策略：浏览器的一个安全功能，不同源的客户端脚本在没有明确授权的情况下，不能读写对方资源
  原因：浏览器的同源策略，浏览器拒绝不是当前域返回的数据
  解决方案一：利用第三方模块django-cors-headers
  解决方案二：利用中间件
  ```

* django中当用户登录A应用服务器,下次请求被nignx代理到B应用服务器,会产生什么影

  ```python
  影响：若用户在A应用服务器登录的session数据没共享到B应用服务器上，那么之前的登录状态就没有了。
  ```

* Django中QuerySet的get和filter方法的区别？

  ```python
  1）参数：get的参数只能是model中定义的字段，而filter参数既可以是字段，也可以是where查询关键字，如in、like等
  2）返回值：get返回值是一个定义的model对象，而filter返回值是一个新queryset对象，值得一提的是queryset是一个集合对象，既可以一直使用点方法，也可迭代、遍历、切片等，但不等于是list类型。
  3）异常：get只有一条记录返回时才正常，当返回多条记录或没查到时会抛异常，而filter有没有记录都不会报错
  ```

* 简述Django中内置缓存机制？

  ```python
  Django提供6种缓存机制：
  1）开发调试
  2）内存
  3）文件
  4）数据库
  5）Memcache缓存（python-memcached模块）
  6）Memcache缓存（pylibmc模块）
  除此之外还可使用Redis缓存，因Django是动态网站，每次请求会去数据库进行相应操作，当程序访问量大时，耗时必然会更加明显。
  解决方案：利用缓存将某个views的返回值保存至内存或memcache中，默认配置5分钟再有人访问，则不去执行view中的操作，而是直接从内存或Redis中获取缓存内容并返回
  ```

* Celery分布式任务队列

  ```python
  原因：用户发起请求并等待响应返回，此过程可能需要执行一段时间，用户等待很长时间，造成不好的用户体验。
  解决方案：将耗时的程序放到celery中执行并将耗时的任务添加到队列queue中，即使用Redis实现broke中间人，然后用多个worker去监听队列里的任务去执行
  流程：客户端--->任务发送--->任务队列（broker）<---获取任务处理<---任务处理者（worker）
  重要概念：
  1）任务task：一个python函数
  2）队列queue：将需要执行的任务加入到队列中
  3）工人worker：在一个新进程中，负责执行队列中的任务
  4）代理人broker：负责调度，在布置环境中使用Redis
  正向代理：请求经过代理服务器从局域网发出，然后到达互联网上的服务器，特点是服务端不知道真正的客户端是谁
  反向代理：请求从互联网发出，先进入代理服务器，再转发给局域网内的服务器，特点是客户端并不知道真正的服务端是谁，而两种的区别是正向代理的对象是客户端，反向代理的对象是服务端
  ```

* 谈谈RESTful风格的API？

  ```python
  REST(表现层状态转换):Representational State Transfer，是一种设计风格而不是标准，一种客户端和服务器的交互形式
  1）url设计
  a.一般采用https协议进行传输，保证数据交互安全性
  b.用api关键字标识接口url
  c.多版本共存
  d.前后台交互的数据即资源
  e.资源操作由请求方式决定，如get请求获取数据、post请求增加数据、put请求整体修改数据、patch请求局部修改数据、delete请求删除数据
  2）响应状态码
  a.200常规请求
  b.201创建成功
  c.301永久重定向
  d.302暂时重定向
  e.403请求无权限
  f.404请求路径不存在
  g.405请求方法不存在
  h.500服务器异常
  3）响应结果
  a.数据状态码status
  b.数据状态信息message
  c.数据本身results
  d.二次请求访问资源请求链接img（选写）
  ```

* 谈谈django-restframework的理解

  ```python
  作用：写接口
  # 请求模块
  功能介绍：
  1）drf的request是在wsgi的_request基础上进行二次封装，而_request仅作为drf中的一个属性，同时对_request做了完全兼容
  2）drf的request对数据解析更加规范，所有拼接参数（params）都解析到query_params中，所有数据包数据（body）都解析到data中，所有的请求头数据（headers）都解析到META中
  3）query_params和data属于QueryDict类型，可通过.dict()转化成原生dict类型
  源码分析：
  1）drf的APIView类重写as_view方法，从而局部禁用csrf认证
  2）drf的APIView类重写dispatch方法，从而对request进行二次封装
  # 渲染模块
  1）在视图类中通过renderer_classes对该视图的响应数据做局部配置，可做浏览器渲染
  2）在配置文件中通过DEFAULT_RENDERER_CLASSES对全部视图的响应数据做全局配置，只渲染json
  源码分析：
  1）drf的APIView类中的dispatch方法对响应对象进行二次封装，完成多种渲染方式
  2）在dispatch方法中的finalize_response属性，内部完成解析配置的渲染类
  3）先从视图类找renderer_classes类属性（局部配置），再从APIView类属性（配置文件），再从项目配置文件中（全局配置），最后从drf默认配置文件中找（默认配置）
  # 解析模块
  功能介绍：
  1）在视图类中通过parser_classes属性对该视图的数据包解析做局部配置
  2）在配置文件中通过DEFAULT_PARSER_CLASSES对全局视图的数据包解析做全局配置
  3）默认支持三种请求数据包格式：json类型、urlencoded类型、form-data类型
  源码分析：
  1）在APIView类中的dispatch方法内部既对request二次封装还提供数据解析
  2）准备解析的内容字典并提供解析的类对象
  # 序列化模块
  为何使用：后台的数据多以类对象形式存在，经过序列化后，格式化成返回给前台的数据
  序列化：
  1）视图类三步操作：
  a.ORM操作数据库拿到资源数据
  b.序列化返回给前台的数据
  c.返回序列化后的数据
  2）视图类中序列化操作：
  a.直接将要序列化的数据传给序列化类
  b.若序列化数据是单个对象，序列化参数many默认为False，反之是多个对象，序列化参数many修改为True
  3）自定义序列化类：
  a.model类中给前台的字段即系统字段必须跟model类字段名保持一致
  b.自定义序列化字段用SerializerMethodField()，该字段值来源于get_自定义字段名(序列化对象,Model对象)方法的返回值
  反序列化：
  1）视图类三步操作
  a.从请求对象中获取前台数据
  b.校验前台数据是否合法
  c.反序列化成后台Model对象与数据库交互
  2）视图类中反序列化操作：
  a.将要反序列化的数据传给序列化类的data参数
  b.若反序列化的数据是单个字典，反序列化参数many默认为False，反之是多个字典的对象，反序列化参数many为True
  3）自定义反序列化类
  a.系统字段最好跟model类字段名保持一致，且参数required决定该字段是否必须校验字段
  b.自定义反序列化字段校验规则同系统字段，但在自定义校验规则中将其取出，不参与数据库交互
  c.局部钩子方法命名validate_属性名(self, 属性的value)，校验规则为成功返回属性的value 失败抛出校验错误的异常
  d.全局钩子方法命名 validate(self, 所有属性attrs)，校验规则为成功返回attrs 失败抛出校验错误的异常
  ```

* Django如何提升性能（高并发）？

  ```python
  # 前端
  1）减少http请求，减少数据库的访问量，如使用雪碧图
  2）使用浏览器缓存，将常用的css、js、logo图标等静态资源缓存到本地浏览器，通过设置http请求头中的cache-control和expires的属性可设定浏览器缓存
  3）对html、css、js文件进行压缩，减少网络的流通量
  # 后端
  1）合理使用缓存技术，对常用的动态数据，如首页做缓存并设置过期时间，减少对数据库的压力，提高网站性能
  2）使用celery消息队列，将耗时的操作扔到队列中，让worker去监听队列里的任务，实现异步操作，如发邮件、发短信
  3）代码上优化，如nginx部署项目配置合适的配置参数，提升效率，增加并发量
  4）若考虑安全因素，服务器磁盘用固态硬盘读写远大于机械硬盘，但没普及，主要是固态硬盘技术还不完全成熟
  5）搭建服务器集群，将并发访问请求分散到多台服务器上处理
  6）运维人员的一些性能优化技术
  ```

* 验证码过期时间怎么设置

  ```python
  将验证码保存到数据库或session中，设置过期时间1分钟，然后页面利用js设置一个倒计时展示，1分钟后再次点击获取新验证码
  ```

* Django开发中数据库优化？

  ```python
  1）设计表时，少使用外键，因外键约束会影响插入和删除功能
  2）使用缓存，减少对数据库的访问
  3）设计表时能用varchar确定字段长度就别用text
  4）给搜索频率高的字段创建索引
  5）若一个页面需多次数据库连接，最好一次性取出所有数据，减少查询次数
  6）若页面只需要数据库某一两个字段用QuerySet.values()
  ```

* 对uWSGI和nginx的理解

  ```python
  1）WSGI：全称是Web Server Gateway Interface，即Web服务器网关接口，定义了Web服务器如何与Python应用程序进行交互。
  2）uWSGI：实现uwsgi和WSGI两种协议的web服务器
  3）uwsgi：实现uWSGI的功能模块，常用于uWSGI服务器与其他网络服务器的数据通信
  4）nginx：一种开源的高性能的HTTP服务器和反向代理，处理静态文件和索引文件效率高，稳定性高，负载均衡功能提高网站并发量
  5）两者如何配合工作？
  a.浏览器发起HTTP请求到nginx服务器，nginx接收到请求进行分析，判断访问资源类型
  b.如果是静态资源直接返回给浏览器，如果是动态资源就转交给uwsgi服务器，根据自身的WSGI协议找到对应的Django框架
  c.找到后进行逻辑处理将返回值发送到uwsgi服务器，再返回给nginx，最后通过nginx将返回值返回给浏览器进行渲染显示给用户
  ```

* Django中间件

  ![img](https://images.cnblogs.com/cnblogs_com/daizongqi/1581977/o_191218122928%E6%90%9C%E7%8B%97%E6%88%AA%E5%9B%BE20191218202822.png)

  ```python
  1）先画出Django生命请求周期流程图
  当用户在浏览器中输入url时,浏览器会生成请求头和请求体发给服务端，请求头和请求体中会包含浏览器的动作(action),这个动作通常为get或者post,体现在url之中，url经过Django中的wsgi,再经过Django的中间件,最后url到过路由映射表,在路由中一条一条进行匹配,一旦其中一条匹配成功就执行对应的视图函数,后面的路由就不再继续匹配了，视图函数根据客户端的请求查询相应的数据.返回给Django,然后Django把客户端想要的数据做为一个字符串返回给客户端，客户端浏览器接收到返回的数据,经过渲染后显示给用户。
  2）中间件：作用于网站全局功能，应考虑使用中间件，因任何请求来和响应走都需要经过中间件，常用于用户访问频率限制、用户是否是黑名单或白名单、所有用户登录校验、获取用户权限RBAC等
  3）Django中间件暴露给程序员五个自定义方法，且在特定条件下自动触发
  a.process_request方法:请求来时，从上往下依次经过每一个中间件里面process_request，中间件中若没有该方法，直接跳过执行下一个，该方法内若自己返回HttpResponse对象就不再往后执行，会执行同一级别的process_reponse方法
  b.process_response方法：响应走时，从下往上依次经过每一个中间件里面的process_reponse方法，该方法必须将形参response返回，若没有定义该方法直接跳过执行下一个。
  c.process_view方法：路由匹配成功之后执行视图函数之前触发
  d.process_view方法：当视图函数出现异常时自动触发
  e.process_template_response方法：当视图函数执行完毕后并返回对象中含有render方法情况下才会执行
  4）如何使用
  a.在应用名下新建文件夹并在其目录下新建任意名称的py文件
  b.重写类继承MiddlewareMixin
  c.配置文件注册到中间件配置中，需手写字符串路径，如app01.aaa.bbb.MyMiddle
  from django.shortcuts import HttpResponse
  from django.utils.deprecation import MiddlewareMixin
  class MyMiddle(MiddlewareMixin):
      def process_request(self, request):
          print("自定义process_request方法")
          return HttpResponse("自定义中间件peocess_request的返回值") # 直接原地返回
      def process_response(self, request, response):
          print("自定义process_response方法")
          return response # 必须返回给前台的数据
  ```

* Django创建项目的命令

  ```python
  django-admin startproject 项目名称
  python manage.py startapp 应用名
  生成迁移文件：python manage.py makemigrations
  执行迁移文件：python manage.py migrate 
  Django是MTV框架，本质上还是MVC框架
  MTV：M--models；T--templates；V--views
  MVC：M--models；V--views；C--controller（路由匹配）
  FBV：基于函数的视图
  CBV：基于类的视图，提高代码的复用性
  ```

* re的match和search的区别

  ```python
  match方法：只检测字符串开头位置是否匹配，成功通过.group()方法返回结果，失败返回None
  s1 = 'abcabcabc'
  print(re.match('abc', s1).group()) # abc
  search方法：对整个字符串进行匹配，只要找到第一个匹配结果通过.group()方法返回结果，失败返回None
  s1 = 'abcabcabc'
  print(re.search('bca', s1).group()) # bca
  贪婪匹配（.*）：能匹配的最大部分，匹配所有符合的
  非贪婪匹配（.*?）:匹配越来越好，匹配第一个符合的
  ```

* http协议

  ```python
  HTTP协议全称：超文本传输协议
  # 四大特性
  1）基于TCP/IP之上作用于应用层（TCP打电话，UDP发信息）
  2）基于请求响应
  3）无状态（不保存用户状态）--从而产生cookie  session  token
  4）无连接（one night 情）--长连接（websocket--HTTP协议的大补丁）--用于聊天软件
  # 数据格式
  1）请求格式：请求首行（请求方式、协议版本）\r\n请求头（一堆键值对）\r\n\r\n请求体（真正的数据：发post请求才有，get请求不会有）
  2）响应格式：响应首行\r\n响应头\r\n\r\n响应头
  # 响应状态码
  1）1XX：服务端已经成功接收你的数据，正在处理，可继续提交数据
  2）2XX：服务端成功响应（200请求成功）
  3）3XX：重定向
  4）4XX：请求错误（403拒绝访问；404请求资源不存在）
  5）5XX：服务器内部错误（500）
  # 服务端
  1）24小时提供服务
  2）固定IP和端口
  3）能承受高并发，即多个客户端连接
  # 请求方式
  1）GET请求：获取资源
  2）POST请求：新建资源
  3）PUT请求：更新资源
  4）DELETE请求：删除资源
  # 常见请求头
  1）Host：主机和端口号
  2）User-Agent：浏览器名称
  3）Accept：传输文件类型
  4）Cookie：字符串信息
  ```

* cookie和session的区别

  ```python
  1）cookie数据放在客户端浏览器上，session数据放在服务器上
  2）cookie数据不是很安全，爬虫可利用cookie，而session在一定时间内保存在服务器上，当访问增多耗能
  3）将登陆等信息存放在session中，其他信息放在cookie中
  4）两者是相辅相成的，当用户首次访问服务器，服务器会为每个用户单独创建一个session对象，并为每个session分配唯一一个id，id通过cookie保存到客户端，当用户再次访问服务器时，需将对应的id携带给服务器，服务器通过这唯一的id就可找到用户对应的session对象，从而达到管理用户
  ```

* post与get请求区别

  ```python
  1）get请求数据会暴露在地址栏中，不安全，而post请求数据会放置在请求体中，安全
  2）get请求对传输数据大小有要求，而post理论上不受限制，但各服务器有所规定
  ```

* 描述浏览器访问百度的过程

  ```python
  1、域名解析：浏览器向DNS获取web服务器 www.baidu.com这个域名的 的ip地址
  2、建立TCP连接：浏览器与对应ip地址的服务器进行TCP链接，端口为80
  3、浏览器执行HTTP协议，发送GET请求，读取对应文件
  4、服务器接收到请求后,返回网页信息 
  5、客户端浏览器将这些信息组织成用户可以查看的网页形式
  ```

* cdn

  ```python
  内容分发网络:目的是使用户可以就近到服务器取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度。
  ```

* 进程间如何通信

  ```python
  python提供了多种进程通信的方式，主要Queue和Pipe两种方式，其中Queue用于多进程通信，Pipe用于两个进程间通信
  ```

* GIL锁

  ```python
  全局解释锁，每次只能一个线程获得cpu的使用权：为了线程安全，也就是为了解决多线程之间的数据完整性和状态同步而加的锁，因为我们知道线程之间的数据是共享的。
  ```

* TCP三次握手、四次挥手流程

  ```python
  三次握手过程：
  1）首先客户端向服务端发送一个带有SYN（请求询问） 标志以及随机生成的报文
  2）服务端收到报文后返回一个报文给客户端
  3）客户端再次发送带有ACk（回复）标志的报文给服务端，至此三次握手过程结束，客户端开始向服务端发送数据。
  四次挥手过程（由于TCP是可双向通信，故每个方向必须单独进行关闭）：
  1）客户端发送带有fin标识的报文给服务端，请求通信关闭
  2）服务端收到信息后，回复ACK答应关闭客户端通信(连接)请求
  3）服务端发送带有fin标识的报文给客户端，也请求关闭通信
  4）客户端回应ack给服务端，答应关闭服务端的通信(连接)请求
  ```

* 斐波拉契数列

  ```python
  def fib():
      i, k = 1, 0
      while 1:
          j = i + k
          yield j
          i = k
          k = j
  for fn in fib():
      if fn > 1000:
          break
      else:
          print(fn)
  ```

* 闭包函数

  ```python
  定义：在一个函数内部的函数，被外层函数包裹着，可访问到外层函数中的变量名，如下inner函数就是一个闭包函数。
  def outer():
      num = 1
      def inner():
          print(num)  # 内层函数中不存在num 但可以访问到外层的num
      return inner
  func = outer()  # func == inner
  num = 1000
  func()  # 输出结果：1
  ```

* 如何查找一个字符串中特定的字符？

  ```python
  1）、find()方法：查找子字符串，若找到返回从0开始的下标值，若找不到返回-1
  2）、index()方法：在字符串里查找子串第一次出现的位置，类似字符串的find方法，不过比find方法更好的是，如果查找不到子串，会抛出异常，而不是返回-1
  ```

* 求结果

  ```python
  v = dict.fromkeys(['k1','k2'],[])
  v['k1'].append(666)
  print(v) #{'k1': [666], 'k2': [666]}
  v['k1'] = 777
  print(v)#{'k1': 777, 'k2': [666]}
  #第一次字典的两个k指向的是同一块内存地址，所以k1的内存地址追加666，k2的值也同样会是666，而当给k1赋值时，改变了k1指向的内存地址，所以这个时候，k2不会随之发生变化
  ```

* *arg和**kwargs的作用

  ```python
  *arg:用来接收溢出的位置参数，将接收的参数组织成元组
  **kwargs：用来接收溢出的关键字参数，将接收的参数组织成字典
  ```

* 垃圾回收机制

  ```python
  1）引用计数
  2）标记清除
  3）分代回收
  ```

* 下面代码的输出结果并解释

  ```python
  def extendlist(val, list=[]):
  	list.append(val)
  	return list
  list1 = extendlist(10)
  list2 = extendlist(123, [])
  list3 = extendlist('a')
  print("list1 = %s" %list1) # list1 = [10, 'a']
  print("list2 = %s" %list2) # list2 = [123]
  print("list3 = %s" %list3) # list3 = [10, 'a']
  解释：带有默认参数的表达式在函数被定义时计算，不是在调用时被计算
  def func(a, b={}):
      b[a] = 'v'
      print(b)
  func(1) #{1: 'v'}
  func(2) #{1: 'v', 2: 'v'}
  ```

* 集合相关

  ```python
  &:交集
  |:并集
  -：差集
  ^:对称差集
  l1 = ['b'，'c'，'d'，'b'，'c'，'a'，'a']
  l2 = list(set(l1)) # 去重
  list1 = [1，2，3]
  list2 = [3，4，5]
  set1 = set(list1)
  set2 = set(list2)
  print(set1&set2) #相同元素
  print(set1^set2) #不同元素
  ```

* 写一个列表生成式，产生公差为11的等差数列

  ```python
  1.print([x*11 for x in range(10)])
  ```

* 现有字典`dic={'a':24,'g':52,'i':12,'k':33}`,对value值进行排序？

  ```python
  dic={'a':24,'g':52,'i':12,'k':33}
  print(dic.items())
  # dict_items([('a', 24), ('g', 52), ('i', 12), ('k', 33)])
  print(sorted(dic.items(),key=lambda name:name[1]))
  # [('i', 12), ('a', 24), ('k', 33), ('g', 52)]
  list1 = [{'name':'a'，'age':20}，{'name':'b'，'age':30}，{'name':'c'，'age':25}]
  sorted(list1，key=lambda x:x['age']，reverse=True)
  ```

* 哪些情况下，`y!=x-(x-y)`会成立

  ```python
  x,y是两个不相等的非空集合
  ```
  
* is和==的区别？

  ```python
  is比较的是id
  == 比较的是值
  ```
  
* 列举布尔值为False的常见值

  ```python
  0, False , None , 空类型
  ```
  
* 字符串反转

  ```python
  name[::-1]
  ```
  
* 逻辑与或非关系

  ```python
  v1 = 1 or 3 --> 逻辑或，1和3都是真的，1或3，取决于第一个，即1
  v2 = 1 and 3 --> 逻辑与，1和3都是真的，取决于第二个，即3
  v3 = 0 and 2 or 1 or 4 --> 逻辑与，0和2，取0； 0或1，取1；1或4，取1，即1
  ```
  
* 三元运算和字典生成式

  ```python
  三元运算：条件成立 if 条件 else 条件不成立
  字典生成式：dict = {key: value for (key, value) in iterable}
  ```

* pep8规范

  ```python
  1）函数与类之间用两个空行隔开
  2）同一个类中，方法之间用一个空行隔开
  3）函数、变量名用小写拼写，各单词以下划线相连
  4）每行的字符数不应超过79
  5）使用空格space表示缩进，而不要用tab制表符
  ```
  
* 进程与线程的区别？

  ```python
  进程：一个程序的执行过程，而负责执行任务的是CPU，如执行WPS程序
  线程：进程中的一部分，进程进程中包含多个线程在运行，如监听键盘输入、处理文字等
  协程：单线程下实现并发，由程序员控制和保存状态
  1）进程间相互独立，而同一个进程内的多个线程共享该进程的地址资源
  2）创建线程的开销要远小于创建进程的开销
  3）在主进程下开启多个线程，每个线程跟主进程的pid号一样，而多个进程都有不同的pid号
  并发：同一时刻只能处理一个任务，但可以交替处理多个任务。(一个处理器同时处理多个任务)
  并行：同一时刻可以处理多个任务。(多核的处理器同时处理多个不同的任务)，类比并发是一个人同时吃三个馒头，而并行是三个人同时吃三个馒头。 
  同步：执行一个操作之后，需要主动等待返回结果；
  异步：执行一个操作之后，不需要主动等待返回结果，若接收到结果通知，再回来执行刚才没执行完的操作。
  同步和异步关心的问题是：要不要主动等待结果。
  阻塞：在执行一个操作时，不能做其他操作；
  非阻塞：在执行一个操作时，能做其他操作。
  阻塞和非阻塞关心的问题是：能不能做其他操作。
  多进程：CPU密集型，用于金融行业
  多线程：IO密集型，用于爬虫
  asynio：高并发模块
  nginx：一款自由的、开源的、高性能的HTTP服务器和反向代理服务器，同时也是一个IMAP、POP3、SMTP代理服务器。可以用作HTTP服务器、方向代理服务器、负载均衡。
  负载均衡：系统的扩展可分为纵向（垂直）扩展和横向（水平）扩展。纵向扩展，是从单机的角度通过增加硬件处理能力，比如CPU处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升，不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。因此需要采用横向扩展的方式，通过添加机器来满足大型网站服务的处理能力。比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。这就是典型的集群和负载均衡架构
  反向代理：保护真实服务器不被外界攻击，加速网络等
  ```

* 深浅拷贝

  ```python
  可变类型（列表、集合、字典）：值变id不变；不可变类型（数值、字符串、元组）：值变id变
  拷贝：当l2为l的拷贝对象时，l内的可变类型变化，l2变化；l内的不可变类型变化，l2变化，即简单的赋值
  浅拷贝：当l2为l的浅拷贝对象时，l内的可变类型变化，l2变化；l内的不可变类型变化，l2不变，利用内置方法copy方法，简而言之是仅仅拷贝数据集合的第一层数据
  深拷贝：当l2为l的深拷贝对象时，l内的可变类型变化，l2不变；l内不可变类型变化，l2不变，即利用内置方法deepcopy方法，简而言之是拷贝数据集合的所有层
  ```

* Linux命令

  ```python
  1）查看IP：ip addr 或 ifconfig
  2）查看端口：netstat -anptl
  3）查看内存占用情况：top（动态展示）、free（当前空闲和已用内存的即时快照）、vmstat（虚拟内存统计信息）
  ```

  

