[TOC]

# 实现动态爬虫爬取数据

谷歌浏览器驱动下载地址：

```
http://chromedriver.storage.googleapis.com/index.html
```

火狐浏览器驱动下载地址：

```
https://github.com/mozilla/geckodriver/releases/
```

# 一、selenium的安装与基本介绍

1. selenium的安装非常简单，和其他的Python 库一样，我们可以用pip 安装。

2. ```python
   pip install selenium
   ```

3. selenium的脚本可以控制浏览器进行操作，可以实现多个浏览器的调用，包括IE（7, 8, 9, 10, 11），Firefox，Safari，Google Chrome，Opera等。最常用的是 Chrome，因此下面的讲解也以chrome为例，在执行之前你需要安装chrome浏览器。

4. ```python
   from selenium import webdriver
   driver = webdriver.Chrome("F:\python_老男孩学习\实战项目\爬虫\chromedriver.exe")#这里是写chrome的地址
   driver.get("http://www.santostang.com/2018/07/04/hello-world/")
   ```

## 1.1selenium选择元素的方法

- find_element_by_id：通过元素的id选择，例如:driver.find_element_by_id(‘loginForm’)
- find_element_by_name：通过元素的name选择，driver.find_element_by_name(‘password’)
- find_element_by_xpath：通过xpath选择，driver.find_element_by_xpath(“//form[1]”)
- find_element_by_link_text：通过链接地址选择
- find_element_by_partial_link_text：通过链接的部分地址选择
- find_element_by_tag_name：通过元素的名称选择
- find_element_by_class_name：通过元素的id选择
- find_element_by_css_selector：通过css选择器选择

有时候，我们需要查找多个元素。在上述例子中，我们就查找了所有的评论。因此，也有对应的元素选择方法，就是在上述的element后加上s，变成elements。

– find_elements_by_name
– find_elements_by_xpath
– find_elements_by_link_text
– find_elements_by_partial_link_text
– find_elements_by_tag_name
– find_elements_by_class_name
– find_elements_by_css_selector

其中xpath和css_selector是比较好的方法，一方面比较清晰，另一方面相对其他方法定位元素比较准确。
除此之外，我们还可以使用selenium操作元素方法实现自动操作网页。常见的操作元素方法如下：
– clear 清除元素的内容
– send_keys 模拟按键输入
– click 点击元素
– submit 提交表单

## 1.2对登陆的处理

```python
user = driver.find_element_by_name("username")  #找到用户名输入框
user.clear  #清除用户名输入框内容
user.send_keys("1234567")  #在框中输入用户名
pwd = driver.find_element_by_name("password")  #找到密码输入框
pwd.clear  #清除密码输入框内容
pwd.send_keys("******")    #在框中输入密码
driver.find_element_by_id("loginBtn").click()  #点击登录
```

上述代码中，是一个自动登录程序中截取的一部分。从代码中可以看到，我们可以用selenium操作元素的方法，对浏览器中的网页进行各种操作，包括登录。
除此之外，selenium除了鼠标简单的操作，还可以实现复杂的双击，拖拽等操作。此外，它还可以获得网页中各个元素的大小，甚至还可以进行模拟键盘的操作。由于篇幅有限，有兴趣的读者，可以到selenium的官方文档查看：http://selenium-python.readthedocs.io/index.html





# 二、举例

## 2.1获取一个界面的信息

```python
"""
在上述的例子中，使用Chrome“检查”功能找到源地址还十分容易。
但是有一些网站非常复杂，例如前面的天猫产品评论，使用“检查”功能很难找到调用的网页地址。
除此之外，有一些数据真实地址的URL也十分冗长和复杂，有些网站为了规避这些抓取会对地址进行加密，造成其中的一些变量让人摸不着头脑。
因此，这里介绍第二种方法，使用浏览器渲染引擎。
直接用浏览器在显示网页时解析HTML，应用CSS样式并执行JavaScript的语句。
这方法在爬虫过程中会打开一个浏览器，加载该网页，自动操作浏览器浏览各个网页，顺便把数据抓下来。
用一句简单而通俗的话说，使用浏览器渲染方法，爬取动态网页变成了爬取静态网页。
我们可以用Python的selenium库模拟浏览器完成抓取。Selenium是一个用于Web应用程序测试的工具。
Selenium测试直接运行在浏览器中，浏览器自动按照脚本代码做出点击，输入，打开，验证等操作，就像真正的用户在操作一样。
"""
from selenium import webdriver
driver = webdriver.Chrome("F:\python_老男孩学习\实战项目\爬虫\chromedriver.exe")
driver.get("http://www.santostang.com/2018/07/04/hello-world/")
"""
下面代码的意思：
driver.find_element_by_css_selector是用CSS选择器查找元素，
找到class为’reply-content’的div元素；
find_element_by_tag_name则是通过元素的tag去寻找，
意思是找到comment中的p元素。最后，再输出p元素中的text文本
"""
# comment = driver.find_element_by_css_selector('div.reply-content')
# comment = comment.find_element_by_tag_name('p')
# print(comment.text)
"""
原来的js,没有解析出来，需要对js进行解析
"""

print(driver.page_source)
print("###########################")
driver.switch_to.frame(driver.find_element_by_css_selector("iframe[title='livere']"))
comment = driver.find_element_by_css_selector('div.reply-content')
comment = comment.find_element_by_tag_name('p')
print(comment.text)

```

## 2.2改进版（获取多个界面的信息）

```python
from selenium import webdriver
import time
driver = webdriver.Chrome("F:\python_老男孩学习\实战项目\爬虫\chromedriver.exe")
driver.implicitly_wait(20) # 隐性等待，最长等20秒
#把上述地址改成你电脑中geckodriver.exe程序的地址
driver.get("http://www.santostang.com/2018/07/04/hello-world/")
time.sleep(5)
for i in range(0,3):
    # 下滑到页面底部
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    # 转换iframe，再找到查看更多，点击
    driver.switch_to.frame(driver.find_element_by_css_selector("iframe[title='livere']"))
    load_more = driver.find_element_by_css_selector('button.more-btn')
    load_more.click()
    # 把iframe又转回去
    driver.switch_to.default_content()
    time.sleep(2)
    driver.switch_to.frame(driver.find_element_by_css_selector("iframe[title='livere']"))
    comments = driver.find_elements_by_css_selector('div.reply-content')
    for eachcomment in comments:
        content = eachcomment.find_element_by_tag_name('p')
        print (content.text)
```

# 三，selenium的高级操作

## Selenium的高级操作

使用Selenium和使用浏览器“检查”方法爬取动态网页相比，Selenium因为要把整个网页加载出来，再开始爬取内容，速度往往较慢。
因此在实际使用当中，如果使用浏览器“检查”功能进行网页的逆向工程不复杂的话，最好使用浏览器“检查”功能方法。不过，也有一些方法可以用Selenium控制浏览器的加载的内容，从而加快Selenium的爬取速度。常用的方法有：

1. 控制CSS的加载

2. 控制图片文件的显示

3. 控制JavaScript的执行

   

4. 控制CSS。因为抓取过程中仅仅抓取页面的内容，CSS样式文件是用来控制页面的外观和元素放置位置的，对内容并没有影响，所以我们可以限制网页加载CSS，从而减少抓取时间。其代码如下：

```python
# 控制 css
from selenium import webdriver
fp = webdriver.FirefoxProfile()
fp.set_preference("permissions.default.stylesheet",2)
driver = webdriver.Firefox(firefox_profile=fp, executable_path = r'C:\Users\santostang\Desktop\geckodriver.exe')
#把上述地址改成你电脑中geckodriver.exe程序的地址
driver.get("http://www.santostang.com/2018/07/04/hello-world/")
```

在上述代码中，控制css的加载主要用fp = webdriver.FirefoxProfile()这个功能。设定不加载css，使用fp.set_preference(“permissions.default.stylesheet”,2)。之后使用webdriver.Firefox(firefox_profile=fp)就可以控制不加载css了。

2. 限制图片的加载。如果不需要抓取网页上的图片，最好可以禁止图片加载，限制图片的加载可以帮助我们极大地提高网络爬虫的效率。因为网页上的图片往往较多，而且图片文件相对于文字、CSS、JavaScript等其他文件都比较大，所以加载需要较长时间。

```python
# 限制图片的加载
from selenium import webdriver
fp = webdriver.FirefoxProfile()
fp.set_preference("permissions.default.image",2)
driver = webdriver.Firefox(firefox_profile=fp, executable_path = r'C:\Users\santostang\Desktop\geckodriver.exe')
#把上述地址改成你电脑中geckodriver.exe程序的地址
driver.get("http://www.santostang.com/2018/07/04/hello-world/")
```

与限制css类似，限制图片的加载可以用fp.set_preference(“permissions. default.image”,2)

3. 控制JavaScript的运行。如果需要抓取的内容不是通过JavaScript动态加载得到的，我们可以通过禁止JavaScript的执行来提高抓取的效率。因为大多数网页都会利用JavaScript异步加载很多内容，这些内容不仅是我们不需要的，它们的加载还浪费了时间。

```python
# 限制 JavaScript 的执行
from selenium import webdriver
fp = webdriver.FirefoxProfile()
fp.set_preference("javascript.enabled", False)
driver = webdriver.Firefox(firefox_profile=fp, executable_path = r'C:\Users\santostang\Desktop\geckodriver.exe')
#把上述地址改成你电脑中geckodriver.exe程序的地址
driver.get("http://www.santostang.com/2018/07/04/hello-world/")
```



![](https://img2018.cnblogs.com/blog/1739658/201909/1739658-20190905170352354-364495707.jpg)